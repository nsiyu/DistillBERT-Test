{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Input Question:  Which NFL team represented the AFC at Super Bowl 50?\n",
      "Model Response:  denver broncos\n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "Input Question:  Which NFL team represented the NFC at Super Bowl 50?\n",
      "Model Response:  carolina panthers\n",
      "Actual Answer:  Carolina Panthers\n",
      "\n",
      "Input Question:  Where did Super Bowl 50 take place?\n",
      "Model Response:  levi's stadium\n",
      "Actual Answer:  Santa Clara, California\n",
      "\n",
      "Input Question:  Which NFL team won Super Bowl 50?\n",
      "Model Response:  \n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "Input Question:  What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
      "Model Response:  gold\n",
      "Actual Answer:  gold\n",
      "\n",
      "Input Question:  What was the theme of Super Bowl 50?\n",
      "Model Response:  arabic numerals\n",
      "Actual Answer:  \"golden anniversary\"\n",
      "\n",
      "Input Question:  What day was the game played on?\n",
      "Model Response:  february 7, 2016\n",
      "Actual Answer:  February 7, 2016\n",
      "\n",
      "Input Question:  What is the AFC short for?\n",
      "Model Response:  american football conference\n",
      "Actual Answer:  American Football Conference\n",
      "\n",
      "Input Question:  What was the theme of Super Bowl 50?\n",
      "Model Response:  arabic numerals\n",
      "Actual Answer:  \"golden anniversary\"\n",
      "\n",
      "Input Question:  What does AFC stand for?\n",
      "Model Response:  american football conference\n",
      "Actual Answer:  American Football Conference\n",
      "\n",
      "Input Question:  What day was the Super Bowl played on?\n",
      "Model Response:  february 7, 2016\n",
      "Actual Answer:  February 7, 2016\n",
      "\n",
      "Input Question:  Who won Super Bowl 50?\n",
      "Model Response:  denver broncos\n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "Input Question:  What venue did Super Bowl 50 take place in?\n",
      "Model Response:  levi's stadium\n",
      "Actual Answer:  Levi's Stadium\n",
      "\n",
      "Input Question:  What city did Super Bowl 50 take place in?\n",
      "Model Response:  santa clara\n",
      "Actual Answer:  Santa Clara\n",
      "\n",
      "Input Question:  If Roman numerals were used, what would Super Bowl 50 have been called?\n",
      "Model Response:  super bowl l\n",
      "Actual Answer:  Super Bowl L\n",
      "\n",
      "Input Question:  Super Bowl 50 decided the NFL champion for what season?\n",
      "Model Response:  2015\n",
      "Actual Answer:  2015\n",
      "\n",
      "Input Question:  What year did the Denver Broncos secure a Super Bowl title for the third time?\n",
      "Model Response:  2016\n",
      "Actual Answer:  2015\n",
      "\n",
      "Input Question:  What city did Super Bowl 50 take place in?\n",
      "Model Response:  santa clara\n",
      "Actual Answer:  Santa Clara\n",
      "\n",
      "Input Question:  What stadium did Super Bowl 50 take place in?\n",
      "Model Response:  levi's stadium\n",
      "Actual Answer:  Levi's Stadium\n",
      "\n",
      "Input Question:  What was the final score of Super Bowl 50? \n",
      "Model Response:  24 – 10\n",
      "Actual Answer:  24–10\n",
      "\n",
      "Input Question:  What month, day and year did Super Bowl 50 take place? \n",
      "Model Response:  february 7, 2016\n",
      "Actual Answer:  February 7, 2016\n",
      "\n",
      "Input Question:  What year was Super Bowl 50?\n",
      "Model Response:  2015\n",
      "Actual Answer:  2015\n",
      "\n",
      "Input Question:  What team was the AFC champion?\n",
      "Model Response:  denver broncos\n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "Input Question:  What team was the NFC champion?\n",
      "Model Response:  carolina panthers\n",
      "Actual Answer:  Carolina Panthers\n",
      "\n",
      "Input Question:  Who won Super Bowl 50?\n",
      "Model Response:  denver broncos\n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "Input Question:  Super Bowl 50 determined the NFL champion for what season?\n",
      "Model Response:  2015\n",
      "Actual Answer:  2015\n",
      "\n",
      "Input Question:  Which team won Super Bowl 50.\n",
      "Model Response:  denver broncos\n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "Input Question:  Where was Super Bowl 50 held?\n",
      "Model Response:  levi's stadium\n",
      "Actual Answer:  Santa Clara, California.\n",
      "\n",
      "Input Question:  The name of the NFL championship game is?\n",
      "Model Response:  super bowl l\n",
      "Actual Answer:  Super Bowl\n",
      "\n",
      "Input Question:  What 2015 NFL team one the AFC playoff?\n",
      "Model Response:  denver broncos\n",
      "Actual Answer:  Denver Broncos\n",
      "\n",
      "One of the most famous people born in Warsaw was Maria Skłodowska-Curie, who achieved international recognition for her research on radioactivity and was the first female recipient of the Nobel Prize. Famous musicians include Władysław Szpilman and Frédéric Chopin. Though Chopin was born in the village of Żelazowa Wola, about 60 km (37 mi) from Warsaw, he moved to the city with his family when he was seven months old. Casimir Pulaski, a Polish general and hero of the American Revolutionary War, was born here in 1745.\n",
      "Input Question:  What was Maria Curie the first female recipient of?\n",
      "Model Response:  nobel prize\n",
      "Actual Answer:  Nobel Prize\n",
      "\n",
      "Input Question:  What year was Casimir Pulaski born in Warsaw?\n",
      "Model Response:  1745\n",
      "Actual Answer:  1745\n",
      "\n",
      "Input Question:  Who was one of the most famous people born in Warsaw?\n",
      "Model Response:  maria skłodowska - curie\n",
      "Actual Answer:  Maria Skłodowska-Curie\n",
      "\n",
      "Input Question:  Who was Frédéric Chopin?\n",
      "Model Response:  władysław szpilman\n",
      "Actual Answer:  Famous musicians\n",
      "\n",
      "Input Question:  How old was Chopin when he moved to Warsaw with his family?\n",
      "Model Response:  seven months\n",
      "Actual Answer:  seven months old\n",
      "\n",
      "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "Input Question:  In what country is Normandy located?\n",
      "Model Response:  france\n",
      "Actual Answer:  France\n",
      "\n",
      "Input Question:  When were the Normans in Normandy?\n",
      "Model Response:  10th and 11th centuries\n",
      "Actual Answer:  10th and 11th centuries\n",
      "\n",
      "Input Question:  From which countries did the Norse originate?\n",
      "Model Response:  denmark, iceland and norway\n",
      "Actual Answer:  Denmark, Iceland and Norway\n",
      "\n",
      "Input Question:  Who was the Norse leader?\n",
      "Model Response:  rollo\n",
      "Actual Answer:  Rollo\n",
      "\n",
      "Input Question:  What century did the Normans first gain their separate identity?\n",
      "Model Response:  10th\n",
      "Actual Answer:  10th century\n",
      "\n",
      "Nikola Tesla (Serbian Cyrillic: Никола Тесла; 10 July 1856 – 7 January 1943) was a Serbian American inventor, electrical engineer, mechanical engineer, physicist, and futurist best known for his contributions to the design of the modern alternating current (AC) electricity supply system.\n",
      "Input Question:  In what year was Nikola Tesla born? \n",
      "Model Response:  1856\n",
      "Actual Answer:  1856\n",
      "\n",
      "Input Question:  What was Nikola Tesla's ethnicity?\n",
      "Model Response:  serbian american\n",
      "Actual Answer:  Serbian\n",
      "\n",
      "Input Question:  In what year did Tesla die? \n",
      "Model Response:  1943\n",
      "Actual Answer:  1943\n",
      "\n",
      "Input Question:  When was Nikola Tesla born?\n",
      "Model Response:  10 july 1856\n",
      "Actual Answer:  1856\n",
      "\n",
      "Input Question:  In what year did Tesla die?\n",
      "Model Response:  1943\n",
      "Actual Answer:  1943\n",
      "\n",
      "Input Question:  What is Tesla's home country?\n",
      "Model Response:  serbian\n",
      "Actual Answer:  Serbian\n",
      "\n",
      "Input Question:  What does AC stand for?\n",
      "Model Response:  alternating current\n",
      "Actual Answer:  alternating current\n",
      "\n",
      "Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.\n",
      "Input Question:  What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?\n",
      "Model Response:  computational complexity theory\n",
      "Actual Answer:  Computational complexity theory\n",
      "\n",
      "Input Question:  By what main attribute are computational problems classified utilizing computational complexity theory? \n",
      "Model Response:  inherent difficulty\n",
      "Actual Answer:  inherent difficulty\n",
      "\n",
      "Input Question:  What is the term for a task that generally lends itself to being solved by a computer?\n",
      "Model Response:  a computational problem\n",
      "Actual Answer:  computational problems\n",
      "\n",
      "The role of teacher is often formal and ongoing, carried out at a school or other place of formal education. In many countries, a person who wishes to become a teacher must first obtain specified professional qualifications or credentials from a university or college. These professional qualifications may include the study of pedagogy, the science of teaching. Teachers, like other professionals, may have to continue their education after they qualify, a process known as continuing professional development. Teachers may use a lesson plan to facilitate student learning, providing a course of study which is called the curriculum.\n",
      "Input Question:  What is a course of study called?\n",
      "Model Response:  the curriculum\n",
      "Actual Answer:  the curriculum.\n",
      "\n",
      "Input Question:  What is another name to describe the science of teaching?\n",
      "Model Response:  pedagogy\n",
      "Actual Answer:  pedagogy\n",
      "\n",
      "Input Question:  Where do most teachers get their credentials from?\n",
      "Model Response:  a university or college\n",
      "Actual Answer:  university or college.\n",
      "\n",
      "Input Question:  What can a teacher use to help students learn?\n",
      "Model Response:  a lesson plan\n",
      "Actual Answer:  lesson plan\n",
      "\n",
      "Input Question:  Where is a teacher most likely to be teaching at?\n",
      "Model Response:  school\n",
      "Actual Answer:  school\n",
      "\n",
      "Martin Luther (/ˈluːθər/ or /ˈluːðər/; German: [ˈmaɐ̯tiːn ˈlʊtɐ] ( listen); 10 November 1483 – 18 February 1546) was a German professor of theology, composer, priest, former monk and a seminal figure in the Protestant Reformation. Luther came to reject several teachings and practices of the Late Medieval Catholic Church. He strongly disputed the claim that freedom from God's punishment for sin could be purchased with money. He proposed an academic discussion of the power and usefulness of indulgences in his Ninety-Five Theses of 1517. His refusal to retract all of his writings at the demand of Pope Leo X in 1520 and the Holy Roman Emperor Charles V at the Diet of Worms in 1521 resulted in his excommunication by the Pope and condemnation as an outlaw by the Emperor.\n",
      "Input Question:  Of what nationality was Martin Luther?\n",
      "Model Response:  german\n",
      "Actual Answer:  German\n",
      "\n",
      "Input Question:  When did Martin Luther die?\n",
      "Model Response:  18 february 1546\n",
      "Actual Answer:  18 February 1546\n",
      "\n",
      "Input Question:  What organization's teaching did Luther reject?\n",
      "Model Response:  the late medieval catholic church\n",
      "Actual Answer:  Catholic Church.\n",
      "\n",
      "Input Question:  What did the Church claim could be avoided with money?\n",
      "Model Response:  freedom from god's punishment for sin\n",
      "Actual Answer:  God's punishment\n",
      "\n",
      "Input Question:  What did the Church do when Luther refused to retract his writings?\n",
      "Model Response:  excommunication\n",
      "Actual Answer:  excommunication\n",
      "\n",
      "Southern California, often abbreviated SoCal, is a geographic and cultural region that generally comprises California's southernmost 10 counties. The region is traditionally described as \"eight counties\", based on demographics and economic ties: Imperial, Los Angeles, Orange, Riverside, San Bernardino, San Diego, Santa Barbara, and Ventura. The more extensive 10-county definition, including Kern and San Luis Obispo counties, is also used based on historical political divisions. Southern California is a major economic center for the state of California and the United States.\n",
      "Input Question:  What is Southern California often abbreviated as?\n",
      "Model Response:  socal\n",
      "Actual Answer:  SoCal\n",
      "\n",
      "Input Question:  Despite being traditionall described as \"eight counties\", how many counties does this region actually have?\n",
      "Model Response:  10\n",
      "Actual Answer:  10 counties\n",
      "\n",
      "Input Question:  What is a major importance of Southern California in relation to California and the United States?\n",
      "Model Response:  economic\n",
      "Actual Answer:  economic center\n",
      "\n",
      "Input Question:  What are the ties that best described what the \"eight counties\" are based on?\n",
      "Model Response:  demographics and economic ties : imperial, los angeles, orange, riverside, san bernardino, san diego, santa barbara, and ventura\n",
      "Actual Answer:  demographics and economic ties\n",
      "\n",
      "Input Question:  The reasons for the las two counties to be added are based on what?\n",
      "Model Response:  historical political divisions\n",
      "Actual Answer:  historical political divisions\n",
      "\n",
      "Formed in November 1990 by the equal merger of Sky Television and British Satellite Broadcasting, BSkyB became the UK's largest digital subscription television company. Following BSkyB's 2014 acquisition of Sky Italia and a majority 90.04% interest in Sky Deutschland in November 2014, its holding company British Sky Broadcasting Group plc changed its name to Sky plc. The United Kingdom operations also changed the company name from British Sky Broadcasting Limited to Sky UK Limited, still trading as Sky.\n",
      "Input Question:  What company was formed by the merger of Sky Television and British Satellite Broadcasting?\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  BSkyB\n",
      "\n",
      "Input Question:  Who is the UK's largest digital subscription television company?\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  BSkyB\n",
      "\n",
      "Input Question:  What year did BSkyB acquire Sky Italia?\n",
      "Model Response:  2014\n",
      "Actual Answer:  2014\n",
      "\n",
      "Input Question:  What is the name of the holding company for BSkyB?\n",
      "Model Response:  british sky broadcasting group plc\n",
      "Actual Answer:  Sky plc\n",
      "\n",
      "Input Question:  What is the name of the United Kingdom operation for BSkyB?\n",
      "Model Response:  british sky broadcasting limited\n",
      "Actual Answer:  Sky UK Limited\n",
      "\n",
      "The economy of Victoria is highly diversified: service sectors including financial and property services, health, education, wholesale, retail, hospitality and manufacturing constitute the majority of employment. Victoria's total gross state product (GSP) is ranked second in Australia, although Victoria is ranked fourth in terms of GSP per capita because of its limited mining activity. Culturally, Melbourne is home to a number of museums, art galleries and theatres and is also described as the \"sporting capital of Australia\". The Melbourne Cricket Ground is the largest stadium in Australia, and the host of the 1956 Summer Olympics and the 2006 Commonwealth Games. The ground is also considered the \"spiritual home\" of Australian cricket and Australian rules football, and hosts the grand final of the Australian Football League (AFL) each year, usually drawing crowds of over 95,000 people. Victoria includes eight public universities, with the oldest, the University of Melbourne, having been founded in 1853.\n",
      "Input Question:  What kind of economy does Victoria have?\n",
      "Model Response:  highly diversified\n",
      "Actual Answer:  diversified\n",
      "\n",
      "Input Question:  Where according to gross state product does Victoria rank in Australia?\n",
      "Model Response:  second\n",
      "Actual Answer:  second\n",
      "\n",
      "Input Question:  At what rank does GPS per capita set Victoria?\n",
      "Model Response:  fourth\n",
      "Actual Answer:  fourth\n",
      "\n",
      "Input Question:  What city in Victoria is called the sporting capital of Australia?\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  Melbourne\n",
      "\n",
      "Input Question:  What is the largest stadium in Australia?\n",
      "Model Response:  melbourne cricket ground\n",
      "Actual Answer:  Melbourne Cricket Ground\n",
      "\n",
      "Huguenot numbers peaked near an estimated two million by 1562, concentrated mainly in the southern and central parts of France, about one-eighth the number of French Catholics. As Huguenots gained influence and more openly displayed their faith, Catholic hostility grew, in spite of increasingly liberal political concessions and edicts of toleration from the French crown. A series of religious conflicts followed, known as the Wars of Religion, fought intermittently from 1562 to 1598. The wars finally ended with the granting of the Edict of Nantes, which granted the Huguenots substantial religious, political and military autonomy.\n",
      "Input Question:  Where was France's Huguenot population largely centered?\n",
      "Model Response:  southern and central parts of france\n",
      "Actual Answer:  the southern and central parts of France\n",
      "\n",
      "Input Question:  What was the proportion of Huguenots to Catholics at their peak?\n",
      "Model Response:  \n",
      "Actual Answer:  about one-eighth the number\n",
      "\n",
      "Input Question:  When were the Wars of Religion fought?\n",
      "Model Response:  1562 to 1598\n",
      "Actual Answer:  from 1562 to 1598\n",
      "\n",
      "Input Question:  What treaty ended the Wars of Religion?\n",
      "Model Response:  edict of nantes\n",
      "Actual Answer:  the Edict of Nantes\n",
      "\n",
      "Input Question:  What did this agreement do?\n",
      "Model Response:  gained influence and more openly displayed their faith\n",
      "Actual Answer:  granted the Huguenots substantial religious, political and military autonomy\n",
      "\n",
      "Steam engines are external combustion engines, where the working fluid is separate from the combustion products. Non-combustion heat sources such as solar power, nuclear power or geothermal energy may be used. The ideal thermodynamic cycle used to analyze this process is called the Rankine cycle. In the cycle, water is heated and transforms into steam within a boiler operating at a high pressure. When expanded through pistons or turbines, mechanical work is done. The reduced-pressure steam is then condensed and pumped back into the boiler.\n",
      "Input Question:  Along with geothermal and nuclear, what is a notable non-combustion heat source?\n",
      "Model Response:  solar power\n",
      "Actual Answer:  solar\n",
      "\n",
      "Input Question:  What ideal thermodynamic cycle analyzes the process by which steam engines work?\n",
      "Model Response:  rankine cycle\n",
      "Actual Answer:  Rankine\n",
      "\n",
      "Input Question:  In the Rankine cycle, what does water turn into when heated?\n",
      "Model Response:  steam\n",
      "Actual Answer:  steam\n",
      "\n",
      "Input Question:  At what pressure is water heated in the Rankine cycle?\n",
      "Model Response:  high pressure\n",
      "Actual Answer:  high\n",
      "\n",
      "Input Question:  What types of engines are steam engines?\n",
      "Model Response:  external combustion engines\n",
      "Actual Answer:  external combustion\n",
      "\n",
      "Oxygen is a chemical element with symbol O and atomic number 8. It is a member of the chalcogen group on the periodic table and is a highly reactive nonmetal and oxidizing agent that readily forms compounds (notably oxides) with most elements. By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium. At standard temperature and pressure, two atoms of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O\n",
      "2. Diatomic oxygen gas constitutes 20.8% of the Earth's atmosphere. However, monitoring of atmospheric oxygen levels show a global downward trend, because of fossil-fuel burning. Oxygen is the most abundant element by mass in the Earth's crust as part of oxide compounds such as silicon dioxide, making up almost half of the crust's mass.\n",
      "Input Question:  The atomic number of the periodic table for oxygen?\n",
      "Model Response:  8\n",
      "Actual Answer:  8\n",
      "\n",
      "Input Question:  What is the second most abundant element?\n",
      "Model Response:  hydrogen and helium\n",
      "Actual Answer:  helium\n",
      "\n",
      "Input Question:  How many atoms combine to form dioxygen?\n",
      "Model Response:  two\n",
      "Actual Answer:  two atoms\n",
      "\n",
      "Input Question:  Roughly, how much oxygen makes up the Earth crust?\n",
      "Model Response:  half\n",
      "Actual Answer:  almost half\n",
      "\n",
      "Input Question:  Which gas makes up 20.8% of the Earth's atmosphere?\n",
      "Model Response:  diatomic oxygen\n",
      "Actual Answer:  Diatomic oxygen\n",
      "\n",
      "Input Question:  How much of the earth's atmosphere is diatomic oxygen?\n",
      "Model Response:  20. 8 %\n",
      "Actual Answer:  20.8%\n",
      "\n",
      "Input Question:  What element makes up almost half of the earth's crust by mass?\n",
      "Model Response:  silicon dioxide\n",
      "Actual Answer:  Oxygen\n",
      "\n",
      "Input Question:  What is the atomic number for oxygen?\n",
      "Model Response:  8\n",
      "Actual Answer:  8\n",
      "\n",
      "Input Question:  Are atmospheric oxygen levels going up, down, or staying the same?\n",
      "Model Response:  global downward\n",
      "Actual Answer:  monitoring of atmospheric oxygen levels show a global downward trend\n",
      "\n",
      "Input Question:  What are the three most abundent elements of the universe by mass?\n",
      "Model Response:  hydrogen and helium\n",
      "Actual Answer:  By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium\n",
      "\n",
      "Input Question:  What is the atomic number of the element oxygen?\n",
      "Model Response:  8\n",
      "Actual Answer:  8\n",
      "\n",
      "Input Question:  Of what group in the periodic table is oxygen a member?\n",
      "Model Response:  chalcogen\n",
      "Actual Answer:  chalcogen\n",
      "\n",
      "Input Question:  What type of compounds does oxygen most commonly form?\n",
      "Model Response:  oxides\n",
      "Actual Answer:  oxides\n",
      "\n",
      "Input Question:  Compared to other elements, how abundant does oxygen rank?\n",
      "Model Response:  third - most abundant\n",
      "Actual Answer:  third\n",
      "\n",
      "Input Question:  Under normal conditions, what do two atoms of oxygen form?\n",
      "Model Response:  dioxygen\n",
      "Actual Answer:  dioxygen\n",
      "\n",
      "The 1973 oil crisis began in October 1973 when the members of the Organization of Arab Petroleum Exporting Countries (OAPEC, consisting of the Arab members of OPEC plus Egypt and Syria) proclaimed an oil embargo. By the end of the embargo in March 1974, the price of oil had risen from US$3 per barrel to nearly $12 globally; US prices were significantly higher. The embargo caused an oil crisis, or \"shock\", with many short- and long-term effects on global politics and the global economy. It was later called the \"first oil shock\", followed by the 1979 oil crisis, termed the \"second oil shock.\"\n",
      "Input Question:  When did the 1973 oil crisis begin?\n",
      "Model Response:  october 1973\n",
      "Actual Answer:  October 1973\n",
      "\n",
      "Input Question:  What was the price of oil in March of 1974?\n",
      "Model Response:  us $ 3 per barrel to nearly $ 12\n",
      "Actual Answer:  nearly $12\n",
      "\n",
      "Input Question:  When was the second oil crisis?\n",
      "Model Response:  1979\n",
      "Actual Answer:  1979\n",
      "\n",
      "Input Question:  What was another term used for the oil crisis?\n",
      "Model Response:  second oil shock\n",
      "Actual Answer:  first oil shock\n",
      "\n",
      "Input Question:  Who proclaimed the oil embargo?\n",
      "Model Response:  organization of arab petroleum exporting countries\n",
      "Actual Answer:  members of the Organization of Arab Petroleum Exporting Countries\n",
      "\n",
      "The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of \"landing a man on the Moon and returning him safely to the Earth\" by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini (1962–66). The first manned flight of Apollo was in 1968.\n",
      "Input Question:  What project put the first Americans into space?\n",
      "Model Response:  mercury\n",
      "Actual Answer:  Project Mercury\n",
      "\n",
      "Input Question:  What program was created to carry out these projects and missions?\n",
      "Model Response:  the apollo program\n",
      "Actual Answer:  National Aeronautics and Space Administration (NASA)\n",
      "\n",
      "Input Question:  What year did the first manned Apollo flight occur?\n",
      "Model Response:  1968\n",
      "Actual Answer:  1968\n",
      "\n",
      "Input Question:  What President is credited with the original notion of putting Americans in space?\n",
      "Model Response:  dwight d. eisenhower\n",
      "Actual Answer:  Dwight D. Eisenhower\n",
      "\n",
      "Input Question:  How many people were on the project that followed Project Mercury?\n",
      "Model Response:  three\n",
      "Actual Answer:  two\n",
      "\n",
      "European Union law is a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states. The three sources of European Union law are primary law, secondary law and supplementary law. The main sources of primary law are the Treaties establishing the European Union. Secondary sources include regulations and directives which are based on the Treaties. The legislature of the European Union is principally composed of the European Parliament and the Council of the European Union, which under the Treaties may establish secondary law to pursue the objective set out in the Treaties.\n",
      "Input Question:  What are the three sources of European Union law?\n",
      "Model Response:  primary law, secondary law and supplementary law\n",
      "Actual Answer:  primary law, secondary law and supplementary law.\n",
      "\n",
      "Input Question:  What is European Union Law?\n",
      "Model Response:  a body of treaties and legislation\n",
      "Actual Answer:  a body of treaties and legislation\n",
      "\n",
      "Input Question:  What are the main sources of primary law?\n",
      "Model Response:  treaties establishing the european union\n",
      "Actual Answer:  Treaties establishing the European Union\n",
      "\n",
      "Input Question:  What are the secondary sources of primary law?\n",
      "Model Response:  treaties establishing the european union\n",
      "Actual Answer:  regulations and directives\n",
      "\n",
      "Input Question:  What are the two bodies that make up the European Union's legislature?\n",
      "Model Response:  european parliament and the council of the european union\n",
      "Actual Answer:  European Parliament and the Council of the European Union\n",
      "\n",
      "Input Question:  What is European Union law?\n",
      "Model Response:  a body of treaties and legislation\n",
      "Actual Answer:  a body of treaties and legislation\n",
      "\n",
      "Input Question:  What effect does European Union law have on laws of member states?\n",
      "Model Response:  direct effect or indirect effect\n",
      "Actual Answer:  direct effect or indirect effect\n",
      "\n",
      "Input Question:  What are the three sources of European Union law?\n",
      "Model Response:  primary law, secondary law and supplementary law\n",
      "Actual Answer:  primary law, secondary law and supplementary law\n",
      "\n",
      "Input Question:  What are the main legislative bodies of the European Union?\n",
      "Model Response:  european parliament and the council of the european union\n",
      "Actual Answer:  European Parliament and the Council of the European Union\n",
      "\n",
      "Input Question:  What are the three main sources of European Union law?\n",
      "Model Response:  primary law, secondary law and supplementary law\n",
      "Actual Answer:  primary law, secondary law and supplementary law\n",
      "\n",
      "Input Question:  What are the main sources of primary law?\n",
      "Model Response:  treaties establishing the european union\n",
      "Actual Answer:  the Treaties establishing the European Union\n",
      "\n",
      "Input Question:  What is the legislature of the European Union comprised of?\n",
      "Model Response:  european parliament and the council of the european union\n",
      "Actual Answer:  the European Parliament and the Council of the European Union\n",
      "\n",
      "Input Question:  How many sources of European Union law are there?\n",
      "Model Response:  three\n",
      "Actual Answer:  three\n",
      "\n",
      "The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\n",
      "Input Question:  Which name is also used to describe the Amazon rainforest in English?\n",
      "Model Response:  amazonia\n",
      "Actual Answer:  also known in English as Amazonia or the Amazon Jungle,\n",
      "\n",
      "Input Question:  How many square kilometers of rainforest is covered in the basin?\n",
      "Model Response:  5, 500, 000\n",
      "Actual Answer:  5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest.\n",
      "\n",
      "Input Question:  How many nations control this region in total?\n",
      "Model Response:  nine\n",
      "Actual Answer:  This region includes territory belonging to nine nations.\n",
      "\n",
      "Input Question:  How many nations contain \"Amazonas\" in their names?\n",
      "Model Response:  four\n",
      "Actual Answer:  States or departments in four nations contain \"Amazonas\" in their names.\n",
      "\n",
      "Input Question:  What percentage does the Amazon represents in rainforests on the planet?\n",
      "Model Response:  over half\n",
      "Actual Answer:  The Amazon represents over half of the planet's remaining rainforests\n",
      "\n",
      "Input Question:  What is the Dutch word for the Amazon rainforest?\n",
      "Model Response:  amazoneregenwoud\n",
      "Actual Answer:  Amazoneregenwoud\n",
      "\n",
      "Input Question:  What rainforest covers the majority of the Amazon basin in South America?\n",
      "Model Response:  amazon rainforest\n",
      "Actual Answer:  The Amazon rainforest\n",
      "\n",
      "Input Question:  In what country can most of the Amazon rainforest be found?\n",
      "Model Response:  brazil\n",
      "Actual Answer:  Brazil\n",
      "\n",
      "Input Question:  The Amazon rainforest makes up what amount of Earth's rainforests?\n",
      "Model Response:  over half\n",
      "Actual Answer:  over half\n",
      "\n",
      "Input Question:  How many species of trees can be found in the Amazon rainforest?\n",
      "Model Response:  16, 000\n",
      "Actual Answer:  16,000\n",
      "\n",
      "Input Question:  What kind of forest is the Amazon rainforest?\n",
      "Model Response:  moist broadleaf\n",
      "Actual Answer:  moist broadleaf forest\n",
      "\n",
      "Input Question:  How many square kilometers is the Amazon Basin?\n",
      "Model Response:  7, 000, 000 square kilometres ( 2, 700, 000 sq mi ), of which 5, 500, 000 square kilometres ( 2, 100, 000\n",
      "Actual Answer:  7,000,000 square kilometres (2,70\n",
      "\n",
      "Input Question:  How many nations are within the Amazon Basin?\n",
      "Model Response:  nine\n",
      "Actual Answer:  nine nations\n",
      "\n",
      "Input Question:  Which nation contains the majority of the amazon forest?\n",
      "Model Response:  brazil\n",
      "Actual Answer:  Brazil\n",
      "\n",
      "Input Question:  What is the estimate for the amount of tree species in the amazon tropical rain forest?\n",
      "Model Response:  390 billion\n",
      "Actual Answer:  16,000 species\n",
      "\n",
      "Ctenophora (/tᵻˈnɒfərə/; singular ctenophore, /ˈtɛnəfɔːr/ or /ˈtiːnəfɔːr/; from the Greek κτείς kteis 'comb' and φέρω pherō 'carry'; commonly known as comb jellies) is a phylum of animals that live in marine waters worldwide. Their most distinctive feature is the ‘combs’ – groups of cilia which they use for swimming – they are the largest animals that swim by means of cilia. Adults of various species range from a few millimeters to 1.5 m (4 ft 11 in) in size. Like cnidarians, their bodies consist of a mass of jelly, with one layer of cells on the outside and another lining the internal cavity. In ctenophores, these layers are two cells deep, while those in cnidarians are only one cell deep. Some authors combined ctenophores and cnidarians in one phylum, Coelenterata, as both groups rely on water flow through the body cavity for both digestion and respiration. Increasing awareness of the differences persuaded more recent authors to classify them as separate phyla.\n",
      "Input Question:  What are Ctenophora commonly known as?\n",
      "Model Response:  comb jellies\n",
      "Actual Answer:  comb jellies\n",
      "\n",
      "Input Question:  Where do Ctenophora live?\n",
      "Model Response:  marine waters\n",
      "Actual Answer:  marine waters worldwide.\n",
      "\n",
      "Input Question:  What size are adult Ctenophora?\n",
      "Model Response:  1. 5 m ( 4 ft 11 in )\n",
      "Actual Answer:  a few millimeters to 1.5 m (4 ft 11 in) in size.\n",
      "\n",
      "Input Question:  What is a ctenophora?\n",
      "Model Response:  a phylum\n",
      "Actual Answer:  phylum of animals that live in marine waters\n",
      "\n",
      "Input Question:  What does the ctenophora use to swim?\n",
      "Model Response:  combs ’ – groups of cilia\n",
      "Actual Answer:  ‘combs’ – groups of cilia\n",
      "\n",
      "Input Question:  What does ctenophora use for digestion and respiration?\n",
      "Model Response:  water flow through the body cavity\n",
      "Actual Answer:  water flow through the body cavity\n",
      "\n",
      "Input Question:  How large can ctenophora grow?\n",
      "Model Response:  1. 5 m ( 4 ft 11 in )\n",
      "Actual Answer:  1.5 m (4 ft 11 in)\n",
      "\n",
      "Input Question:  What is the most distinctive feature of ctenophora?\n",
      "Model Response:  ‘ combs\n",
      "Actual Answer:  ‘combs’ – groups of cilia\n",
      "\n",
      "Input Question:  What are ctenophora commonly known as?\n",
      "Model Response:  comb jellies\n",
      "Actual Answer:  comb jellies\n",
      "\n",
      "Input Question:  How big can ctenophora grow?\n",
      "Model Response:  1. 5 m ( 4 ft 11 in )\n",
      "Actual Answer:  1.5 m (4 ft 11 in)\n",
      "\n",
      "Input Question:  What does ctenophora rely on for digestion and respiration?\n",
      "Model Response:  water flow through the body cavity\n",
      "Actual Answer:  water flow through the body cavity\n",
      "\n",
      "Input Question:  What does ctenophora mean in Greek?\n",
      "Model Response:  comb\n",
      "Actual Answer:  κτείς kteis 'comb' and φέρω pherō 'carry'\n",
      "\n",
      "Input Question:  Where do ctenophora live?\n",
      "Model Response:  marine waters\n",
      "Actual Answer:  marine waters\n",
      "\n",
      "Fresno (/ˈfrɛznoʊ/ FREZ-noh), the county seat of Fresno County, is a city in the U.S. state of California. As of 2015, the city's population was 520,159, making it the fifth-largest city in California, the largest inland city in California and the 34th-largest in the nation. Fresno is in the center of the San Joaquin Valley and is the largest city in the Central Valley, which contains the San Joaquin Valley. It is approximately 220 miles (350 km) northwest of Los Angeles, 170 miles (270 km) south of the state capital, Sacramento, or 185 miles (300 km) south of San Francisco. The name Fresno means \"ash tree\" in Spanish, and an ash leaf is featured on the city's flag.\n",
      "Input Question:  Which city is the fifth-largest city in California?\n",
      "Model Response:  fresno\n",
      "Actual Answer:  Fresno\n",
      "\n",
      "Input Question:  How far is Fresno from Los Angeles?\n",
      "Model Response:  220 miles\n",
      "Actual Answer:  220 miles (350 km)\n",
      "\n",
      "Input Question:  What does the name Fresno mean in Spanish?\n",
      "Model Response:  ash tree\n",
      "Actual Answer:  ash tree\n",
      "\n",
      "Input Question:  What is featured on the city of Fresno's city flag?\n",
      "Model Response:  ash leaf\n",
      "Actual Answer:  ash leaf\n",
      "\n",
      "Input Question:  How do you pronounce Fresno?\n",
      "Model Response:  ash tree\n",
      "Actual Answer:  (/ˈfrɛznoʊ/ FREZ-noh)\n",
      "\n",
      "Starting in the late 1950s, American computer scientist Paul Baran developed the concept Distributed Adaptive Message Block Switching with the goal to provide a fault-tolerant, efficient routing method for telecommunication messages as part of a research program at the RAND Corporation, funded by the US Department of Defense. This concept contrasted and contradicted the theretofore established principles of pre-allocation of network bandwidth, largely fortified by the development of telecommunications in the Bell System. The new concept found little resonance among network implementers until the independent work of Donald Davies at the National Physical Laboratory (United Kingdom) (NPL) in the late 1960s. Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe in the decade following, including the incorporation of the concept in the early ARPANET in the United States.\n",
      "Input Question:  What did Paul Baran develop \n",
      "Model Response:  distributed adaptive message block switching\n",
      "Actual Answer:  Paul Baran developed the concept Distributed Adaptive Message Block Switching\n",
      "\n",
      "Input Question:  What did Distributed Adaptive Message Block Switching do\n",
      "Model Response:  to provide a fault - tolerant, efficient routing method for telecommunication messages\n",
      "Actual Answer:  provide a fault-tolerant, efficient routing method for telecommunication messages\n",
      "\n",
      "Input Question:  What did this concept contradict \n",
      "Model Response:  the theretofore established principles of pre - allocation of network bandwidth\n",
      "Actual Answer:  This concept contrasted and contradicted the theretofore established principles of pre-allocation of network bandwidth\n",
      "\n",
      "Input Question:  What is Donald Davies credited with \n",
      "Model Response:  coining the modern name packet switching\n",
      "Actual Answer:  Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe\n",
      "\n",
      "Input Question:  What did Paul Baran develop in the late 1950's\n",
      "Model Response:  distributed adaptive message block switching\n",
      "Actual Answer:  the concept Distributed Adaptive Message Block Switching\n",
      "\n",
      "Input Question:  What was the goal of the system \n",
      "Model Response:  to provide a fault - tolerant, efficient routing method for telecommunication messages\n",
      "Actual Answer:  to provide a fault-tolerant, efficient routing method for telecommunication messages\n",
      "\n",
      "Input Question:  Who is credited with the modern name for this system \n",
      "Model Response:  donald davies\n",
      "Actual Answer:  Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe\n",
      "\n",
      "The Black Death is thought to have originated in the arid plains of Central Asia, where it then travelled along the Silk Road, reaching Crimea by 1343. From there, it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on merchant ships. Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30–60% of Europe's total population. In total, the plague reduced the world population from an estimated 450 million down to 350–375 million in the 14th century. The world population as a whole did not recover to pre-plague levels until the 17th century. The plague recurred occasionally in Europe until the 19th century.\n",
      "Input Question:  Where did the black death originate?\n",
      "Model Response:  the arid plains of central asia\n",
      "Actual Answer:  the arid plains of Central Asia\n",
      "\n",
      "Input Question:  How did the black death make it to the Mediterranean and Europe?\n",
      "Model Response:  spreading throughout the mediterranean and europe, the black death is estimated to have killed 30 – 60 % of europe's total population\n",
      "Actual Answer:  merchant ships.\n",
      "\n",
      "Input Question:  How much of the European population did the black death kill?\n",
      "Model Response:  30 – 60 %\n",
      "Actual Answer:  30–60% of Europe's total population\n",
      "\n",
      "Input Question:  When did the world's population finally recover from the black death?\n",
      "Model Response:  17th century\n",
      "Actual Answer:  the 17th century\n",
      "\n",
      "Input Question:  For how long did the plague stick around?\n",
      "Model Response:  19th century\n",
      "Actual Answer:  until the 19th century\n",
      "\n",
      "There are three major types of rock: igneous, sedimentary, and metamorphic. The rock cycle is an important concept in geology which illustrates the relationships between these three types of rock, and magma. When a rock crystallizes from melt (magma and/or lava), it is an igneous rock. This rock can be weathered and eroded, and then redeposited and lithified into a sedimentary rock, or be turned into a metamorphic rock due to heat and pressure that change the mineral content of the rock which gives it a characteristic fabric. The sedimentary rock can then be subsequently turned into a metamorphic rock due to heat and pressure and is then weathered, eroded, deposited, and lithified, ultimately becoming a sedimentary rock. Sedimentary rock may also be re-eroded and redeposited, and metamorphic rock may also undergo additional metamorphism. All three types of rocks may be re-melted; when this happens, a new magma is formed, from which an igneous rock may once again crystallize.\n",
      "Input Question:  An igneous rock is a rock that crystallizes from what?\n",
      "Model Response:  melt\n",
      "Actual Answer:  melt (magma and/or lava)\n",
      "\n",
      "Input Question:  Sedimentary rock can be turned into which of the three types of rock?\n",
      "Model Response:  metamorphic rock\n",
      "Actual Answer:  metamorphic rock\n",
      "\n",
      "Input Question:  When the three types of rock are re-melted what is formed? \n",
      "Model Response:  magma\n",
      "Actual Answer:  new magma\n",
      "\n",
      "Input Question:  What are the three major types of rock? \n",
      "Model Response:  igneous, sedimentary, and metamorphic\n",
      "Actual Answer:  igneous, sedimentary, and metamorphic\n",
      "\n",
      "Input Question:  What changes the mineral content of a rock?\n",
      "Model Response:  heat and pressure\n",
      "Actual Answer:  heat and pressure\n",
      "\n",
      "Newcastle upon Tyne (RP: i/ˌnjuːkɑːsəl əˌpɒn ˈtaɪn/; Locally: i/njuːˌkæsəl əˌpən ˈtaɪn/), commonly known as Newcastle, is a city in Tyne and Wear, North East England, 103 miles (166 km) south of Edinburgh and 277 miles (446 km) north of London on the northern bank of the River Tyne, 8.5 mi (13.7 km) from the North Sea. Newcastle is the most populous city in the North East and Tyneside the eighth most populous conurbation in the United Kingdom. Newcastle is a member of the English Core Cities Group and is a member of the Eurocities network of European cities. Newcastle was part of the county of Northumberland until 1400, when it became a county itself, a status it retained until becoming part of Tyne and Wear in 1974.[not in citation given] The regional nickname and dialect for people from Newcastle and the surrounding area is Geordie.\n",
      "Input Question:  How many miles south of Edinburgh is Newcastle?\n",
      "Model Response:  103\n",
      "Actual Answer:  103 miles\n",
      "\n",
      "Input Question:  How many miles from the north Sea is Newcastle?\n",
      "Model Response:  8. 5\n",
      "Actual Answer:  8.5 mi\n",
      "\n",
      "Input Question:  What network is Newcastle a member of?\n",
      "Model Response:  eurocities network of european cities\n",
      "Actual Answer:  Eurocities\n",
      "\n",
      "Input Question:  What county was Newcastle a part of until 1400?\n",
      "Model Response:  northumberland\n",
      "Actual Answer:  Northumberland\n",
      "\n",
      "Input Question:  What's the regional nickname for Newcastle and its surrounding area?\n",
      "Model Response:  geordie\n",
      "Actual Answer:  Geordie\n",
      "\n",
      "The Victoria and Albert Museum (often abbreviated as the V&A), London, is the world's largest museum of decorative arts and design, housing a permanent collection of over 4.5 million objects. It was founded in 1852 and named after Queen Victoria and Prince Albert. The V&A is located in the Brompton district of the Royal Borough of Kensington and Chelsea, in an area that has become known as \"Albertopolis\" because of its association with Prince Albert, the Albert Memorial and the major cultural institutions with which he was associated. These include the Natural History Museum, the Science Museum and the Royal Albert Hall. The museum is a non-departmental public body sponsored by the Department for Culture, Media and Sport. Like other national British museums, entrance to the museum has been free since 2001.\n",
      "Input Question:  where is the Victoria and Albert Museum located?\n",
      "Model Response:  london\n",
      "Actual Answer:  The V&A is located in the Brompton district of the Royal Borough of Kensington and Chelsea\n",
      "\n",
      "Input Question:  how many permanent objects are located there?\n",
      "Model Response:  4. 5 million\n",
      "Actual Answer:  a permanent collection of over 4.5 million objects.\n",
      "\n",
      "Input Question:  when was the Victoria and Albert museum founded?\n",
      "Model Response:  1852\n",
      "Actual Answer:  It was founded in 1852\n",
      "\n",
      "Input Question:  Who is the museum named for?\n",
      "Model Response:  queen victoria and prince albert\n",
      "Actual Answer:  named after Queen Victoria and Prince Albert\n",
      "\n",
      "Input Question:  In which London borough is the Victoria and Albert Museum located?\n",
      "Model Response:  kensington and chelsea\n",
      "Actual Answer:  Royal Borough of Kensington and Chelsea\n",
      "\n",
      "Input Question:  In what year was the Victoria and Albert Museum founded?\n",
      "Model Response:  1852\n",
      "Actual Answer:  1852\n",
      "\n",
      "Input Question:  Which monarchs was the Victoria and Albert Museum named after?\n",
      "Model Response:  queen victoria and prince albert\n",
      "Actual Answer:  Queen Victoria and Prince Albert\n",
      "\n",
      "Input Question:  Which department sponsors the Victoria and Albert Museum?\n",
      "Model Response:  department for culture, media and sport\n",
      "Actual Answer:  Department for Culture, Media and Sport\n",
      "\n",
      "Input Question:  In which year did the museum started charging free admission fees?\n",
      "Model Response:  2001\n",
      "Actual Answer:  2001\n",
      "\n",
      "The American Broadcasting Company (ABC) (stylized in its logo as abc since 1957) is an American commercial broadcast television network that is owned by the Disney–ABC Television Group, a subsidiary of Disney Media Networks division of The Walt Disney Company. The network is part of the Big Three television networks. The network is headquartered on Columbus Avenue and West 66th Street in Manhattan, with additional major offices and production facilities in New York City, Los Angeles and Burbank, California.\n",
      "Input Question:  What company owns the American Broadcasting Company?\n",
      "Model Response:  disney – abc television group\n",
      "Actual Answer:  The Walt Disney Company\n",
      "\n",
      "Input Question:  In what year did ABC stylize it's logo as abc?\n",
      "Model Response:  1957\n",
      "Actual Answer:  1957\n",
      "\n",
      "Input Question:  In what borough of New York City is ABC headquartered?\n",
      "Model Response:  manhattan\n",
      "Actual Answer:  Manhattan\n",
      "\n",
      "Input Question:  On what streets is the ABC headquarters located\n",
      "Model Response:  columbus avenue and west 66th street\n",
      "Actual Answer:  Columbus Avenue and West 66th Street\n",
      "\n",
      "Input Question:  Disney-ABC Television Group is a subsidiary of what division of the Walt Disney Company?\n",
      "Model Response:  disney media networks\n",
      "Actual Answer:  Disney Media Networks\n",
      "\n",
      "He came to power by uniting many of the nomadic tribes of Northeast Asia. After founding the Mongol Empire and being proclaimed \"Genghis Khan\", he started the Mongol invasions that resulted in the conquest of most of Eurasia. These included raids or invasions of the Qara Khitai, Caucasus, Khwarezmid Empire, Western Xia and Jin dynasties. These campaigns were often accompanied by wholesale massacres of the civilian populations – especially in the Khwarezmian and Xia controlled lands. By the end of his life, the Mongol Empire occupied a substantial portion of Central Asia and China.\n",
      "Input Question:  What do we call the empire that Genghis Khan founded?\n",
      "Model Response:  the mongol empire\n",
      "Actual Answer:  the Mongol Empire\n",
      "\n",
      "Input Question:  Who did Genghis Khan unite before he began conquering the rest of Eurasia?\n",
      "Model Response:  nomadic tribes of northeast asia\n",
      "Actual Answer:  many of the nomadic tribes of Northeast Asia\n",
      "\n",
      "Input Question:  In which regions in particular did Genghis Khan's armies massacre civilians?\n",
      "Model Response:  khwarezmian and xia\n",
      "Actual Answer:  Khwarezmian and Xia controlled lands\n",
      "\n",
      "Input Question:  What areas did Genghis Khan control at the end of his life?\n",
      "Model Response:  khwarezmian and xia controlled lands. by the end of his life, the mongol empire occupied a substantial portion of central asia and china\n",
      "Actual Answer:  a substantial portion of Central Asia and China\n",
      "\n",
      "Input Question:  Which other empires or dynasties did Genghis Khan conquer?\n",
      "Model Response:  qara khitai, caucasus, khwarezmid empire, western xia and jin dynasties\n",
      "Actual Answer:  the Qara Khitai, Caucasus, Khwarezmid Empire, Western Xia and Jin dynasties\n",
      "\n",
      "The word pharmacy is derived from its root word pharma which was a term used since the 15th–17th centuries. However, the original Greek roots from pharmakos imply sorcery or even poison. In addition to pharma responsibilities, the pharma offered general medical advice and a range of services that are now performed solely by other specialist practitioners, such as surgery and midwifery. The pharma (as it was referred to) often operated through a retail shop which, in addition to ingredients for medicines, sold tobacco and patent medicines. Often the place that did this was called an apothecary and several languages have this as the dominant term, though their practices are more akin to a modern pharmacy, in English the term apothecary would today be seen as outdated or only approproriate if herbal remedies were on offer to a large extent. The pharmas also used many other herbs not listed. The Greek word Pharmakeia (Greek: φαρμακεία) derives from pharmakon (φάρμακον), meaning \"drug\", \"medicine\" (or \"poison\").[n 1]\n",
      "Input Question:  What word is the word pharmacy taken from?\n",
      "Model Response:  pharma\n",
      "Actual Answer:  its root word pharma\n",
      "\n",
      "Input Question:  What goods were sold in a pharma?\n",
      "Model Response:  tobacco and patent medicines\n",
      "Actual Answer:  ingredients for medicines, sold tobacco and patent medicines\n",
      "\n",
      "Input Question:  What did the Greek root pharmakos imply?\n",
      "Model Response:  sorcery or even poison\n",
      "Actual Answer:  sorcery or even poison\n",
      "\n",
      "Input Question:  How would the word apothecary be viewed by contemporary English speakers?\n",
      "Model Response:  outdated or only approproriate\n",
      "Actual Answer:  outdated or only approproriate if herbal remedies were on offer to a large extent\n",
      "\n",
      "Input Question:  What else was used by pharmas?\n",
      "Model Response:  many other herbs\n",
      "Actual Answer:  many other herbs not listed\n",
      "\n",
      "The immune system is a system of many biological structures and processes within an organism that protects against disease. To function properly, an immune system must detect a wide variety of agents, known as pathogens, from viruses to parasitic worms, and distinguish them from the organism's own healthy tissue. In many species, the immune system can be classified into subsystems, such as the innate immune system versus the adaptive immune system, or humoral immunity versus cell-mediated immunity. In humans, the blood–brain barrier, blood–cerebrospinal fluid barrier, and similar fluid–brain barriers separate the peripheral immune system from the neuroimmune system which protects the brain.\n",
      "Input Question:  What is the immune system?\n",
      "Model Response:  a system of many biological structures and processes within an organism that protects against disease\n",
      "Actual Answer:  a system of many biological structures and processes within an organism that protects against disease\n",
      "\n",
      "Input Question:  What does the immune system protect against?\n",
      "Model Response:  disease\n",
      "Actual Answer:  a wide variety of agents, known as pathogens, from viruses to parasitic worms\n",
      "\n",
      "Input Question:  What are two of its subsystems?\n",
      "Model Response:  innate immune system versus the adaptive immune system, or humoral immunity versus cell - mediated immunity\n",
      "Actual Answer:  the innate immune system versus the adaptive immune system\n",
      "\n",
      "Input Question:  What is the subsystem that protects the human brain?\n",
      "Model Response:  neuroimmune system\n",
      "Actual Answer:  the neuroimmune system\n",
      "\n",
      "Input Question:  What is the immune system?\n",
      "Model Response:  a system of many biological structures and processes within an organism that protects against disease\n",
      "Actual Answer:  biological structures and processes within an organism\n",
      "\n",
      "Input Question:  What does the immune system protect against?\n",
      "Model Response:  disease\n",
      "Actual Answer:  pathogens, from viruses to parasitic worms\n",
      "\n",
      "Input Question:  What are two of its subsystems?\n",
      "Model Response:  innate immune system versus the adaptive immune system, or humoral immunity versus cell - mediated immunity\n",
      "Actual Answer:  innate immune system versus the adaptive immune system\n",
      "\n",
      "Input Question:  The immune system protects organisms against what?\n",
      "Model Response:  disease\n",
      "Actual Answer:  disease\n",
      "\n",
      "Input Question:  What are the agents the immune system detects known as?\n",
      "Model Response:  pathogens\n",
      "Actual Answer:  pathogens\n",
      "\n",
      "Input Question:  Which part of the immune system protects the brain?\n",
      "Model Response:  neuroimmune system\n",
      "Actual Answer:  neuroimmune system\n",
      "\n",
      "Input Question:  What separates the neuroimmune system and peripheral immune system in humans?\n",
      "Model Response:  the blood – brain barrier, blood – cerebrospinal fluid barrier, and similar fluid – brain barriers\n",
      "Actual Answer:  blood–brain barrier, blood–cerebrospinal fluid barrier\n",
      "\n",
      "Input Question:  What are the agents detected by the immune system called?\n",
      "Model Response:  pathogens\n",
      "Actual Answer:  pathogens\n",
      "\n",
      "Input Question:  What are the two major subsystems of the immune system?\n",
      "Model Response:  innate immune system versus the adaptive immune system, or humoral immunity versus cell - mediated immunity\n",
      "Actual Answer:  innate immune system versus the adaptive immune system\n",
      "\n",
      "Input Question:  What are the two different types of immunity?\n",
      "Model Response:  humoral\n",
      "Actual Answer:  humoral immunity versus cell-mediated immunity\n",
      "\n",
      "Input Question:  What is the immune system of the brained known as?\n",
      "Model Response:  neuroimmune system\n",
      "Actual Answer:  neuroimmune system\n",
      "\n",
      "One of its earliest massive implementations was brought about by Egyptians against the British occupation in the 1919 Revolution. Civil disobedience is one of the many ways people have rebelled against what they deem to be unfair laws. It has been used in many nonviolent resistance movements in India (Gandhi's campaigns for independence from the British Empire), in Czechoslovakia's Velvet Revolution and in East Germany to oust their communist governments, In South Africa in the fight against apartheid, in the American Civil Rights Movement, in the Singing Revolution to bring independence to the Baltic countries from the Soviet Union, recently with the 2003 Rose Revolution in Georgia and the 2004 Orange Revolution in Ukraine, among other various movements worldwide.\n",
      "Input Question:  What is it called when people in society rebel against laws they think are unfair?\n",
      "Model Response:  civil disobedience\n",
      "Actual Answer:  Civil disobedience\n",
      "\n",
      "Input Question:  What is an example of major civil disobedience in South Africa?\n",
      "Model Response:  fight against apartheid\n",
      "Actual Answer:  apartheid\n",
      "\n",
      "Input Question:  What was the the movement called that brought Baltic countries independence from the Soviet Union?\n",
      "Model Response:  singing revolution\n",
      "Actual Answer:  Singing Revolution\n",
      "\n",
      "Input Question:  In 2004 the Orange revolution occurred in what country?\n",
      "Model Response:  ukraine\n",
      "Actual Answer:  Ukraine\n",
      "\n",
      "Input Question:  Where was the location of the 2003 Rose revolution?\n",
      "Model Response:  georgia\n",
      "Actual Answer:  Georgia\n",
      "\n",
      "Input Question:  Which people brought forward one of the earliest examples of Civil Disobedience?\n",
      "Model Response:  egyptians\n",
      "Actual Answer:  Egyptians\n",
      "\n",
      "Input Question:  Who was one of the earliest examples of Civil Disobedience against?\n",
      "Model Response:  british occupation\n",
      "Actual Answer:  the British\n",
      "\n",
      "Input Question:  Why do people chose civil disobedience to protest?\n",
      "Model Response:  unfair laws\n",
      "Actual Answer:  nonviolent resistance\n",
      "\n",
      "Input Question:  What does civil disobedience protest against?\n",
      "Model Response:  unfair laws\n",
      "Actual Answer:  unfair laws\n",
      "\n",
      "Input Question:  What civil rights movement in the US was known for it's disobedience?\n",
      "Model Response:  singing revolution to bring independence to the baltic countries from the soviet union\n",
      "Actual Answer:  American Civil Rights Movement\n",
      "\n",
      "Construction is the process of constructing a building or infrastructure. Construction differs from manufacturing in that manufacturing typically involves mass production of similar items without a designated purchaser, while construction typically takes place on location for a known client. Construction as an industry comprises six to nine percent of the gross domestic product of developed countries. Construction starts with planning,[citation needed] design, and financing and continues until the project is built and ready for use.\n",
      "Input Question:  What is the process of constructing a building or infrastructure?\n",
      "Model Response:  construction\n",
      "Actual Answer:  Construction\n",
      "\n",
      "Input Question:  What typically involves mass production of similar items without a designated purchaser?\n",
      "Model Response:  manufacturing\n",
      "Actual Answer:  manufacturing\n",
      "\n",
      "Input Question:  What percentile of gross domestic product is construction comprised of?\n",
      "Model Response:  six to nine percent\n",
      "Actual Answer:  six to nine percent\n",
      "\n",
      "Input Question:  What three things are needed for construction to take place?\n",
      "Model Response:  planning, [ citation needed ] design, and financing\n",
      "Actual Answer:  planning,[citation needed] design, and financing\n",
      "\n",
      "Input Question:  Construction takes place on location for who?\n",
      "Model Response:  a known client\n",
      "Actual Answer:  a known client\n",
      "\n",
      "Private schools, also known as independent schools, non-governmental, or nonstate schools, are not administered by local, state or national governments; thus, they retain the right to select their students and are funded in whole or in part by charging their students tuition, rather than relying on mandatory taxation through public (government) funding; at some private schools students may be able to get a scholarship, which makes the cost cheaper, depending on a talent the student may have (e.g. sport scholarship, art scholarship, academic scholarship), financial need, or tax credit scholarships that might be available.\n",
      "Input Question:  Along with non-governmental and nonstate schools, what is another name for private schools?\n",
      "Model Response:  independent schools\n",
      "Actual Answer:  independent\n",
      "\n",
      "Input Question:  Along with sport and art, what is a type of talent scholarship?\n",
      "Model Response:  academic scholarship\n",
      "Actual Answer:  academic\n",
      "\n",
      "Input Question:  Rather than taxation, what are private schools largely funded by?\n",
      "Model Response:  public ( government ) funding\n",
      "Actual Answer:  tuition\n",
      "\n",
      "Input Question:  What right do private schools have that public schools don't?\n",
      "Model Response:  right to select their students\n",
      "Actual Answer:  to select their students\n",
      "\n",
      "Established originally by the Massachusetts legislature and soon thereafter named for John Harvard (its first benefactor), Harvard is the United States' oldest institution of higher learning, and the Harvard Corporation (formally, the President and Fellows of Harvard College) is its first chartered corporation. Although never formally affiliated with any denomination, the early College primarily trained Congregationalist and Unitarian clergy. Its curriculum and student body were gradually secularized during the 18th century, and by the 19th century Harvard had emerged as the central cultural establishment among Boston elites. Following the American Civil War, President Charles W. Eliot's long tenure (1869–1909) transformed the college and affiliated professional schools into a modern research university; Harvard was a founding member of the Association of American Universities in 1900. James Bryant Conant led the university through the Great Depression and World War II and began to reform the curriculum and liberalize admissions after the war. The undergraduate college became coeducational after its 1977 merger with Radcliffe College.\n",
      "Input Question:  What individual is the school named after?\n",
      "Model Response:  john harvard\n",
      "Actual Answer:  John Harvard\n",
      "\n",
      "Input Question:  When did the undergraduate program become coeducational?\n",
      "Model Response:  1977\n",
      "Actual Answer:  1977\n",
      "\n",
      "Input Question:  What was the name of the leader through the Great Depression and World War II?\n",
      "Model Response:  james bryant conant\n",
      "Actual Answer:  James Bryant Conant\n",
      "\n",
      "Input Question:  What organization did Harvard found in 1900?\n",
      "Model Response:  association of american universities\n",
      "Actual Answer:  Association of American Universities\n",
      "\n",
      "Input Question:  What president of the university transformed it into a modern research university?\n",
      "Model Response:  charles w. eliot\n",
      "Actual Answer:  Charles W. Eliot\n",
      "\n",
      "Jacksonville is the largest city by population in the U.S. state of Florida, and the largest city by area in the contiguous United States. It is the county seat of Duval County, with which the city government consolidated in 1968. Consolidation gave Jacksonville its great size and placed most of its metropolitan population within the city limits; with an estimated population of 853,382 in 2014, it is the most populous city proper in Florida and the Southeast, and the 12th most populous in the United States. Jacksonville is the principal city in the Jacksonville metropolitan area, with a population of 1,345,596 in 2010.\n",
      "Input Question:  Which Florida city has the biggest population?\n",
      "Model Response:  jacksonville\n",
      "Actual Answer:  Jacksonville\n",
      "\n",
      "Input Question:  What was the population Jacksonville city as of 2010?\n",
      "Model Response:  1, 345, 596\n",
      "Actual Answer:  1,345,596\n",
      "\n",
      "Input Question:  Based on population alone, what is Jacksonville's ranking in the United States?\n",
      "Model Response:  12th\n",
      "Actual Answer:  12th\n",
      "\n",
      "Input Question:  In which county does Jacksonville reside?\n",
      "Model Response:  duval county\n",
      "Actual Answer:  Duval\n",
      "\n",
      "Input Question:  What year did consolidation cause Jacksonville to become part of Duval County?\n",
      "Model Response:  1968\n",
      "Actual Answer:  1968\n",
      "\n",
      "A study by the World Institute for Development Economics Research at United Nations University reports that the richest 1% of adults alone owned 40% of global assets in the year 2000. The three richest people in the world possess more financial assets than the lowest 48 nations combined. The combined wealth of the \"10 million dollar millionaires\" grew to nearly $41 trillion in 2008. A January 2014 report by Oxfam claims that the 85 wealthiest individuals in the world have a combined wealth equal to that of the bottom 50% of the world's population, or about 3.5 billion people. According to a Los Angeles Times analysis of the report, the wealthiest 1% owns 46% of the world's wealth; the 85 richest people, a small part of the wealthiest 1%, own about 0.7% of the human population's wealth, which is the same as the bottom half of the population. More recently, in January 2015, Oxfam reported that the wealthiest 1 percent will own more than half of the global wealth by 2016. An October 2014 study by Credit Suisse also claims that the top 1% now own nearly half of the world's wealth and that the accelerating disparity could trigger a recession. In October 2015, Credit Suisse published a study which shows global inequality continues to increase, and that half of the world's wealth is now in the hands of those in the top percentile, whose assets each exceed $759,900. A 2016 report by Oxfam claims that the 62 wealthiest individuals own as much wealth as the poorer half of the global population combined. Oxfam's claims have however been questioned on the basis of the methodology used: by using net wealth (adding up assets and subtracting debts), the Oxfam report, for instance, finds that there are more poor people in the United States and Western Europe than in China (due to a greater tendency to take on debts).[unreliable source?][unreliable source?] Anthony Shorrocks, the lead author of the Credit Suisse report which is one of the sources of Oxfam's data, considers the criticism about debt to be a \"silly argument\" and \"a non-issue . . . a diversion.\"\n",
      "Input Question:  What percentage of global assets does the richest 1% of people have?\n",
      "Model Response:  40 %\n",
      "Actual Answer:  40%\n",
      "\n",
      "Input Question:  According to Oxfam, the 85 richest people have wealth equal to how many average people?\n",
      "Model Response:  3. 5 billion\n",
      "Actual Answer:  about 3.5 billion people\n",
      "\n",
      "Input Question:  In order to be considered in the top percentile, a person would need to amass how much money each year?\n",
      "Model Response:  $ 759, 900\n",
      "Actual Answer:  $759,900\n",
      "\n",
      "Input Question:  What has caused Oxfam's findings to be questioned?\n",
      "Model Response:  \n",
      "Actual Answer:  the methodology used\n",
      "\n",
      "Input Question:  Why does Oxfam and Credit Suisse believe their findings are being doubted?\n",
      "Model Response:  \n",
      "Actual Answer:  a diversion\n",
      "\n",
      "Input Question:  What percent of the global assets in 2000 were owned by just 1% of adults?\n",
      "Model Response:  40 %\n",
      "Actual Answer:  40%\n",
      "\n",
      "Input Question:  What do the three richest people in the world posses more of than the lowest 48 nations together?\n",
      "Model Response:  financial assets\n",
      "Actual Answer:  financial assets\n",
      "\n",
      "Input Question:  How much was the combined wealth of the \"10 Million dollar millionaires\" in 2008?\n",
      "Model Response:  $ 41 trillion\n",
      "Actual Answer:  nearly $41 trillion\n",
      "\n",
      "Input Question:  How much of the global wealth will the wealthiest 1 percent own by 2016?\n",
      "Model Response:  more than half\n",
      "Actual Answer:  half\n",
      "\n",
      "Input Question:  Why are there more poor people in the United States and Europe than China?\n",
      "Model Response:  greater tendency to take on debts\n",
      "Actual Answer:  greater tendency to take on debts\n",
      "\n",
      "Doctor Who is a British science-fiction television programme produced by the BBC since 1963. The programme depicts the adventures of the Doctor, a Time Lord—a space and time-travelling humanoid alien. He explores the universe in his TARDIS, a sentient time-travelling space ship. Its exterior appears as a blue British police box, which was a common sight in Britain in 1963 when the series first aired. Accompanied by companions, the Doctor combats a variety of foes, while working to save civilisations and help people in need.\n",
      "Input Question:  Who is the producer of Doctor Who?\n",
      "Model Response:  bbc\n",
      "Actual Answer:  BBC\n",
      "\n",
      "Input Question:  What year did Doctor Who first show on TV?\n",
      "Model Response:  1963\n",
      "Actual Answer:  1963\n",
      "\n",
      "Input Question:  What is Doctor Who's space ship called?\n",
      "Model Response:  tardis\n",
      "Actual Answer:  TARDIS\n",
      "\n",
      "Input Question:  What does the outside of the Tardis resemble?\n",
      "Model Response:  blue british police box\n",
      "Actual Answer:  a blue British police box\n",
      "\n",
      "Input Question:  What type/genre of TV show is Doctor Who?\n",
      "Model Response:  science - fiction\n",
      "Actual Answer:  science-fiction\n",
      "\n",
      "The University of Chicago (UChicago, Chicago, or U of C) is a private research university in Chicago. The university, established in 1890, consists of The College, various graduate programs, interdisciplinary committees organized into four academic research divisions and seven professional schools. Beyond the arts and sciences, Chicago is also well known for its professional schools, which include the Pritzker School of Medicine, the University of Chicago Booth School of Business, the Law School, the School of Social Service Administration, the Harris School of Public Policy Studies, the Graham School of Continuing Liberal and Professional Studies and the Divinity School. The university currently enrolls approximately 5,000 students in the College and around 15,000 students overall.\n",
      "Input Question:  What kind of university is the University of Chicago?\n",
      "Model Response:  private research\n",
      "Actual Answer:  a private research university\n",
      "\n",
      "Input Question:  When was the University of Chicago established?\n",
      "Model Response:  1890\n",
      "Actual Answer:  1890\n",
      "\n",
      "Input Question:  How many professional schools does the University of Chicago have?\n",
      "Model Response:  seven\n",
      "Actual Answer:  seven\n",
      "\n",
      "Input Question:  How many academic research divisions does the University of Chicago have?\n",
      "Model Response:  four\n",
      "Actual Answer:  four\n",
      "\n",
      "Input Question:  How many students does the University of Chicago have enlisted?\n",
      "Model Response:  15, 000\n",
      "Actual Answer:  5,000\n",
      "\n",
      "The Yuan dynasty (Chinese: 元朝; pinyin: Yuán Cháo), officially the Great Yuan (Chinese: 大元; pinyin: Dà Yuán; Mongolian: Yehe Yuan Ulus[a]), was the empire or ruling dynasty of China established by Kublai Khan, leader of the Mongolian Borjigin clan. Although the Mongols had ruled territories including today's North China for decades, it was not until 1271 that Kublai Khan officially proclaimed the dynasty in the traditional Chinese style. His realm was, by this point, isolated from the other khanates and controlled most of present-day China and its surrounding areas, including modern Mongolia and Korea. It was the first foreign dynasty to rule all of China and lasted until 1368, after which its Genghisid rulers returned to their Mongolian homeland and continued to rule the Northern Yuan dynasty. Some of the Mongolian Emperors of the Yuan mastered the Chinese language, while others only used their native language (i.e. Mongolian) and the 'Phags-pa script.\n",
      "Input Question:  What is the Chinese name for the Yuan dynasty?\n",
      "Model Response:  great yuan\n",
      "Actual Answer:  Yuán Cháo\n",
      "\n",
      "Input Question:  What is the Yuan dynasty's official name?\n",
      "Model Response:  great yuan\n",
      "Actual Answer:  the Great Yuan\n",
      "\n",
      "Input Question:  Who started the Yuan dynasty?\n",
      "Model Response:  kublai khan\n",
      "Actual Answer:  Kublai Khan\n",
      "\n",
      "Input Question:  Who led the Mongolian Borjigin clan?\n",
      "Model Response:  kublai khan\n",
      "Actual Answer:  Kublai Khan\n",
      "\n",
      "Input Question:  When did Khan formally declare the Yuan dynasty?\n",
      "Model Response:  1271\n",
      "Actual Answer:  1271\n",
      "\n",
      "Kenya (/ˈkɛnjə/; locally [ˈkɛɲa] ( listen)), officially the Republic of Kenya, is a country in Africa and a founding member of the East African Community (EAC). Its capital and largest city is Nairobi. Kenya's territory lies on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana (formerly called Lake Rudolf) and further south-east to the Indian Ocean. It is bordered by Tanzania to the south, Uganda to the west, South Sudan to the north-west, Ethiopia to the north and Somalia to the north-east. Kenya covers 581,309 km2 (224,445 sq mi), and had a population of approximately 45 million people in July 2014.\n",
      "Input Question:  Where is Kenya located?\n",
      "Model Response:  africa\n",
      "Actual Answer:  in Africa\n",
      "\n",
      "Input Question:  What is Kenya a founding member of?\n",
      "Model Response:  east african community\n",
      "Actual Answer:  East African Community\n",
      "\n",
      "Input Question:  What is the capitol of Kenya?\n",
      "Model Response:  nairobi\n",
      "Actual Answer:  Nairobi\n",
      "\n",
      "Input Question:  What country boarders the south of Kenya?\n",
      "Model Response:  tanzania\n",
      "Actual Answer:  Tanzania\n",
      "\n",
      "Input Question:  What was the population of Kenya in 2014?\n",
      "Model Response:  45 million\n",
      "Actual Answer:  45 million people\n",
      "\n",
      "The Intergovernmental Panel on Climate Change (IPCC) is a scientific intergovernmental body under the auspices of the United Nations, set up at the request of member governments. It was first established in 1988 by two United Nations organizations, the World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP), and later endorsed by the United Nations General Assembly through Resolution 43/53. Membership of the IPCC is open to all members of the WMO and UNEP. The IPCC produces reports that support the United Nations Framework Convention on Climate Change (UNFCCC), which is the main international treaty on climate change. The ultimate objective of the UNFCCC is to \"stabilize greenhouse gas concentrations in the atmosphere at a level that would prevent dangerous anthropogenic [i.e., human-induced] interference with the climate system\". IPCC reports cover \"the scientific, technical and socio-economic information relevant to understanding the scientific basis of risk of human-induced climate change, its potential impacts and options for adaptation and mitigation.\"\n",
      "Input Question:  What organization is the IPCC a part of?\n",
      "Model Response:  united nations\n",
      "Actual Answer:  the United Nations\n",
      "\n",
      "Input Question:  What UN organizations established the IPCC?\n",
      "Model Response:  the world meteorological organization ( wmo ) and the united nations environment programme ( unep )\n",
      "Actual Answer:  the World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP)\n",
      "\n",
      "Input Question:  What does the UN want to stabilize?\n",
      "Model Response:  greenhouse gas concentrations in the atmosphere\n",
      "Actual Answer:  greenhouse gas concentrations in the atmosphere\n",
      "\n",
      "Input Question:  What is the UN's climate change treaty?\n",
      "Model Response:  united nations framework convention on climate change\n",
      "Actual Answer:  United Nations Framework Convention on Climate Change\n",
      "\n",
      "Input Question:  What UN resolution endorsed the IPCC?\n",
      "Model Response:  resolution 43 / 53\n",
      "Actual Answer:  Resolution 43/53\n",
      "\n",
      "Chloroplasts' main role is to conduct photosynthesis, where the photosynthetic pigment chlorophyll captures the energy from sunlight and converts it and stores it in the energy-storage molecules ATP and NADPH while freeing oxygen from water. They then use the ATP and NADPH to make organic molecules from carbon dioxide in a process known as the Calvin cycle. Chloroplasts carry out a number of other functions, including fatty acid synthesis, much amino acid synthesis, and the immune response in plants. The number of chloroplasts per cell varies from 1 in algae up to 100 in plants like Arabidopsis and wheat.\n",
      "Input Question:  What is the primary purpose of chloroplasts?\n",
      "Model Response:  conduct photosynthesis\n",
      "Actual Answer:  to conduct photosynthesis\n",
      "\n",
      "Input Question:  What does ATP store?\n",
      "Model Response:  nadph\n",
      "Actual Answer:  energy\n",
      "\n",
      "Input Question:  What does NADPH store?\n",
      "Model Response:  atp\n",
      "Actual Answer:  energy\n",
      "\n",
      "Input Question:  What is the process of turning CO2 into organic molecules called?\n",
      "Model Response:  calvin cycle\n",
      "Actual Answer:  the Calvin cycle\n",
      "\n",
      "Input Question:  How many chloroplasts per cell does algae have?\n",
      "Model Response:  1\n",
      "Actual Answer:  1\n",
      "\n",
      "A prime number (or a prime) is a natural number greater than 1 that has no positive divisors other than 1 and itself. A natural number greater than 1 that is not a prime number is called a composite number. For example, 5 is prime because 1 and 5 are its only positive integer factors, whereas 6 is composite because it has the divisors 2 and 3 in addition to 1 and 6. The fundamental theorem of arithmetic establishes the central role of primes in number theory: any integer greater than 1 can be expressed as a product of primes that is unique up to ordering. The uniqueness in this theorem requires excluding 1 as a prime because one can include arbitrarily many instances of 1 in any factorization, e.g., 3, 1 · 3, 1 · 1 · 3, etc. are all valid factorizations of 3.\n",
      "Input Question:  What is the only divisor besides 1 that a prime number can have?\n",
      "Model Response:  1 and itself\n",
      "Actual Answer:  itself\n",
      "\n",
      "Input Question:  What are numbers greater than 1 that can be divided by 3 or more numbers called?\n",
      "Model Response:  composite number\n",
      "Actual Answer:  composite number\n",
      "\n",
      "Input Question:  What theorem defines the main role of primes in number theory?\n",
      "Model Response:  the fundamental theorem of arithmetic\n",
      "Actual Answer:  The fundamental theorem of arithmetic\n",
      "\n",
      "Input Question:  Any number larger than 1 can be represented as a product of what?\n",
      "Model Response:  primes that is unique up to ordering\n",
      "Actual Answer:  a product of primes\n",
      "\n",
      "Input Question:  Why must one be excluded in order to preserve the uniqueness of the fundamental theorem?\n",
      "Model Response:  one can include arbitrarily many instances of 1 in any factorization\n",
      "Actual Answer:  because one can include arbitrarily many instances of 1 in any factorization\n",
      "\n",
      "The Rhine (Romansh: Rein, German: Rhein, French: le Rhin, Dutch: Rijn) is a European river that begins in the Swiss canton of Graubünden in the southeastern Swiss Alps, forms part of the Swiss-Austrian, Swiss-Liechtenstein border, Swiss-German and then the Franco-German border, then flows through the Rhineland and eventually empties into the North Sea in the Netherlands. The biggest city on the river Rhine is Cologne, Germany with a population of more than 1,050,000 people. It is the second-longest river in Central and Western Europe (after the Danube), at about 1,230 km (760 mi),[note 2][note 1] with an average discharge of about 2,900 m3/s (100,000 cu ft/s).\n",
      "Input Question:  Where does the Rhine begin? \n",
      "Model Response:  swiss canton of graubunden\n",
      "Actual Answer:  Swiss canton\n",
      "\n",
      "Input Question:  Where does the Rhine empty?\n",
      "Model Response:  north sea\n",
      "Actual Answer:  North Sea\n",
      "\n",
      "Input Question:  What is the largest city the Rhine runs through? \n",
      "Model Response:  cologne\n",
      "Actual Answer:  Cologne, Germany\n",
      "\n",
      "Input Question:  What river is larger than the Rhine?\n",
      "Model Response:  the danube\n",
      "Actual Answer:  Danube\n",
      "\n",
      "Input Question:  How long is the Rhine?\n",
      "Model Response:  1, 230 km\n",
      "Actual Answer:  1,230 km (760 mi)\n",
      "\n",
      "Input Question:  Where is the Rhine? \n",
      "Model Response:  swiss canton of graubunden in the southeastern swiss alps\n",
      "Actual Answer:  Europe\n",
      "\n",
      "Input Question:  What country does the Rhine empty?\n",
      "Model Response:  the netherlands\n",
      "Actual Answer:  Netherlands\n",
      "\n",
      "Input Question:  How long is the Rhine? \n",
      "Model Response:  1, 230 km\n",
      "Actual Answer:  1,230 km\n",
      "\n",
      "Following a referendum in 1997, in which the Scottish electorate voted for devolution, the current Parliament was convened by the Scotland Act 1998, which sets out its powers as a devolved legislature. The Act delineates the legislative competence of the Parliament – the areas in which it can make laws – by explicitly specifying powers that are \"reserved\" to the Parliament of the United Kingdom. The Scottish Parliament has the power to legislate in all areas that are not explicitly reserved to Westminster. The British Parliament retains the ability to amend the terms of reference of the Scottish Parliament, and can extend or reduce the areas in which it can make laws. The first meeting of the new Parliament took place on 12 May 1999.\n",
      "Input Question:  When was the current parliament of Scotland convened?\n",
      "Model Response:  \n",
      "Actual Answer:  Following a referendum in 1997\n",
      "\n",
      "Input Question:  What act set out the Parliament's powers as a devolved legislature?\n",
      "Model Response:  scotland act 1998\n",
      "Actual Answer:  Scotland Act 1998\n",
      "\n",
      "Input Question:  The legislative competence of the Parliament species what areas?\n",
      "Model Response:  the areas in which it can make laws\n",
      "Actual Answer:  in which it can make laws\n",
      "\n",
      "Input Question:  To what body are certain powers explicitly specified as being reserved for?\n",
      "Model Response:  parliament of the united kingdom\n",
      "Actual Answer:  Parliament of the United Kingdom\n",
      "\n",
      "Input Question:  The Scottish Parliament may legislate as it pleases as long as the powers aren't already reserved by where?\n",
      "Model Response:  westminster\n",
      "Actual Answer:  Westminster\n",
      "\n",
      "Islamism, also known as Political Islam (Arabic: إسلام سياسي‎ islām siyāsī), is an Islamic revival movement often characterized by moral conservatism, literalism, and the attempt \"to implement Islamic values in all spheres of life.\" Islamism favors the reordering of government and society in accordance with the Shari'a. The different Islamist movements have been described as \"oscillating between two poles\": at one end is a strategy of Islamization of society through state power seized by revolution or invasion; at the other \"reformist\" pole Islamists work to Islamize society gradually \"from the bottom up\". The movements have \"arguably altered the Middle East more than any trend since the modern states gained independence\", redefining \"politics and even borders\" according to one journalist (Robin Wright).\n",
      "Input Question:  What is an Islamic revival movement?\n",
      "Model Response:  islamism\n",
      "Actual Answer:  Islamism\n",
      "\n",
      "Input Question:  What aspects of life does Islamism seek to integrate itself into?\n",
      "Model Response:  all\n",
      "Actual Answer:  all spheres of life.\n",
      "\n",
      "Input Question:  What goal does Islamism have when it comes to society and government?\n",
      "Model Response:  reordering\n",
      "Actual Answer:  reordering\n",
      "\n",
      "Input Question:  What have the two different Islamist movements been described as oscillating between?\n",
      "Model Response:  two poles\n",
      "Actual Answer:  poles\n",
      "\n",
      "Input Question:  One strategy of Islamization is to seize power by what methods?\n",
      "Model Response:  revolution or invasion\n",
      "Actual Answer:  revolution or invasion\n",
      "\n",
      "Imperialism is a type of advocacy of empire. Its name originated from the Latin word \"imperium\", which means to rule over large territories. Imperialism is \"a policy of extending a country's power and influence through colonization, use of military force, or other means\". Imperialism has greatly shaped the contemporary world. It has also allowed for the rapid spread of technologies and ideas. The term imperialism has been applied to Western (and Japanese) political and economic dominance especially in Asia and Africa in the 19th and 20th centuries. Its precise meaning continues to be debated by scholars. Some writers, such as Edward Said, use the term more broadly to describe any system of domination and subordination organised with an imperial center and a periphery.\n",
      "Input Question:  The word imperialism has it's origins in which ancient language? \n",
      "Model Response:  latin\n",
      "Actual Answer:  Latin\n",
      "\n",
      "Input Question:  By what means is imperialism usually administered?\n",
      "Model Response:  \n",
      "Actual Answer:  military force\n",
      "\n",
      "Input Question:  The term imperialism has been applied to western countries, and which eastern county?\n",
      "Model Response:  japanese\n",
      "Actual Answer:  Japan\n",
      "\n",
      "Input Question:  Imperialism is responsible for the rapid spread of what?\n",
      "Model Response:  technologies and ideas\n",
      "Actual Answer:  technologies and ideas\n",
      "\n",
      "The United Methodist Church (UMC) is a mainline Protestant Methodist denomination. In the 19th century its main predecessor was a leader in Evangelicalism. Founded in 1968 by the union of the Methodist Church (USA) and the Evangelical United Brethren Church, the UMC traces its roots back to the revival movement of John and Charles Wesley in England as well as the Great Awakening in the United States. As such, the church's theological orientation is decidedly Wesleyan. It embraces both liturgical and evangelical elements.\n",
      "Input Question:  What does UMC stand for?\n",
      "Model Response:  the united methodist church\n",
      "Actual Answer:  United Methodist Church\n",
      "\n",
      "Input Question:  What is the United Methodist Church?\n",
      "Model Response:  a mainline protestant methodist denomination\n",
      "Actual Answer:  mainline Protestant Methodist denomination\n",
      "\n",
      "Input Question:  When was the UMC founded?\n",
      "Model Response:  1968\n",
      "Actual Answer:  1968\n",
      "\n",
      "Input Question:  Who founded the UMC?\n",
      "Model Response:  the union of the methodist church ( usa ) and the evangelical united brethren church\n",
      "Actual Answer:  union of the Methodist Church (USA) and the Evangelical United Brethren Church\n",
      "\n",
      "Input Question:  What is the church's theological orientation?\n",
      "Model Response:  wesleyan\n",
      "Actual Answer:  Wesleyan\n",
      "\n",
      "The French and Indian War (1754–1763) was the North American theater of the worldwide Seven Years' War. The war was fought between the colonies of British America and New France, with both sides supported by military units from their parent countries of Great Britain and France, as well as Native American allies. At the start of the war, the French North American colonies had a population of roughly 60,000 European settlers, compared with 2 million in the British North American colonies. The outnumbered French particularly depended on the Indians. Long in conflict, the metropole nations declared war on each other in 1756, escalating the war from a regional affair into an intercontinental conflict.\n",
      "Input Question:  When was the French and Indian War?\n",
      "Model Response:  1754 – 1763\n",
      "Actual Answer:  1754–1763\n",
      "\n",
      "Input Question:  Who fought in the French and Indian war?\n",
      "Model Response:  british america and new france\n",
      "Actual Answer:  colonies of British America and New France\n",
      "\n",
      "Input Question:  How many people were in French North American Colonies?\n",
      "Model Response:  60, 000\n",
      "Actual Answer:  roughly 60,000 European settlers\n",
      "\n",
      "Input Question:  How many people were in British North American Colonies?\n",
      "Model Response:  2 million\n",
      "Actual Answer:  2 million\n",
      "\n",
      "Philosophers in antiquity used the concept of force in the study of stationary and moving objects and simple machines, but thinkers such as Aristotle and Archimedes retained fundamental errors in understanding force. In part this was due to an incomplete understanding of the sometimes non-obvious force of friction, and a consequently inadequate view of the nature of natural motion. A fundamental error was the belief that a force is required to maintain motion, even at a constant velocity. Most of the previous misunderstandings about motion and force were eventually corrected by Galileo Galilei and Sir Isaac Newton. With his mathematical insight, Sir Isaac Newton formulated laws of motion that were not improved-on for nearly three hundred years. By the early 20th century, Einstein developed a theory of relativity that correctly predicted the action of forces on objects with increasing momenta near the speed of light, and also provided insight into the forces produced by gravitation and inertia.\n",
      "Input Question:  What concept did philosophers in antiquity use to study simple machines?\n",
      "Model Response:  force\n",
      "Actual Answer:  force\n",
      "\n",
      "Input Question:  What was the belief that maintaining motion required force?\n",
      "Model Response:  a fundamental error\n",
      "Actual Answer:  fundamental error\n",
      "\n",
      "Input Question:  Who had mathmatical insite?\n",
      "Model Response:  sir isaac newton\n",
      "Actual Answer:  Sir Isaac Newton\n",
      "\n",
      "Input Question:  How long did it take to improve on Sir Isaac Newton's laws of motion?\n",
      "Model Response:  nearly three hundred years\n",
      "Actual Answer:  nearly three hundred years\n",
      "\n",
      "Input Question:  Who develped the theory of relativity?\n",
      "Model Response:  einstein\n",
      "Actual Answer:  Einstein\n",
      "\n",
      "Accuracy:  0.8562691131498471\n"
     ]
    }
   ],
   "source": [
    "#SQAD Dataset\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "questions = pd.read_json('questions.json')\n",
    "count, total = 0,0\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    #keys: {title, paragraphs}\n",
    "    context = (questions['data'][i]['paragraphs'][0]['context'])\n",
    "    print(context)\n",
    "    for j in range(len(questions['data'][i]['paragraphs'][0]['qas'])):\n",
    "        question = (questions['data'][i]['paragraphs'][0]['qas'][j]['question'])\n",
    "        answer = (questions['data'][i]['paragraphs'][0]['qas'][j]['answers'][0]['text'])\n",
    "        print(\"Input Question: \", question)\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        answer_start_index = torch.argmax(outputs.start_logits)\n",
    "        answer_end_index = torch.argmax(outputs.end_logits)\n",
    "        predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "        print(\"Model Response: \", tokenizer.decode(predict_answer_tokens))\n",
    "        print(\"Actual Answer: \", answer)\n",
    "        for word in (answer.lower().split(\" \")):\n",
    "            if (word in tokenizer.decode(predict_answer_tokens).lower().split(\" \")):\n",
    "                count += 1\n",
    "                break\n",
    "        total += 1\n",
    "        print( )\n",
    "        \n",
    "print(\"Accuracy: \", count/total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad_v2 (C:/Users/nsiyu/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6089be3965db4ba28f2a9a7252c7f515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:  france\n",
      "Actual Answer:  ['France', 'France', 'France', 'France']\n",
      "\n",
      "Model Response:  10th and 11th centuries\n",
      "Actual Answer:  ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries', '10th and 11th centuries']\n",
      "\n",
      "Model Response:  denmark, iceland and norway\n",
      "Actual Answer:  ['Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway']\n",
      "\n",
      "Model Response:  rollo\n",
      "Actual Answer:  ['Rollo', 'Rollo', 'Rollo', 'Rollo']\n",
      "\n",
      "Model Response:  10th\n",
      "Actual Answer:  ['10th century', 'the first half of the 10th century', '10th', '10th']\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  normandy\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  west francia\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  first half of the 10th century\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  william the conqueror\n",
      "Actual Answer:  ['William the Conqueror', 'William the Conqueror', 'William the Conqueror']\n",
      "\n",
      "Model Response:  richard i\n",
      "Actual Answer:  ['Richard I', 'Richard I', 'Richard I']\n",
      "\n",
      "Model Response:  catholic\n",
      "Actual Answer:  ['Catholic', 'Catholic orthodoxy', 'Catholic']\n",
      "\n",
      "Model Response:  political, cultural and military\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  richard i\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  antioch\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  plural of normant\n",
      "Actual Answer:  ['Viking', 'Norseman, Viking', 'Norseman, Viking']\n",
      "\n",
      "Model Response:  9th century\n",
      "Actual Answer:  ['9th century', '9th century', '9th century']\n",
      "\n",
      "Model Response:  normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  9th century\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  911\n",
      "Actual Answer:  ['911', '911', '911']\n",
      "\n",
      "Model Response:  king charles iii of west francia\n",
      "Actual Answer:  ['King Charles III', 'King Charles III', 'King Charles III']\n",
      "\n",
      "Model Response:  river seine\n",
      "Actual Answer:  ['Seine', 'Epte', 'Seine']\n",
      "\n",
      "Model Response:  10th century\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  treaty of saint - clair - sur - epte\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  king charles iii of west francia and the famed viking ruler rollo\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  further viking incursions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  rollo\n",
      "Actual Answer:  ['Rollo', 'Rollo', 'Rollo']\n",
      "\n",
      "Model Response:  880s\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  danes, norwegians, norse – gaels, orkney vikings, possibly swedes, and anglo - danes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  norse\n",
      "Actual Answer:  ['Catholicism', 'Catholicism', 'Catholicism']\n",
      "\n",
      "Model Response:  north\n",
      "Actual Answer:  ['north', 'the north', 'north']\n",
      "\n",
      "Model Response:  catholicism\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  frankish heritage\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  old norse\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  fighting horsemen\n",
      "Actual Answer:  ['fighting horsemen', 'fighting horsemen', 'fighting horsemen']\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  fighting horsemen\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pechenegs, the bulgars, and especially the seljuk turks\n",
      "Actual Answer:  ['Seljuk Turks', 'the Pechenegs, the Bulgars, and especially the Seljuk Turks', 'the Seljuk Turks']\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pechenegs, the bulgars, and especially the seljuk turks\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  norman mercenaries\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sicilian campaign\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1050s\n",
      "Actual Answer:  ['1050s', 'in the 1050s', 'in the 1050s']\n",
      "\n",
      "Model Response:  1060s\n",
      "Actual Answer:  ['1060s', 'In the 1060s', 'In the 1060s']\n",
      "\n",
      "Model Response:  alexius komnenos\n",
      "Actual Answer:  ['Alexius Komnenos', 'Alexius Komnenos', 'Alexius Komnenos']\n",
      "\n",
      "Model Response:  herve\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1050s\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  roussel de bailleul\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1050s. by then however, there were already norman mercenaries serving as far away as trebizond and georgia. they were based at malatya and edessa, under the byzantine duke of antioch, isaac komnenos. in the 1060s\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  afranji\n",
      "Actual Answer:  ['Afranji', 'Afranji', 'Afranji']\n",
      "\n",
      "Model Response:  oursel\n",
      "Actual Answer:  ['Oursel', 'Oursel', 'Oursel']\n",
      "\n",
      "Model Response:  armenians\n",
      "Actual Answer:  ['Turkish forces', 'Turkish forces', 'Turkish forces']\n",
      "\n",
      "Model Response:  some normans joined turkish forces to aid in the destruction of the armenians vassal - states of sassoun and taron in far eastern anatolia. later, many took up service with the armenian state further south in cilicia and the taurus mountains. a norman named oursel\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the armenian state\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  oursel\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  upper euphrates valley in northern syria\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  italo - norman\n",
      "Actual Answer:  ['Norman mercenary', 'an Italo-Norman named Raoul', 'descended from an Italo-Norman named Raoul']\n",
      "\n",
      "Model Response:  byzantine greece\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  george maniaces\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sicilian expedition\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  robert guiscard\n",
      "Actual Answer:  ['Robert Guiscard', 'Robert Guiscard', 'Robert Guiscard']\n",
      "\n",
      "Model Response:  february 1082\n",
      "Actual Answer:  ['1082', 'February 1082', 'February 1082']\n",
      "\n",
      "Model Response:  30, 000\n",
      "Actual Answer:  ['30,000', '30,000', '30,000']\n",
      "\n",
      "Model Response:  robert guiscard\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pope gregory vii\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  [CLS]\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  30, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  deabolis\n",
      "Actual Answer:  ['Deabolis', 'Deabolis', 'Deabolis']\n",
      "\n",
      "Model Response:  bohemond\n",
      "Actual Answer:  ['Bohemond', 'Bohemond', 'Bohemond']\n",
      "\n",
      "Model Response:  river deabolis\n",
      "Actual Answer:  ['Deabolis', 'the river Deabolis', 'Deabolis']\n",
      "\n",
      "Model Response:  dyrrachium\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  robert\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1185\n",
      "Actual Answer:  ['1185', 'in 1185', '1185']\n",
      "\n",
      "Model Response:  dyrrachium\n",
      "Actual Answer:  ['Dyrrachium', 'Dyrrachium', 'Dyrrachium']\n",
      "\n",
      "Model Response:  the adriatic\n",
      "Actual Answer:  ['the Adriatic', 'the Adriatic', 'Adriatic']\n",
      "\n",
      "Model Response:  norman army\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  high byzantine officials\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dyrrachium\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  duke richard ii of normandy\n",
      "Actual Answer:  ['King Ethelred II', 'Ethelred II', 'King Ethelred II']\n",
      "\n",
      "Model Response:  duke richard ii of normandy\n",
      "Actual Answer:  ['Duke Richard II', 'Duke Richard II', 'Duke Richard II']\n",
      "\n",
      "Model Response:  normandy\n",
      "Actual Answer:  ['Normandy', 'Normandy', 'Normandy']\n",
      "\n",
      "Model Response:  sweyn forkbeard\n",
      "Actual Answer:  ['Sweyn Forkbeard', 'Sweyn Forkbeard', 'Sweyn Forkbeard']\n",
      "\n",
      "Model Response:  emma\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1013\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  harthacnut\n",
      "Actual Answer:  ['Harthacnut', 'Harthacnut', 'Harthacnut']\n",
      "\n",
      "Model Response:  1041\n",
      "Actual Answer:  ['1041', 'in 1041', '1041']\n",
      "\n",
      "Model Response:  robert of jumieges\n",
      "Actual Answer:  ['Robert of Jumièges', 'Robert of Jumièges', 'Robert of Jumièges']\n",
      "\n",
      "Model Response:  1041\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  english cavalry\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  he appointed robert of jumieges archbishop of canterbury\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  battle of hastings\n",
      "Actual Answer:  ['Battle of Hastings', 'the Battle of Hastings', 'at the Battle of Hastings']\n",
      "\n",
      "Model Response:  duke william ii of normandy\n",
      "Actual Answer:  ['William II', 'Duke William II', 'Duke William II']\n",
      "\n",
      "Model Response:  1066\n",
      "Actual Answer:  ['1066', 'In 1066', '1066']\n",
      "\n",
      "Model Response:  anglo - saxons\n",
      "Actual Answer:  ['Anglo-Saxons', 'the Anglo-Saxons', 'Anglo-Saxons']\n",
      "\n",
      "Model Response:  1066\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  battle of hastings\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  anglo - saxons\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  early norman kings of england\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  latin language, something that was the subject of some humour by geoffrey chaucer. the anglo - norman language was eventually absorbed into the anglo - saxon language\n",
      "Actual Answer:  ['Modern English', 'Modern English', 'Modern English']\n",
      "\n",
      "Model Response:  the norman aristocracy\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  anglo - saxon language of their subjects\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  geoffrey chaucer\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1169\n",
      "Actual Answer:  ['1169', '1169', '1169']\n",
      "\n",
      "Model Response:  bannow bay\n",
      "Actual Answer:  ['Ireland', 'Ireland', 'Ireland']\n",
      "\n",
      "Model Response:  irish culture\n",
      "Actual Answer:  ['Irish', 'Irish', 'Irish']\n",
      "\n",
      "Model Response:  bannow bay\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  irish culture and history\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  trim castle and dublin castle\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['Edgar', 'Edgar', 'Edgar Atheling']\n",
      "\n",
      "Model Response:  malcolm iii of scotland\n",
      "Actual Answer:  ['King Malcolm III of Scotland', 'King Malcolm III', 'King Malcolm III']\n",
      "\n",
      "Model Response:  1072\n",
      "Actual Answer:  ['1072', '1072', '1072']\n",
      "\n",
      "Model Response:  duncan\n",
      "Actual Answer:  ['Duncan', 'Duncan', 'Duncan']\n",
      "\n",
      "Model Response:  margaret\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  william\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  duncan\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sybilla of normandy\n",
      "Actual Answer:  ['Sybilla of Normandy', 'Sybilla of Normandy', 'Sybilla']\n",
      "\n",
      "Model Response:  normans and norman\n",
      "Actual Answer:  ['Norman', 'Norman', 'Norman']\n",
      "\n",
      "Model Response:  sybilla of normandy\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  normans and norman culture\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hereford\n",
      "Actual Answer:  ['Hereford', 'Hereford', 'Hereford']\n",
      "\n",
      "Model Response:  the welsh\n",
      "Actual Answer:  ['the Welsh', 'the Welsh', 'the Welsh']\n",
      "\n",
      "Model Response:  edward the confessor\n",
      "Actual Answer:  ['Edward the Confessor', 'Edward the Confessor', 'Edward the Confessor']\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ralph as earl of hereford\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cheshire\n",
      "Actual Answer:  ['Wales', 'Wales', 'Wales']\n",
      "\n",
      "Model Response:  the marches\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bernard de neufmarche, roger of montgomery in shropshire and hugh lupus in cheshire\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1018\n",
      "Actual Answer:  ['1018', '1064', '1018']\n",
      "\n",
      "Model Response:  william of montreuil\n",
      "Actual Answer:  ['William of Montreuil', 'William of Montreuil', 'William of Montreuil']\n",
      "\n",
      "Model Response:  antioch\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  religious wars\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  roger de tosny\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  war of barbastro\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1097\n",
      "Actual Answer:  ['1097', '1097', '1097']\n",
      "\n",
      "Model Response:  tancred\n",
      "Actual Answer:  ['Tancred', 'Tancred', 'Tancred']\n",
      "\n",
      "Model Response:  jerusalem\n",
      "Actual Answer:  ['Jerusalem', 'Jerusalem', 'Jerusalem']\n",
      "\n",
      "Model Response:  1097\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bohemond\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  380 years\n",
      "Actual Answer:  ['380 years', '380 years', '380 years']\n",
      "\n",
      "Model Response:  cyprus\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  anglo - norman forces of the third crusade\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a storm\n",
      "Actual Answer:  ['a storm', 'a storm', 'a storm']\n",
      "\n",
      "Model Response:  berengaria\n",
      "Actual Answer:  ['Berengaria', 'Berengaria', 'Berengaria']\n",
      "\n",
      "Model Response:  1191\n",
      "Actual Answer:  ['1191', '1191', '1191']\n",
      "\n",
      "Model Response:  richard the lion - hearted\n",
      "Actual Answer:  ['Isaac Komnenos', 'Isaac', 'Isaac Komnenos']\n",
      "\n",
      "Model Response:  richard the lion - hearted\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1191\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  conrad of montferrat\n",
      "Actual Answer:  ['Conrad of Montferrat', 'Conrad of Montferrat', 'Conrad of Montferrat']\n",
      "\n",
      "Model Response:  silver\n",
      "Actual Answer:  ['silver', 'silver', 'silver']\n",
      "\n",
      "Model Response:  guy de lusignan\n",
      "Actual Answer:  ['Guy de Lusignan', 'Guy de Lusignan', 'Guy de Lusignan']\n",
      "\n",
      "Model Response:  silver\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  guy de lusignan\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  isaac\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  africa\n",
      "Actual Answer:  ['Africa', 'Africa', 'Africa']\n",
      "\n",
      "Model Response:  the expedition led by the norman noble jean de bethencourt and the poitevine gadifer de la salle\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  lanzarote, fuerteventura and el hierro\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bethencourt\n",
      "Actual Answer:  ['Bethencourt', 'Bethencourt', 'Bethencourt']\n",
      "\n",
      "Model Response:  enrique perez de guzman\n",
      "Actual Answer:  ['Enrique Pérez de Guzmán', 'Enrique Pérez de Guzmán', 'Enrique Pérez de Guzmán']\n",
      "\n",
      "Model Response:  enrique perez de guzman\n",
      "Actual Answer:  ['Maciot de Bethencourt', 'Maciot de Bethencourt', 'Maciot de Bethencourt']\n",
      "\n",
      "Model Response:  king of the canary islands\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  enrique perez de guzman\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  channel islands\n",
      "Actual Answer:  ['Channel Islands', 'the Channel Islands', 'the Channel Islands']\n",
      "\n",
      "Model Response:  two\n",
      "Actual Answer:  ['two', 'two', 'two']\n",
      "\n",
      "Model Response:  tres ancien coutumier\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  tres ancien coutumier\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the grand coutumier de normandie\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  romanesque idiom\n",
      "Actual Answer:  ['Romanesque', 'Romanesque', 'Romanesque']\n",
      "\n",
      "Model Response:  rounded arches\n",
      "Actual Answer:  ['rounded', 'rounded', 'rounded']\n",
      "\n",
      "Model Response:  rounded arches\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  early gothic\n",
      "Actual Answer:  ['Early Gothic', 'Early Gothic', 'Early Gothic']\n",
      "\n",
      "Model Response:  early gothic\n",
      "Actual Answer:  ['Anglo-Saxon', 'Anglo-Saxon', 'Anglo-Saxon']\n",
      "\n",
      "Model Response:  kingdom of sicily\n",
      "Actual Answer:  ['Sicily', 'Sicily', 'Kingdom of Sicily']\n",
      "\n",
      "Model Response:  early gothic\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  norman architecture\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the normans\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  early 11th century\n",
      "Actual Answer:  ['early 11th century', '11th century', 'in the early 11th century']\n",
      "\n",
      "Model Response:  the dukes\n",
      "Actual Answer:  ['dukes', 'the dukes', 'dukes']\n",
      "\n",
      "Model Response:  visual arts\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the dukes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  disparate duchy\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  normandy\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  16th century\n",
      "Actual Answer:  ['16th century', 'the 16th century', 'in the 16th century']\n",
      "\n",
      "Model Response:  french wars of religion\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  french revolution\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  embroidery\n",
      "Actual Answer:  ['embroidery', 'embroidery', 'embroidery']\n",
      "\n",
      "Model Response:  the bayeux tapestry\n",
      "Actual Answer:  ['Bayeux Tapestry', 'the Bayeux Tapestry', 'the Bayeux Tapestry']\n",
      "\n",
      "Model Response:  odo, the bishop of bayeux and first earl of kent\n",
      "Actual Answer:  ['Odo', 'Odo', 'Odo']\n",
      "\n",
      "Model Response:  the bayeux tapestry\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  odo, the bishop of bayeux and first earl of kent\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  stonework or metalwork, such as capitals and baptismal fonts. in southern italy, however, norman artwork survives plentifully in forms strongly influenced by its greek, lombard, and arab forebears. of the royal regalia preserved in palermo, the crown is byzantine in style and the coronation cloak is of arab craftsmanship with arabic inscriptions. many churches preserve sculptured fonts, capitals, and more importantly mosaics\n",
      "Actual Answer:  ['mosaics', 'mosaics', 'mosaics']\n",
      "\n",
      "Model Response:  as stonework or metalwork\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mosaics\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  lombard salerno\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  11th\n",
      "Actual Answer:  ['11th', 'the 11th', '11th']\n",
      "\n",
      "Model Response:  william of volpiano and john of ravenna\n",
      "Actual Answer:  ['William of Volpiano and John of Ravenna', 'William of Volpiano and John of Ravenna', 'William of Volpiano and John of Ravenna']\n",
      "\n",
      "Model Response:  history of classical music\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  musical production and education\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern italy\n",
      "Actual Answer:  ['southern Italy', 'southern Italy', 'southern Italy']\n",
      "\n",
      "Model Response:  sant'eufemia\n",
      "Actual Answer:  [\"Latin monastery at Sant'Eufemia.\", \"a Latin monastery at Sant'Eufemia\", \"Sant'Eufemia\"]\n",
      "\n",
      "Model Response:  robert guiscard\n",
      "Actual Answer:  ['Robert Guiscard', 'Robert Guiscard', 'Robert Guiscard']\n",
      "\n",
      "Model Response:  singing\n",
      "Actual Answer:  ['singing', 'singing', 'singing']\n",
      "\n",
      "Model Response:  monks\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computational complexity theory\n",
      "Actual Answer:  ['Computational complexity theory', 'Computational complexity theory', 'Computational complexity theory']\n",
      "\n",
      "Model Response:  inherent difficulty\n",
      "Actual Answer:  ['inherent difficulty', 'their inherent difficulty', 'inherent difficulty']\n",
      "\n",
      "Model Response:  a computational problem\n",
      "Actual Answer:  ['computational problems', 'A computational problem', 'computational problem']\n",
      "\n",
      "Model Response:  a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. a computational problem is understood to be a task that is in principle amenable to being solved by a computer\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computational complexity theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a computational problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  an algorithm\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  an algorithm\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  significant resources\n",
      "Actual Answer:  ['if its solution requires significant resources', 'its solution requires significant resources', 'if its solution requires significant resources']\n",
      "\n",
      "Model Response:  mathematical models of computation\n",
      "Actual Answer:  ['mathematical models of computation', 'mathematical models of computation', 'mathematical models of computation']\n",
      "\n",
      "Model Response:  time and storage\n",
      "Actual Answer:  ['time and storage', 'time and storage', 'time and storage']\n",
      "\n",
      "Model Response:  gates\n",
      "Actual Answer:  ['number of gates in a circuit', 'number of gates in a circuit', 'number of gates']\n",
      "\n",
      "Model Response:  to determine the practical limits on what computers can and cannot do\n",
      "Actual Answer:  ['determine the practical limits on what computers can and cannot do', 'what computers can and cannot do', 'determine the practical limits on what computers can and cannot do']\n",
      "\n",
      "Model Response:  amount of communication ( used in communication complexity ), the number of gates in a circuit ( used in circuit complexity ) and the number of processors\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mathematical models of computation\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time and storage\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  gates\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the number of processors\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  analysis of algorithms and computability theory\n",
      "Actual Answer:  ['analysis of algorithms and computability theory', 'analysis of algorithms and computability theory', 'analysis of algorithms and computability theory']\n",
      "\n",
      "Model Response:  computability theory\n",
      "Actual Answer:  ['analysis of algorithms', 'analysis of algorithms', 'analysis of algorithms']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['computational complexity theory', 'computational complexity theory', 'computational complexity theory']\n",
      "\n",
      "Model Response:  computability theory\n",
      "Actual Answer:  ['computability theory', 'computability theory', 'computability theory']\n",
      "\n",
      "Model Response:  analysis of algorithms and computability theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computability theory. a key distinction between analysis of algorithms and computational complexity theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computational complexity theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computability theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  problem instance\n",
      "Actual Answer:  ['problem instance', 'a problem instance', 'problem instance']\n",
      "\n",
      "Model Response:  a problem\n",
      "Actual Answer:  ['the problem', 'a problem', 'problem']\n",
      "\n",
      "Model Response:  concrete\n",
      "Actual Answer:  ['concrete', 'concrete', 'abstract']\n",
      "\n",
      "Model Response:  output\n",
      "Actual Answer:  ['instances', 'the instance', 'instance']\n",
      "\n",
      "Model Response:  utterance\n",
      "Actual Answer:  ['solution', 'the solution', 'solution']\n",
      "\n",
      "Model Response:  a computational problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  problem instance\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computational complexity theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the solution\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the solution is the output corresponding to the given input\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2000\n",
      "Actual Answer:  ['2000', '2000', '2000']\n",
      "\n",
      "Model Response:  asking for a round trip through all sites in milan\n",
      "Actual Answer:  ['round trip through all sites in Milan', 'asking for a round trip through all sites in Milan whose total length is at most 10 km', 'a round trip through all sites in Milan whose total length is at most 10 km']\n",
      "\n",
      "Model Response:  a round trip through all sites in milan\n",
      "Actual Answer:  ['computational problems', 'computational problems', 'computational problems']\n",
      "\n",
      "Model Response:  2000 kilometres\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  asking for a round trip through all sites in milan\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a round trip through all sites in milan\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bitstrings\n",
      "Actual Answer:  ['problem instance', 'a problem instance', 'problem instance']\n",
      "\n",
      "Model Response:  a string\n",
      "Actual Answer:  ['binary alphabet', 'binary', 'binary']\n",
      "\n",
      "Model Response:  a string over an alphabet\n",
      "Actual Answer:  ['bitstrings', 'bitstrings', 'bitstrings']\n",
      "\n",
      "Model Response:  suitably\n",
      "Actual Answer:  ['binary notation', 'binary notation', 'binary notation']\n",
      "\n",
      "Model Response:  via their adjacency matrices\n",
      "Actual Answer:  ['adjacency matrices', 'directly via their adjacency matrices']\n",
      "\n",
      "Model Response:  alphabet\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a string\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a string over an alphabet\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  integers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  via their adjacency matrices\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  decision problems\n",
      "Actual Answer:  ['Decision problems', 'Decision problems', 'Decision']\n",
      "\n",
      "Model Response:  yes or no, or alternately either 1 or 0\n",
      "Actual Answer:  ['yes or no', 'yes or no', 'yes or no']\n",
      "\n",
      "Model Response:  yes or no, or alternately either 1 or 0\n",
      "Actual Answer:  ['1 or 0', '1 or 0', '1 or 0']\n",
      "\n",
      "Model Response:  yes\n",
      "Actual Answer:  ['yes', 'yes', 'yes']\n",
      "\n",
      "Model Response:  yes\n",
      "Actual Answer:  ['yes', 'yes', 'yes']\n",
      "\n",
      "Model Response:  decision problems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  decision problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a decision problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  yes or no, or alternately either 1 or 0\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  yes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  arbitrary graph\n",
      "Actual Answer:  ['arbitrary graph', 'arbitrary', 'arbitrary']\n",
      "\n",
      "Model Response:  formal language\n",
      "Actual Answer:  ['formal language', 'The formal language', 'The formal language associated with this decision problem']\n",
      "\n",
      "Model Response:  the set of all connected graphs\n",
      "Actual Answer:  ['how graphs are encoded as binary strings', 'how graphs are encoded as binary strings', 'how graphs are encoded as binary strings']\n",
      "\n",
      "Model Response:  arbitrary graph\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  formal language\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  binary strings\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  one has to decide how graphs are encoded as binary strings\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computational\n",
      "Actual Answer:  ['a computational problem', 'a computational problem', 'a computational problem']\n",
      "\n",
      "Model Response:  single\n",
      "Actual Answer:  ['a single output', 'single', 'single']\n",
      "\n",
      "Model Response:  integer factorization problem\n",
      "Actual Answer:  ['A function problem', 'function', 'function problem']\n",
      "\n",
      "Model Response:  integer factorization problem\n",
      "Actual Answer:  ['the integer factorization problem', 'integer factorization', 'integer factorization problem']\n",
      "\n",
      "Model Response:  complex\n",
      "Actual Answer:  ['complex', 'complex', 'complex']\n",
      "\n",
      "Model Response:  a function problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a function problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  traveling salesman problem and the integer factorization problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  traveling salesman problem and the integer factorization problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complex\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  decision problems\n",
      "Actual Answer:  ['decision problems', 'as decision problems', 'as decision problems']\n",
      "\n",
      "Model Response:  triples\n",
      "Actual Answer:  ['set of triples', 'triple', 'the set of triples (a, b, c) such that the relation a × b = c holds']\n",
      "\n",
      "Model Response:  function problems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  triples\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  deciding whether a given triple is a member of this set\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the size of the input in bits\n",
      "Actual Answer:  ['how much time the best algorithm requires to solve the problem', 'time', 'time']\n",
      "\n",
      "Model Response:  the instance\n",
      "Actual Answer:  ['the instance', 'the instance', 'the size of the instance']\n",
      "\n",
      "Model Response:  as a function of the size of the instance\n",
      "Actual Answer:  ['as a function of the size of the instance', 'as a function of the size of the instance', 'a function of the size of the instance']\n",
      "\n",
      "Model Response:  bits\n",
      "Actual Answer:  ['bits', 'bits', 'bits']\n",
      "\n",
      "Model Response:  input size\n",
      "Actual Answer:  ['an increase in the input size', 'input size', 'input size']\n",
      "\n",
      "Model Response:  as a function of the size of the instance\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  size of the input in bits\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  as a function of the size of the instance\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  as a function of the size of the instance\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cobham\n",
      "Actual Answer:  [\"Cobham's thesis\", \"Cobham's\", 'Cobham']\n",
      "\n",
      "Model Response:  the time taken\n",
      "Actual Answer:  ['the time taken', 'the time taken', 'the time taken']\n",
      "\n",
      "Model Response:  worst - case time complexity t ( n )\n",
      "Actual Answer:  ['worst-case time complexity', 'worst-case time complexity', 'the worst-case time complexity']\n",
      "\n",
      "Model Response:  the maximum time taken over all inputs of size n\n",
      "Actual Answer:  ['T(n)', 'T(n)', 'T(n)']\n",
      "\n",
      "Model Response:  polynomial time algorithm\n",
      "Actual Answer:  ['polynomial time algorithm', 'polynomial time', 'polynomial time algorithm']\n",
      "\n",
      "Model Response:  if the input size is n\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cobham\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  worst - case time complexity t ( n )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the maximum time taken over all inputs of size n\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  polynomial time algorithm\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  turing machine\n",
      "Actual Answer:  ['A Turing machine', 'A Turing machine', 'Turing machine']\n",
      "\n",
      "Model Response:  an algorithm\n",
      "Actual Answer:  ['an algorithm', 'an algorithm', 'an algorithm']\n",
      "\n",
      "Model Response:  turing machine\n",
      "Actual Answer:  ['the Turing machine', 'the Turing machine', 'Turing machine']\n",
      "\n",
      "Model Response:  symbols\n",
      "Actual Answer:  ['symbols', 'symbols', 'symbols']\n",
      "\n",
      "Model Response:  turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a deterministic turing machine\n",
      "Actual Answer:  ['A deterministic Turing machine', 'deterministic', 'deterministic Turing machine']\n",
      "\n",
      "Model Response:  rules\n",
      "Actual Answer:  ['rules', 'rules', 'a fixed set of rules to determine its future actions']\n",
      "\n",
      "Model Response:  randomized algorithms\n",
      "Actual Answer:  ['A probabilistic Turing machine', 'probabilistic', 'probabilistic Turing machine']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['A non-deterministic Turing machine', 'non-deterministic', 'non-deterministic Turing machine']\n",
      "\n",
      "Model Response:  randomized algorithms\n",
      "Actual Answer:  ['randomized algorithms', 'randomized algorithms', 'randomized algorithms']\n",
      "\n",
      "Model Response:  a deterministic turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a probabilistic turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the ability to make probabilistic decisions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a non - deterministic turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  that the turing machine branches into many possible computational paths at each step\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity classes\n",
      "Actual Answer:  ['complexity classes', 'complexity classes', 'complexity classes']\n",
      "\n",
      "Model Response:  when resources ( such as time or space ) are bounded\n",
      "Actual Answer:  ['time or space', 'time or space', 'time or space']\n",
      "\n",
      "Model Response:  deterministic turing machines, probabilistic turing machines, non - deterministic turing machines, quantum turing machines, symmetric turing machines and alternating turing machines\n",
      "Actual Answer:  ['probabilistic Turing machines, non-deterministic Turing machines', 'probabilistic Turing machines, non-deterministic Turing machines']\n",
      "\n",
      "Model Response:  to define complexity classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  when resources ( such as time or space ) are bounded\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  deterministic turing machines, probabilistic turing machines, non - deterministic turing machines, quantum turing machines, symmetric turing machines and alternating turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bounded\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  random access machines\n",
      "Actual Answer:  ['random access machines', 'random access machines', 'random access machines']\n",
      "\n",
      "Model Response:  time and memory\n",
      "Actual Answer:  ['computational power', 'computational power', 'computational power']\n",
      "\n",
      "Model Response:  time and memory\n",
      "Actual Answer:  ['time and memory', 'time and memory consumption', 'time and memory consumption']\n",
      "\n",
      "Model Response:  deterministically\n",
      "Actual Answer:  ['the machines operate deterministically', 'deterministically', 'the machines operate deterministically']\n",
      "\n",
      "Model Response:  random access machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time and memory consumption of these alternate models may vary. what all these models have in common is that the machines operate deterministically\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time and memory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the machines operate deterministically\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  non - deterministic\n",
      "Actual Answer:  ['non-deterministic', 'non-deterministic', 'non-deterministic Turing machine']\n",
      "\n",
      "Model Response:  more unusual resources\n",
      "Actual Answer:  ['unusual resources', 'more unusual resources', 'more unusual resources']\n",
      "\n",
      "Model Response:  mathematical models\n",
      "Actual Answer:  ['mathematical models', 'mathematical models', 'branching']\n",
      "\n",
      "Model Response:  non - deterministic time\n",
      "Actual Answer:  ['time', 'non-deterministic time', 'non-deterministic time']\n",
      "\n",
      "Model Response:  computational problems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  non - deterministic turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the non - deterministic turing machine has very little to do\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  non - deterministic turing machine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  non - deterministic time\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \" yes \" or \" no \"\n",
      "Actual Answer:  ['state transitions', 'the total number of state transitions, or steps', 'total number of state transitions, or steps, the machine makes before it halts and outputs the answer']\n",
      "\n",
      "Model Response:  difficulty\n",
      "Actual Answer:  ['difficulty', 'difficulty', 'difficulty']\n",
      "\n",
      "Model Response:  dtime\n",
      "Actual Answer:  ['DTIME(f(n))', 'DTIME(f(n)).', 'DTIME(f(n))']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['time', 'time', 'time']\n",
      "\n",
      "Model Response:  a computational model\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  within time f ( n )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dtime\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dtime\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  if there exists a turing machine operating in time f ( n ) that solves the problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity\n",
      "Actual Answer:  ['complexity resources', 'complexity resources', 'complexity']\n",
      "\n",
      "Model Response:  computational\n",
      "Actual Answer:  ['computational resource', 'computational', 'computational']\n",
      "\n",
      "Model Response:  blum complexity axioms\n",
      "Actual Answer:  ['Blum complexity axioms', 'the Blum complexity axioms', 'the Blum complexity axioms']\n",
      "\n",
      "Model Response:  complexity theory\n",
      "Actual Answer:  ['Complexity measures', 'complexity measures', 'complexity']\n",
      "\n",
      "Model Response:  complexity measures\n",
      "Actual Answer:  ['Complexity measures', 'complexity measures', 'complexity']\n",
      "\n",
      "Model Response:  analogous definitions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time and space\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  blum complexity axioms\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  communication complexity, circuit complexity, and decision tree complexity\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity theory\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  best, worst and average\n",
      "Actual Answer:  ['best, worst and average', 'best, worst and average case', 'best, worst and average case complexity']\n",
      "\n",
      "Model Response:  time complexity\n",
      "Actual Answer:  ['complexity measure', 'complexity', 'complexity']\n",
      "\n",
      "Model Response:  best, worst and average case complexity refer to three different ways of measuring the time complexity ( or any other complexity measure ) of different inputs of the same size\n",
      "Actual Answer:  ['time', 'time complexity', 'time complexity']\n",
      "\n",
      "Model Response:  time complexity\n",
      "Actual Answer:  ['inputs', 'inputs', 'inputs']\n",
      "\n",
      "Model Response:  best, worst and average\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the best, worst and average case complexity\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  best, worst and average case complexity refer to three different ways of measuring the time complexity ( or any other complexity measure ) of different inputs of the same size\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  n\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  quicksort\n",
      "Actual Answer:  ['deterministic sorting algorithm quicksort', 'quicksort', 'the deterministic sorting algorithm quicksort']\n",
      "\n",
      "Model Response:  worst - case\n",
      "Actual Answer:  ['worst-case', 'worst', 'worst-case']\n",
      "\n",
      "Model Response:  o ( n2 )\n",
      "Actual Answer:  ['O(n2)', 'O(n2)', 'O(n2)']\n",
      "\n",
      "Model Response:  deterministic sorting algorithm quicksort\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  solves the problem of sorting a list of integers that is given as the input\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  o ( n2 )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  o ( n2 )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  best case\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the most efficient algorithm solving a given problem\n",
      "Actual Answer:  ['the most efficient algorithm', 'the most efficient algorithm', 'the most efficient algorithm solving a given problem']\n",
      "\n",
      "Model Response:  algorithms\n",
      "Actual Answer:  ['analysis of algorithms', 'analysis of algorithms', 'analysis of algorithms']\n",
      "\n",
      "Model Response:  lower bounds\n",
      "Actual Answer:  ['lower bounds', 'lower', 'lower bounds']\n",
      "\n",
      "Model Response:  upper bound\n",
      "Actual Answer:  ['upper bound', 'upper and lower bounds', 'upper bound']\n",
      "\n",
      "Model Response:  \" all possible algorithms \"\n",
      "Actual Answer:  ['all possible algorithms', 'all possible algorithms', 'all possible algorithms']\n",
      "\n",
      "Model Response:  space consumption\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the complexity of an algorithm\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  analyzing a particular algorithm\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  to show an upper bound t ( n ) on the time complexity of a problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  lower bounds make a statement about all possible algorithms that solve a given problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  big o notation\n",
      "Actual Answer:  ['big O notation', 'big O notation', 'big O notation']\n",
      "\n",
      "Model Response:  constant factors and smaller terms\n",
      "Actual Answer:  ['constant factors and smaller terms', 'constant factors and smaller terms', 'constant factors and smaller terms']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['T(n) = O(n2)', 'T(n) = O(n2)', 'T(n) = O(n2)']\n",
      "\n",
      "Model Response:  computational model\n",
      "Actual Answer:  ['the computational model', 'specific details of the computational model used', 'the specific details of the computational model used']\n",
      "\n",
      "Model Response:  upper and lower bounds\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  big o notation\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  big o notation\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  write t ( n ) = o ( n2 )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity classes\n",
      "Actual Answer:  ['complexity classes', 'complexity classes', 'some complexity classes']\n",
      "\n",
      "Model Response:  complicated definitions\n",
      "Actual Answer:  ['framework', 'framework', 'framework']\n",
      "\n",
      "Model Response:  complicated definitions\n",
      "Actual Answer:  ['complicated definitions', 'complicated definitions', 'definitions']\n",
      "\n",
      "Model Response:  complicated definitions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complicated definitions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complicated definitions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the chosen machine model\n",
      "Actual Answer:  ['chosen machine model', 'the chosen machine model', 'the chosen machine model']\n",
      "\n",
      "Model Response:  quadratic time\n",
      "Actual Answer:  ['linear time', 'linear', 'linear']\n",
      "\n",
      "Model Response:  single - tape\n",
      "Actual Answer:  ['single-tape Turing machines', 'single-tape', 'single-tape']\n",
      "\n",
      "Model Response:  cobham - edmonds thesis\n",
      "Actual Answer:  ['Cobham-Edmonds thesis', 'Cobham-Edmonds', 'Cobham-Edmonds thesis']\n",
      "\n",
      "Model Response:  complexity class p\n",
      "Actual Answer:  ['complexity class P', 'P', 'complexity class P']\n",
      "\n",
      "Model Response:  bounding the computation time above by some concrete function f ( n )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  f ( n )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the language { xx | x is any binary string }\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  xx | x\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cobham - edmonds thesis\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time or space\n",
      "Actual Answer:  ['time or space', 'time or space', 'time or space']\n",
      "\n",
      "Model Response:  bounding\n",
      "Actual Answer:  ['bounding', 'bounding', 'bounding']\n",
      "\n",
      "Model Response:  important complexity classes\n",
      "Actual Answer:  ['complexity classes', 'complexity classes', 'complexity classes']\n",
      "\n",
      "Model Response:  important complexity classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time or space\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bounding the time or space\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bpp, zpp and rp\n",
      "Actual Answer:  ['BPP, ZPP and RP', 'BPP, ZPP and RP', 'BPP, ZPP and RP']\n",
      "\n",
      "Model Response:  boolean\n",
      "Actual Answer:  ['Boolean', 'Boolean', 'Boolean circuits;']\n",
      "\n",
      "Model Response:  quantum\n",
      "Actual Answer:  ['quantum', 'quantum', 'quantum']\n",
      "\n",
      "Model Response:  # p\n",
      "Actual Answer:  ['#P', '#P', '#P']\n",
      "\n",
      "Model Response:  interactive\n",
      "Actual Answer:  ['Interactive', 'Interactive', 'Interactive']\n",
      "\n",
      "Model Response:  bpp, zpp and rp\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  probabilistic turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  quantum turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  # p\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  interactive proof systems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  computation time\n",
      "Actual Answer:  ['computation time', 'computation time', 'computation time']\n",
      "\n",
      "Model Response:  dtime ( n2\n",
      "Actual Answer:  ['DTIME(n2)', 'DTIME(n2)', 'DTIME(n2)']\n",
      "\n",
      "Model Response:  time and space hierarchy theorems\n",
      "Actual Answer:  ['time and space hierarchy theorems', 'time and space hierarchy theorems', 'time and space hierarchy theorems']\n",
      "\n",
      "Model Response:  a proper hierarchy\n",
      "Actual Answer:  ['a proper hierarchy on the classes defined', 'a proper hierarchy on the classes', 'a proper hierarchy']\n",
      "\n",
      "Model Response:  quantitative\n",
      "Actual Answer:  ['quantitative statements', 'quantitative', 'quantitative']\n",
      "\n",
      "Model Response:  computation time\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  relaxing the requirements on ( say ) computation time\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dtime ( n2\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hierarchy theorems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  quantitative\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the time and space hierarchy theorems\n",
      "Actual Answer:  ['time and space hierarchy theorems', 'The time and space hierarchy theorems', 'time and space hierarchy theorems']\n",
      "\n",
      "Model Response:  strictly contained in exptime\n",
      "Actual Answer:  ['EXPTIME', 'EXPTIME', 'EXPTIME']\n",
      "\n",
      "Model Response:  pspace\n",
      "Actual Answer:  ['PSPACE', 'PSPACE', 'PSPACE']\n",
      "\n",
      "Model Response:  the time and space hierarchy theorems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  p\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  l\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a reduction\n",
      "Actual Answer:  ['reduction', 'a reduction', 'reduction']\n",
      "\n",
      "Model Response:  another problem\n",
      "Actual Answer:  ['another problem', 'another problem', 'another problem']\n",
      "\n",
      "Model Response:  no more difficult\n",
      "Actual Answer:  ['reduces', 'reduces', 'X reduces to Y']\n",
      "\n",
      "Model Response:  cook reductions, karp reductions and levin reductions\n",
      "Actual Answer:  ['Karp reductions and Levin reductions', 'Cook reductions, Karp reductions']\n",
      "\n",
      "Model Response:  complexity\n",
      "Actual Answer:  ['the bound on the complexity of reductions', 'types of reductions', 'the bound on the complexity of reductions']\n",
      "\n",
      "Model Response:  the concept of a reduction\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a reduction\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a reduction\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cook reductions, karp reductions and levin reductions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  polynomial - time reduction\n",
      "Actual Answer:  ['polynomial-time reduction', 'polynomial-time', 'polynomial-time reduction']\n",
      "\n",
      "Model Response:  multiplying two integers\n",
      "Actual Answer:  ['multiplying two integers', 'multiplying two integers', 'multiplying two integers']\n",
      "\n",
      "Model Response:  squaring an integer can be reduced to the problem of multiplying two integers\n",
      "Actual Answer:  ['polynomial time', 'polynomial', 'polynomial time']\n",
      "\n",
      "Model Response:  both inputs\n",
      "Actual Answer:  ['input', 'input', 'input']\n",
      "\n",
      "Model Response:  multiplication\n",
      "Actual Answer:  ['multiplication', 'multiplication', 'multiplication']\n",
      "\n",
      "Model Response:  polynomial - time reduction\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the reduction process takes polynomial time\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  multiplying two integers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  squaring\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the type of reduction being used\n",
      "Actual Answer:  ['the type of reduction being used', 'the type of reduction being used']\n",
      "\n",
      "Model Response:  an algorithm for x\n",
      "Actual Answer:  ['if every problem in C can be reduced to X', 'problem in C is harder than X']\n",
      "\n",
      "Model Response:  solve any problem in c\n",
      "Actual Answer:  ['solve any problem in C', 'solve any problem in C', 'solve any problem in C']\n",
      "\n",
      "Model Response:  the set of np - hard problems\n",
      "Actual Answer:  ['NP-hard', 'NP-hard', 'NP-hard problems']\n",
      "\n",
      "Model Response:  the type of reduction being used\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  an algorithm for x\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  no problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the set of np - hard problems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  np - complete\n",
      "Actual Answer:  ['NP-complete', 'NP-complete', 'NP-complete']\n",
      "\n",
      "Model Response:  p\n",
      "Actual Answer:  ['NP', 'P', 'P']\n",
      "\n",
      "Model Response:  finding an np - complete problem that can be solved in polynomial time\n",
      "Actual Answer:  ['there is no known polynomial-time solution', 'no known polynomial-time solution', 'there is no known polynomial-time solution']\n",
      "\n",
      "Model Response:  the set\n",
      "Actual Answer:  ['NP', 'NP', 'NP']\n",
      "\n",
      "Model Response:  x is said to be complete\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  x\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  np - complete\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  π2\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  p\n",
      "Actual Answer:  ['P', 'P', 'P']\n",
      "\n",
      "Model Response:  cobham – edmonds thesis\n",
      "Actual Answer:  ['Cobham–Edmonds thesis', 'Cobham–Edmonds thesis', 'Cobham–Edmonds thesis']\n",
      "\n",
      "Model Response:  p\n",
      "Actual Answer:  ['NP', 'NP', 'NP']\n",
      "\n",
      "Model Response:  boolean satisfiability problem, the hamiltonian path problem and the vertex cover problem\n",
      "Actual Answer:  ['Boolean satisfiability problem', 'Boolean satisfiability problem']\n",
      "\n",
      "Model Response:  cobham – edmonds thesis. the complexity class np, on the other hand, contains many problems that people would like to solve efficiently, but for which no efficient algorithm is known, such as the boolean satisfiability problem, the hamiltonian path problem and the vertex cover problem. since deterministic turing machines\n",
      "Actual Answer:  ['Turing machines', 'deterministic Turing machines', 'deterministic Turing machines']\n",
      "\n",
      "Model Response:  the complexity class p\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  np\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  boolean satisfiability problem, the hamiltonian path problem and the vertex cover problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  deterministic turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  more efficient solutions\n",
      "Actual Answer:  ['more efficient solutions', 'shown to have more efficient solutions', 'many important problems can be shown to have more efficient solutions']\n",
      "\n",
      "Model Response:  protein structure prediction\n",
      "Actual Answer:  ['protein structure prediction', 'protein structure prediction', 'protein structure prediction']\n",
      "\n",
      "Model Response:  us $ 1, 000, 000\n",
      "Actual Answer:  ['$1,000,000', 'US$1,000,000', 'US$1,000,000']\n",
      "\n",
      "Model Response:  whether p equals np\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  many important problems can be shown to have more efficient solutions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  protein structure prediction in biology\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  p versus np problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  us $ 1, 000, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ladner\n",
      "Actual Answer:  ['Ladner', 'Ladner', 'Ladner']\n",
      "\n",
      "Model Response:  np - intermediate problems\n",
      "Actual Answer:  ['NP-intermediate problems', 'NP-intermediate problems', 'NP-intermediate']\n",
      "\n",
      "Model Response:  the graph isomorphism problem, the discrete logarithm problem and the integer factorization problem\n",
      "Actual Answer:  ['graph isomorphism problem', 'the discrete logarithm problem', 'graph isomorphism problem, the discrete logarithm problem and the integer factorization problem']\n",
      "\n",
      "Model Response:  ladner\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  graph isomorphism problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the graph isomorphism problem, the discrete logarithm problem and the integer factorization problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the graph isomorphism problem, the discrete logarithm problem and the integer factorization problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  graph isomorphism\n",
      "Actual Answer:  ['The graph isomorphism problem', 'graph isomorphism', 'The graph isomorphism problem']\n",
      "\n",
      "Model Response:  np - complete\n",
      "Actual Answer:  ['NP-complete', 'NP-complete', 'NP-complete']\n",
      "\n",
      "Model Response:  polynomial hierarchy\n",
      "Actual Answer:  ['polynomial time hierarchy', 'polynomial time', 'polynomial time hierarchy']\n",
      "\n",
      "Model Response:  second level\n",
      "Actual Answer:  ['second level', 'second', 'second']\n",
      "\n",
      "Model Response:  laszlo babai and eugene luks\n",
      "Actual Answer:  ['Laszlo Babai and Eugene Luks', 'Babai and Eugene Luks', 'Laszlo Babai and Eugene Luks']\n",
      "\n",
      "Model Response:  determining whether two finite graphs are isomorphic\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the graph isomorphism\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  whether the graph isomorphism problem is in p, np - complete, or np - intermediate\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  polynomial hierarchy\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  its second level\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  integer factorization\n",
      "Actual Answer:  ['The integer factorization problem', 'integer factorization', 'integer factorization problem']\n",
      "\n",
      "Model Response:  k\n",
      "Actual Answer:  ['k', 'k', 'k']\n",
      "\n",
      "Model Response:  rsa algorithm\n",
      "Actual Answer:  ['modern cryptographic systems', 'modern cryptographic systems', 'RSA algorithm']\n",
      "\n",
      "Model Response:  general number field sieve\n",
      "Actual Answer:  ['the general number field sieve', 'RSA', 'general number field sieve']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  integer factorization\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  integer factorization\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  integer factorization problem is in np and in co - np ( and even in up and co - up ). if the problem is np - complete\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  general number field sieve\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  it is possible that all these complexity classes collapse to one class\n",
      "Actual Answer:  ['suspected to be unequal', 'unequal', 'Many known complexity classes are suspected to be unequal']\n",
      "\n",
      "Model Response:  unequal\n",
      "Actual Answer:  ['P ⊆ NP ⊆ PP ⊆ PSPACE', 'P ⊆ NP ⊆ PP ⊆ PSPACE', 'P ⊆ NP ⊆ PP ⊆ PSPACE']\n",
      "\n",
      "Model Response:  p and pspace\n",
      "Actual Answer:  ['between P and PSPACE', 'between P and PSPACE', 'between P and PSPACE']\n",
      "\n",
      "Model Response:  any of these classes are unequal\n",
      "Actual Answer:  ['Proving that any of these classes are unequal', 'Proving that any of these classes are unequal', 'Proving that any of these classes are unequal']\n",
      "\n",
      "Model Response:  unequal\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  unequal\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  p and pspace\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  collapse to one class\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  proving that any of these classes are unequal\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  co - np\n",
      "Actual Answer:  ['co-NP', 'co-NP', 'co-NP']\n",
      "\n",
      "Model Response:  reversed\n",
      "Actual Answer:  ['reversed', 'reversed', 'reversed']\n",
      "\n",
      "Model Response:  np is not equal to co - np\n",
      "Actual Answer:  ['not equal', 'not equal', 'not equal']\n",
      "\n",
      "Model Response:  p is not equal to np\n",
      "Actual Answer:  ['P is not equal to NP', 'not equal', 'P is not equal to NP']\n",
      "\n",
      "Model Response:  co - np\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  reversed\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  np is not equal to co - np\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  it has not yet been proven. it has been shown that if these two complexity classes are not equal then p is not equal to np\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  l\n",
      "Actual Answer:  ['L', 'L', 'L']\n",
      "\n",
      "Model Response:  nl and nc, and it is not known if they are distinct or equal classes\n",
      "Actual Answer:  ['strictly contained in P or equal to P', 'contained in P or equal to P.', 'strictly contained in P or equal to P']\n",
      "\n",
      "Model Response:  many complexity classes\n",
      "Actual Answer:  ['complexity classes', 'many complexity classes', 'many complexity classes']\n",
      "\n",
      "Model Response:  nl and nc\n",
      "Actual Answer:  ['NL and NC', 'NL and NC', 'NL and NC']\n",
      "\n",
      "Model Response:  it is not known if they are distinct or equal classes\n",
      "Actual Answer:  ['if they are distinct or equal classes', 'if they are distinct or equal classes', 'if they are distinct or equal classes']\n",
      "\n",
      "Model Response:  l\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  distinct or equal classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  distinct or equal classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  nl and nc\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  it is not known if they are distinct or equal classes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  intractable problems\n",
      "Actual Answer:  ['intractable problems', 'intractable problems', 'intractable', 'intractable']\n",
      "\n",
      "Model Response:  polynomial time\n",
      "Actual Answer:  ['exponential-time algorithms', 'exponential-time', 'exponential-time algorithms', 'exponential-time algorithms']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['NP-complete problems', 'NP-complete', 'NP-complete', 'NP-complete']\n",
      "\n",
      "Model Response:  intractable problems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  take too long\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cobham – edmonds thesis\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  with a much faster computer\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  polynomial time\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  presburger\n",
      "Actual Answer:  ['Presburger arithmetic', 'Presburger', 'Presburger arithmetic']\n",
      "\n",
      "Model Response:  algorithms\n",
      "Actual Answer:  ['algorithms have been written', 'algorithms have been written', 'algorithms have been written that solve the problem in reasonable times in most cases']\n",
      "\n",
      "Model Response:  np - complete knapsack\n",
      "Actual Answer:  ['NP-complete knapsack problem', 'NP-complete knapsack', 'the NP-complete knapsack problem']\n",
      "\n",
      "Model Response:  over a wide range of sizes in less than quadratic time\n",
      "Actual Answer:  ['in less than quadratic time', 'less than quadratic time', 'less than quadratic time']\n",
      "\n",
      "Model Response:  np - complete knapsack problem\n",
      "Actual Answer:  ['NP-complete Boolean satisfiability problem', 'NP-complete Boolean satisfiability', 'the NP-complete Boolean satisfiability problem']\n",
      "\n",
      "Model Response:  presburger\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  algorithms\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  algorithms\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  large instances of the np - complete boolean satisfiability problem\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  numerous foundations\n",
      "Actual Answer:  ['foundations were laid out', 'numerous foundations were laid out', 'numerous foundations were laid out by various researchers']\n",
      "\n",
      "Model Response:  alan turing\n",
      "Actual Answer:  ['Alan Turing', 'Alan Turing', 'Alan Turing']\n",
      "\n",
      "Model Response:  turing machines\n",
      "Actual Answer:  ['Turing machines', 'Turing machines', 'Turing machines']\n",
      "\n",
      "Model Response:  1936\n",
      "Actual Answer:  ['1936', '1936', '1936']\n",
      "\n",
      "Model Response:  a very robust and flexible simplification of a computer\n",
      "Actual Answer:  ['a computer', 'a computer', 'a computer']\n",
      "\n",
      "Model Response:  numerous foundations\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  alan turing\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  turing machines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \" on the computational complexity of algorithms\n",
      "Actual Answer:  ['On the Computational Complexity of Algorithms', 'On the Computational Complexity of Algorithms', '\"On the Computational Complexity of Algorithms\"']\n",
      "\n",
      "Model Response:  juris hartmanis and richard stearns\n",
      "Actual Answer:  ['Juris Hartmanis and Richard Stearns', 'Juris Hartmanis and Richard Stearns', 'Juris Hartmanis and Richard Stearns']\n",
      "\n",
      "Model Response:  1965\n",
      "Actual Answer:  ['1965', '1965', '1965']\n",
      "\n",
      "Model Response:  time and space complexity\n",
      "Actual Answer:  ['time and space', 'definitions of time and space complexity', 'time and space complexity']\n",
      "\n",
      "Model Response:  1965\n",
      "Actual Answer:  ['1965', '1965', '1965']\n",
      "\n",
      "Model Response:  \" on the computational complexity of algorithms\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  juris hartmanis and richard stearns\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \" on the computational complexity of algorithms \"\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  time and space complexity\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  john myhill\n",
      "Actual Answer:  ['John Myhill', 'John Myhill', 'John Myhill']\n",
      "\n",
      "Model Response:  1961\n",
      "Actual Answer:  ['1961', '1961', '1961']\n",
      "\n",
      "Model Response:  hisao yamada\n",
      "Actual Answer:  ['Hisao Yamada', 'Hisao Yamada', 'Hisao Yamada']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  john myhill\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1961\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hisao yamada\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  boris trakhtenbrot\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  input encoding\n",
      "Actual Answer:  ['input encoding', 'input encoding', 'input encoding']\n",
      "\n",
      "Model Response:  discussion\n",
      "Actual Answer:  ['encoding', 'encoding', 'encoding']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  input encoding\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  complexity - theoretic theorems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  input encoding, one tries to keep the discussion\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  manuel blum\n",
      "Actual Answer:  ['Manuel Blum', 'Manuel Blum', 'Manuel Blum']\n",
      "\n",
      "Model Response:  speed - up theorem\n",
      "Actual Answer:  ['speed-up theorem', 'speed-up theorem', 'speed-up theorem']\n",
      "\n",
      "Model Response:  reducibility among combinatorial problems \"\n",
      "Actual Answer:  ['\"Reducibility Among Combinatorial Problems\"', 'Reducibility Among Combinatorial Problems', '\"Reducibility Among Combinatorial Problems\"']\n",
      "\n",
      "Model Response:  21\n",
      "Actual Answer:  ['21', '21', '21']\n",
      "\n",
      "Model Response:  manuel blum\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  manuel blum\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  stephen cook\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  richard karp\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  reducibility among combinatorial problems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  socal\n",
      "Actual Answer:  ['SoCal', 'SoCal', 'SoCal']\n",
      "\n",
      "Model Response:  10\n",
      "Actual Answer:  ['10 counties', '10', '10']\n",
      "\n",
      "Model Response:  economic\n",
      "Actual Answer:  ['economic center', 'major economic center', 'economic center']\n",
      "\n",
      "Model Response:  demographics and economic ties : imperial, los angeles, orange, riverside, san bernardino, san diego, santa barbara, and ventura\n",
      "Actual Answer:  ['demographics and economic ties', 'economic', 'demographics and economic']\n",
      "\n",
      "Model Response:  historical political divisions\n",
      "Actual Answer:  ['historical political divisions', 'historical political divisions', 'historical political divisions']\n",
      "\n",
      "Model Response:  kern and san luis obispo counties\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  kern and san luis obispo counties\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  greater southern california megaregion\n",
      "Actual Answer:  ['Southern California Megaregion', 'the greater Southern California Megaregion', 'Southern California Megaregion']\n",
      "\n",
      "Model Response:  11\n",
      "Actual Answer:  ['11', '11', '11']\n",
      "\n",
      "Model Response:  las vegas, nevada\n",
      "Actual Answer:  ['Nevada', 'Nevada', 'Nevada']\n",
      "\n",
      "Model Response:  mexican border\n",
      "Actual Answer:  ['Mexican', 'Mexican', 'Mexican']\n",
      "\n",
      "Model Response:  tijuana\n",
      "Actual Answer:  ['Tijuana', 'Tijuana', 'Tijuana']\n",
      "\n",
      "Model Response:  greater southern california megaregion\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  las vegas, nevada, and south across the mexican border into tijuana\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  11 megaregions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pacific coast\n",
      "Actual Answer:  ['Pacific', 'Pacific', 'Pacific']\n",
      "\n",
      "Model Response:  seven\n",
      "Actual Answer:  ['seven', 'seven', 'seven']\n",
      "\n",
      "Model Response:  12 million\n",
      "Actual Answer:  ['12 million', 'over 12 million inhabitants', '12 million']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['San Diego', 'the San Diego area', 'San Diego']\n",
      "\n",
      "Model Response:  17. 5 million\n",
      "Actual Answer:  ['17.5 million', 'over 17.5 million', '17.5 million']\n",
      "\n",
      "Model Response:  60 percent\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  msas : the los angeles metropolitan area, consisting of los angeles and orange counties ; the inland empire\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  over four million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  msas : the los angeles metropolitan area, consisting of los angeles and orange counties ; the inland empire\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  colorado desert\n",
      "Actual Answer:  ['Colorado River', 'the Colorado River', 'Colorado River']\n",
      "\n",
      "Model Response:  mojave desert\n",
      "Actual Answer:  ['Colorado Desert', 'the Colorado Desert', 'Colorado Desert']\n",
      "\n",
      "Model Response:  mojave desert\n",
      "Actual Answer:  ['Mojave Desert', 'the Mojave Desert', 'Mojave Desert']\n",
      "\n",
      "Model Response:  mexico – united states border\n",
      "Actual Answer:  ['Mexico–United States border', 'the Mexico–United States border', 'Mexico–United States border']\n",
      "\n",
      "Model Response:  mexico – united states border\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mexico – united states border\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  south\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  ['California', 'California', 'California']\n",
      "\n",
      "Model Response:  3, 792, 621\n",
      "Actual Answer:  ['3,792,621', '3,792,621', '3,792,621']\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Los Angeles', 'Los Angeles', 'Los Angeles']\n",
      "\n",
      "Model Response:  san diego\n",
      "Actual Answer:  ['San Diego', 'San Diego', 'San Diego']\n",
      "\n",
      "Model Response:  south\n",
      "Actual Answer:  ['south', 'south']\n",
      "\n",
      "Model Response:  los angeles and san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Los Angeles', 'Los Angeles', 'Riverside']\n",
      "\n",
      "Model Response:  united states\n",
      "Actual Answer:  ['United States', 'the United States', 'Los Angeles']\n",
      "\n",
      "Model Response:  its counties\n",
      "Actual Answer:  ['counties', 'counties', 'five most populous in the state']\n",
      "\n",
      "Model Response:  top 15\n",
      "Actual Answer:  ['15', '15', 'Riverside']\n",
      "\n",
      "Model Response:  los angeles, orange, san diego, san bernardino, and riverside\n",
      "Actual Answer:  ['counties', 'Riverside']\n",
      "\n",
      "Model Response:  los angeles, orange, san diego, san bernardino, and riverside\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  15\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  five most populous in the state and all are in the top 15 most populous counties\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hollywood\n",
      "Actual Answer:  ['Hollywood', 'Hollywood', 'Hollywood']\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Los Angeles', 'Los Angeles', 'Los Angeles']\n",
      "\n",
      "Model Response:  walt disney company\n",
      "Actual Answer:  ['The Walt Disney Company', 'The Walt Disney Company', 'The Walt Disney Company']\n",
      "\n",
      "Model Response:  music\n",
      "Actual Answer:  ['music', 'major record companies']\n",
      "\n",
      "Model Response:  sony\n",
      "Actual Answer:  ['Sony', 'Sony', 'Sony']\n",
      "\n",
      "Model Response:  walt disney company\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  motion picture, television, and music\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hollywood\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  walt disney company ( which also owns abc ), sony pictures, universal, mgm, paramount pictures, 20th century fox, and warner brothers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  skateboard\n",
      "Actual Answer:  ['skateboard', 'skateboard', 'skateboard']\n",
      "\n",
      "Model Response:  tony hawk\n",
      "Actual Answer:  ['Tony Hawk', 'Tony Hawk', 'Tony Hawk']\n",
      "\n",
      "Model Response:  shaun white\n",
      "Actual Answer:  ['Shaun White', 'Shaun White', 'Shaun White']\n",
      "\n",
      "Model Response:  oahu\n",
      "Actual Answer:  ['Oahu', 'Oahu', 'Oahu']\n",
      "\n",
      "Model Response:  transpacific yacht race\n",
      "Actual Answer:  ['Transpac', 'Transpac', 'Transpac']\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  professional surfers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  america's cup\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  palm springs\n",
      "Actual Answer:  ['Palm Springs', 'Palm Springs', 'Palm Springs']\n",
      "\n",
      "Model Response:  popular beaches\n",
      "Actual Answer:  ['beaches', 'for its popular beaches', 'beaches']\n",
      "\n",
      "Model Response:  southern\n",
      "Actual Answer:  ['southern', 'the desert', 'southern']\n",
      "\n",
      "Model Response:  open spaces\n",
      "Actual Answer:  ['open spaces', 'nearby open spaces', 'nearby open spaces']\n",
      "\n",
      "Model Response:  many locals and tourists\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  beaches\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  37° 9'58. 23 \"\n",
      "Actual Answer:  ['37° 9\\' 58.23\"', '37° 9\\' 58.23\"', '37° 9\\' 58.23\"']\n",
      "\n",
      "Model Response:  11\n",
      "Actual Answer:  ['11', '11', '11']\n",
      "\n",
      "Model Response:  ten\n",
      "Actual Answer:  ['ten', 'ten', 'ten']\n",
      "\n",
      "Model Response:  tehachapi mountains\n",
      "Actual Answer:  ['Tehachapi Mountains', 'Tehachapi Mountains']\n",
      "\n",
      "Model Response:  northern\n",
      "Actual Answer:  ['northern', 'the Tehachapi Mountains', 'northern']\n",
      "\n",
      "Model Response:  california's north - south midway point\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  midway point\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  county lines\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mexico\n",
      "Actual Answer:  ['Mexico', 'Mexico', 'Mexico']\n",
      "\n",
      "Model Response:  alta california\n",
      "Actual Answer:  ['Alta California', 'Alta California', 'Alta California']\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Monterey', 'Monterey', 'Monterey']\n",
      "\n",
      "Model Response:  the compromise of 1850\n",
      "Actual Answer:  ['the Missouri Compromise', 'the Compromise of 1850', 'Compromise of 1850']\n",
      "\n",
      "Model Response:  free\n",
      "Actual Answer:  ['free', 'a free state', 'free']\n",
      "\n",
      "Model Response:  mexico\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  californios of monterey in the upper part and los angeles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  line of the missouri compromise\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the compromise of 1850\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  inequitable taxes\n",
      "Actual Answer:  ['inequitable taxes', 'inequitable taxes', 'inequitable taxes']\n",
      "\n",
      "Model Response:  cow counties\n",
      "Actual Answer:  ['Cow Counties', 'Cow Counties', 'Cow Counties']\n",
      "\n",
      "Model Response:  three\n",
      "Actual Answer:  ['three', 'three', 'three']\n",
      "\n",
      "Model Response:  75 %\n",
      "Actual Answer:  ['75', '75%', '75']\n",
      "\n",
      "Model Response:  milton latham\n",
      "Actual Answer:  ['Milton Latham', 'Milton Latham', 'Milton Latham']\n",
      "\n",
      "Model Response:  californios\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the pico act of 1859\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  john b. weller\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  john b. weller\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  senator\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles times\n",
      "Actual Answer:  ['Los Angeles Times', 'the Los Angeles Times', 'Los Angeles Times']\n",
      "\n",
      "Model Response:  1900\n",
      "Actual Answer:  ['1900', '1900', '1900']\n",
      "\n",
      "Model Response:  1999\n",
      "Actual Answer:  ['1999', '1999', '1999']\n",
      "\n",
      "Model Response:  imperial\n",
      "Actual Answer:  ['Imperial', 'Imperial', '1999']\n",
      "\n",
      "Model Response:  seven\n",
      "Actual Answer:  ['seven', 'seven', 'seven']\n",
      "\n",
      "Model Response:  \" the seven counties of los angeles, san bernardino, orange, riverside, san diego, ventura and santa barbara. \"\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a newer county — imperial\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  regional tourism groups\n",
      "Actual Answer:  ['regional tourism groups', 'regional tourism groups', 'AAA Auto Clubs']\n",
      "\n",
      "Model Response:  california state automobile association\n",
      "Actual Answer:  ['California State Automobile Association', 'the California State Automobile Association', 'California State Automobile Association']\n",
      "\n",
      "Model Response:  three - region\n",
      "Actual Answer:  ['three-region', 'the three-region point of view', 'three-region']\n",
      "\n",
      "Model Response:  tehachapis\n",
      "Actual Answer:  ['Tehachapis', 'the Tehachapis', 'Tehachapis']\n",
      "\n",
      "Model Response:  southern california region\n",
      "Actual Answer:  ['southern', 'southern California', 'southern California']\n",
      "\n",
      "Model Response:  aaa auto clubs\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  aaa auto clubs\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  geographical phrase\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  regional tourism groups\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  third\n",
      "Actual Answer:  ['third', 'third', 'third']\n",
      "\n",
      "Model Response:  vast areas\n",
      "Actual Answer:  ['vast areas', 'vast areas', 'vast areas']\n",
      "\n",
      "Model Response:  suburban\n",
      "Actual Answer:  ['suburban', 'suburban', 'suburban communities and use of automobiles and highways']\n",
      "\n",
      "Model Response:  highways\n",
      "Actual Answer:  ['highways', 'highways']\n",
      "\n",
      "Model Response:  international metropolitan region\n",
      "Actual Answer:  ['international metropolitan', 'an international metropolitan region', 'international metropolitan']\n",
      "\n",
      "Model Response:  great lakes megalopolis and the northeastern megalopolis\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles, orange county, san diego, and riverside - san bernardino\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san diego – tijuana\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  camp pendleton\n",
      "Actual Answer:  ['Camp Pendleton', 'Camp Pendleton', 'Camp Pendleton']\n",
      "\n",
      "Model Response:  inland empire\n",
      "Actual Answer:  ['Inland Empire', 'Temecula and Murrieta']\n",
      "\n",
      "Model Response:  united states census bureau\n",
      "Actual Answer:  ['United States Census Bureau', 'the United States Census Bureau', 'United States Census Bureau']\n",
      "\n",
      "Model Response:  orange\n",
      "Actual Answer:  ['Orange', 'Orange Counties', 'Orange']\n",
      "\n",
      "Model Response:  1990s\n",
      "Actual Answer:  ['1990s', '1990s', '1990s']\n",
      "\n",
      "Model Response:  exurbs\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  l. a. and orange counties\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  exurbs\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  santa maria and san luis obispo\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mediterranean\n",
      "Actual Answer:  ['Mediterranean', 'a Mediterranean climate', 'Mediterranean']\n",
      "\n",
      "Model Response:  rain\n",
      "Actual Answer:  ['infrequent rain', 'infrequent rain', 'infrequent rain']\n",
      "\n",
      "Model Response:  90 - 60's\n",
      "Actual Answer:  [\"60's\", \"60's\", \"60's\"]\n",
      "\n",
      "Model Response:  very rare\n",
      "Actual Answer:  ['very rare', 'very rare', 'very rare']\n",
      "\n",
      "Model Response:  70 - 50's\n",
      "Actual Answer:  ['70', '70', '70']\n",
      "\n",
      "Model Response:  mediterranean\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  all of southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  summers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  snow\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  geologic, topographic, and natural ecosystem\n",
      "Actual Answer:  ['varied', 'varied', 'natural ecosystem']\n",
      "\n",
      "Model Response:  pacific ocean\n",
      "Actual Answer:  ['Pacific Ocean', 'Pacific Ocean', 'Pacific Ocean']\n",
      "\n",
      "Model Response:  geologic, topographic, and natural ecosystem\n",
      "Actual Answer:  ['topographic', 'topographic', 'topographic']\n",
      "\n",
      "Model Response:  peninsular\n",
      "Actual Answer:  ['Peninsular', 'Peninsular Ranges', 'Peninsular Ranges']\n",
      "\n",
      "Model Response:  transverse and peninsular ranges\n",
      "Actual Answer:  ['valleys', 'valleys', 'interior valleys']\n",
      "\n",
      "Model Response:  geologic, topographic, and natural ecosystem landscapes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pacific ocean\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pacific ocean\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  10, 000\n",
      "Actual Answer:  ['10,000', '10,000', '10,000']\n",
      "\n",
      "Model Response:  10, 000\n",
      "Actual Answer:  ['small', 'small', 'small']\n",
      "\n",
      "Model Response:  6. 7\n",
      "Actual Answer:  ['6.7', '6.7', '6.7']\n",
      "\n",
      "Model Response:  property\n",
      "Actual Answer:  ['property damage', 'property damage']\n",
      "\n",
      "Model Response:  $ 20 billion\n",
      "Actual Answer:  ['$20 billion', 'over $20 billion', 'over $20 billion']\n",
      "\n",
      "Model Response:  1994\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  northridge earthquake\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  10, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  15 – 20\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san andreas fault\n",
      "Actual Answer:  ['San Andreas', 'the San Andreas Fault', 'San Andreas Fault']\n",
      "\n",
      "Model Response:  6. 7 +\n",
      "Actual Answer:  ['6.7', '6.7+', '6.7+']\n",
      "\n",
      "Model Response:  the puente hills fault\n",
      "Actual Answer:  ['Puente Hills', 'the Puente Hills Fault', 'Puente Hills Fault']\n",
      "\n",
      "Model Response:  usgs\n",
      "Actual Answer:  ['USGS', 'The USGS', 'USGS']\n",
      "\n",
      "Model Response:  earthquake occurrence\n",
      "Actual Answer:  ['occurrence', 'occurrence', 'occurrence']\n",
      "\n",
      "Model Response:  san andreas fault\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san andreas fault\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  california earthquake forecast\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  earthquake occurrence in california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  economically\n",
      "Actual Answer:  ['economically', 'economically', 'economically']\n",
      "\n",
      "Model Response:  global\n",
      "Actual Answer:  ['global', 'global', 'global']\n",
      "\n",
      "Model Response:  economic\n",
      "Actual Answer:  ['economic', 'economic', 'economic activity']\n",
      "\n",
      "Model Response:  a city\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the hub of economic activity\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  culturally, politically, and economically into distinctive regions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2010\n",
      "Actual Answer:  ['2010', '2010', '2010']\n",
      "\n",
      "Model Response:  high growth rates\n",
      "Actual Answer:  ['high growth rates', 'high growth rates', 'high growth rates']\n",
      "\n",
      "Model Response:  10. 0 %\n",
      "Actual Answer:  ['10.0%', '10.0%', '10.0%']\n",
      "\n",
      "Model Response:  tech\n",
      "Actual Answer:  ['tech-oriented', 'tech-oriented']\n",
      "\n",
      "Model Response:  sacramento\n",
      "Actual Answer:  ['Greater Sacramento', 'Greater Sacramento', 'Greater Sacramento']\n",
      "\n",
      "Model Response:  2010 united states census\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  10. 0 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  tech\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sacramento\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  metropolitan statistical areas\n",
      "Actual Answer:  ['Metropolitan Statistical Areas', 'Metropolitan Statistical Areas', 'Metropolitan Statistical Areas']\n",
      "\n",
      "Model Response:  two\n",
      "Actual Answer:  ['two', 'two', 'two']\n",
      "\n",
      "Model Response:  five million\n",
      "Actual Answer:  ['five million', 'five million', 'five million']\n",
      "\n",
      "Model Response:  southern border region\n",
      "Actual Answer:  ['Southern Border Region', 'the Southern Border Region', 'Southern Border Region']\n",
      "\n",
      "Model Response:  17, 786, 419\n",
      "Actual Answer:  ['17,786,419', '17,786,419', '17,786,419']\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  greater los angeles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san diego – tijuana\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  santa barbara, san luis obispo, and bakersfield metropolitan areas\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Los Angeles', 'Los Angeles', 'Los Angeles']\n",
      "\n",
      "Model Response:  100, 000\n",
      "Actual Answer:  ['1.3 million', '1.3 million', 'San Diego']\n",
      "\n",
      "Model Response:  34\n",
      "Actual Answer:  ['twelve', 'twelve', 'twelve']\n",
      "\n",
      "Model Response:  100, 000\n",
      "Actual Answer:  ['100,000', '100,000', '100,000']\n",
      "\n",
      "Model Response:  riverside\n",
      "Actual Answer:  ['Riverside', 'Riverside', 'Riverside']\n",
      "\n",
      "Model Response:  los angeles ( at 3. 7 million people ) and san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles ( at 3. 7 million people ) and san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  petroleum\n",
      "Actual Answer:  ['petroleum', 'petroleum', 'petroleum']\n",
      "\n",
      "Model Response:  hollywood\n",
      "Actual Answer:  ['Hollywood', 'Hollywood', 'Hollywood']\n",
      "\n",
      "Model Response:  housing bubble\n",
      "Actual Answer:  ['the housing bubble', 'the housing bubble']\n",
      "\n",
      "Model Response:  diverse\n",
      "Actual Answer:  ['diverse', 'diverse', 'diverse']\n",
      "\n",
      "Model Response:  heavily impacted\n",
      "Actual Answer:  ['heavily impacted', 'heavily impacted']\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the housing bubble\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  petroleum\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1920s\n",
      "Actual Answer:  ['1920s', '1920s', '1920s']\n",
      "\n",
      "Model Response:  suburbs\n",
      "Actual Answer:  ['richest', 'rich', 'one of the richest']\n",
      "\n",
      "Model Response:  cattle\n",
      "Actual Answer:  ['cattle', 'cattle', 'cattle']\n",
      "\n",
      "Model Response:  citrus\n",
      "Actual Answer:  ['citrus', 'citrus', 'citrus']\n",
      "\n",
      "Model Response:  aerospace\n",
      "Actual Answer:  ['aerospace', 'aerospace', 'aerospace']\n",
      "\n",
      "Model Response:  motion pictures, petroleum and aircraft manufacturing\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cattle and citrus\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  military spending cutbacks\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1920s\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  major business districts\n",
      "Actual Answer:  ['business', 'major business', 'major business']\n",
      "\n",
      "Model Response:  central business districts\n",
      "Actual Answer:  ['Central business districts', 'Central business districts', 'Central business districts']\n",
      "\n",
      "Model Response:  downtown los angeles, downtown san diego\n",
      "Actual Answer:  ['South Coast Metro', 'South Coast Metro', 'South Coast Metro']\n",
      "\n",
      "Model Response:  cbd\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  central business districts\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cbd\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  business districts\n",
      "Actual Answer:  ['business', 'major business districts', 'major business']\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Los Angeles Area', 'the Los Angeles Area', 'major business']\n",
      "\n",
      "Model Response:  san fernando valley\n",
      "Actual Answer:  ['San Fernando Valley', 'the San Fernando Valley', 'San Fernando Valley']\n",
      "\n",
      "Model Response:  los angeles\n",
      "Actual Answer:  ['Los Angeles', 'Los Angeles', 'Los Angeles']\n",
      "\n",
      "Model Response:  downtown burbank, downtown santa monica, downtown glendale and downtown long beach. los angeles itself has many business districts including the downtown los angeles central business district\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles central business district\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  downtown los angeles central business district\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  business districts\n",
      "Actual Answer:  ['business', 'business districts', 'business']\n",
      "\n",
      "Model Response:  downtown riverside\n",
      "Actual Answer:  ['Riverside', 'Riverside', 'Downtown Riverside']\n",
      "\n",
      "Model Response:  hospitality business / financial centre\n",
      "Actual Answer:  ['Hospitality Business/Financial Centre', 'Downtown Riverside', 'Hospitality Business/Financial Centre']\n",
      "\n",
      "Model Response:  downtown san bernardino, hospitality business / financial centre\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  downtown san bernardino, hospitality business / financial centre\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  orange county\n",
      "Actual Answer:  ['Orange', 'Orange County', 'Orange County']\n",
      "\n",
      "Model Response:  university of california, irvine\n",
      "Actual Answer:  ['University of California, Irvine', 'the University of California, Irvine', 'University of California']\n",
      "\n",
      "Model Response:  irvine tech center\n",
      "Actual Answer:  ['West Irvine', 'West Irvine', 'West Irvine']\n",
      "\n",
      "Model Response:  south coast metro\n",
      "Actual Answer:  ['South Coast Metro', 'the South Coast Metro', 'South Coast Metro']\n",
      "\n",
      "Model Response:  rapidly\n",
      "Actual Answer:  ['rapidly', 'rapidly', 'rapidly']\n",
      "\n",
      "Model Response:  orange county\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  newport center districts\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  irvine spectrum, west irvine, and international corporations\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  west irvine\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  downtown san diego\n",
      "Actual Answer:  ['Downtown San Diego', 'Downtown San Diego', 'Downtown']\n",
      "\n",
      "Model Response:  northern san diego\n",
      "Actual Answer:  ['Northern San Diego', 'Northern San Diego', 'Northern San Diego']\n",
      "\n",
      "Model Response:  north county\n",
      "Actual Answer:  ['North County', 'North County', 'North County regions']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['San Diego', 'San Diego', 'San Diego']\n",
      "\n",
      "Model Response:  downtown san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  most of these districts are located in northern san diego and some within north county regions\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  carmel valley, del mar heights, mission valley, rancho bernardo, sorrento mesa, and university city\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles international airport\n",
      "Actual Answer:  ['Los Angeles International Airport', 'Los Angeles International Airport', 'Los Angeles International Airport']\n",
      "\n",
      "Model Response:  passenger volume\n",
      "Actual Answer:  ['passenger volume', 'passenger volume', 'passenger volume']\n",
      "\n",
      "Model Response:  third\n",
      "Actual Answer:  ['third', 'third', 'third']\n",
      "\n",
      "Model Response:  san diego international airport\n",
      "Actual Answer:  ['San Diego International Airport', 'San Diego International Airport', 'San Diego International Airport']\n",
      "\n",
      "Model Response:  van nuys airport\n",
      "Actual Answer:  ['Van Nuys Airport', 'Van Nuys Airport', 'Van Nuys Airport']\n",
      "\n",
      "Model Response:  los angeles international airport\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san diego international airport\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  van nuys airport\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  orange county, bakersfield, ontario, burbank and long beach\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  metrolink\n",
      "Actual Answer:  ['Metrolink', 'Metrolink', 'Metrolink']\n",
      "\n",
      "Model Response:  seven\n",
      "Actual Answer:  ['seven', 'seven', 'seven']\n",
      "\n",
      "Model Response:  six\n",
      "Actual Answer:  ['Six', 'Six', 'Six']\n",
      "\n",
      "Model Response:  san diego\n",
      "Actual Answer:  ['Orange', 'Orange', 'Orange']\n",
      "\n",
      "Model Response:  downtown los angeles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  metrolink\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  port of los angeles\n",
      "Actual Answer:  ['Port of Los Angeles', 'the Port of Los Angeles', 'Port of Los Angeles']\n",
      "\n",
      "Model Response:  port of long beach\n",
      "Actual Answer:  ['Port of San Diego', 'Port of Long Beach', 'Port of Long Beach']\n",
      "\n",
      "Model Response:  southern california\n",
      "Actual Answer:  ['Southern', 'Southern California', 'Southern']\n",
      "\n",
      "Model Response:  port of los angeles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  port of long beach\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  port of long beach\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the tech coast\n",
      "Actual Answer:  ['The Tech Coast', 'The Tech Coast', 'Tech Coast']\n",
      "\n",
      "Model Response:  research universities\n",
      "Actual Answer:  ['research', 'research', 'research']\n",
      "\n",
      "Model Response:  private\n",
      "Actual Answer:  ['private', 'private', 'private']\n",
      "\n",
      "Model Response:  5\n",
      "Actual Answer:  ['5', '5', '5']\n",
      "\n",
      "Model Response:  12\n",
      "Actual Answer:  ['12', '12', '12']\n",
      "\n",
      "Model Response:  irvine, los angeles, riverside, santa barbara, and san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  5\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  12\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  university of redlands, university of san diego\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  northridge\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  nfl\n",
      "Actual Answer:  ['NFL', 'Professional', 'NFL']\n",
      "\n",
      "Model Response:  nba\n",
      "Actual Answer:  ['NBA', 'NBA', 'NBA']\n",
      "\n",
      "Model Response:  mlb\n",
      "Actual Answer:  ['MLB', 'MLB', 'MLB']\n",
      "\n",
      "Model Response:  los angeles kings\n",
      "Actual Answer:  ['Los Angeles Kings', 'Los Angeles Kings', 'Los Angeles Kings']\n",
      "\n",
      "Model Response:  la galaxy\n",
      "Actual Answer:  ['LA Galaxy', 'LA Galaxy', 'LA Galaxy']\n",
      "\n",
      "Model Response:  los angeles rams, san diego chargers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles rams, san diego chargers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles rams, san diego chargers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles rams, san diego chargers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  los angeles rams, san diego chargers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  chivas\n",
      "Actual Answer:  ['Chivas USA', 'Chivas', 'Chivas']\n",
      "\n",
      "Model Response:  two\n",
      "Actual Answer:  ['two', 'two', 'two']\n",
      "\n",
      "Model Response:  2014\n",
      "Actual Answer:  ['2014', '2014', '2014']\n",
      "\n",
      "Model Response:  stubhub center\n",
      "Actual Answer:  ['StubHub Center', 'the StubHub Center', 'StubHub Center']\n",
      "\n",
      "Model Response:  2018\n",
      "Actual Answer:  ['2018', 'in 2018', '2018']\n",
      "\n",
      "Model Response:  two\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  la galaxy and chivas usa\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2014 mls season\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2018\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  college sports\n",
      "Actual Answer:  ['College', 'College', 'College']\n",
      "\n",
      "Model Response:  usc trojans\n",
      "Actual Answer:  ['UCLA', 'UCLA', 'UCLA']\n",
      "\n",
      "Model Response:  trojans\n",
      "Actual Answer:  ['Trojans', 'Trojans', 'Trojans']\n",
      "\n",
      "Model Response:  pac - 12\n",
      "Actual Answer:  ['Pac-12', 'the Pac-12', 'Pac-12']\n",
      "\n",
      "Model Response:  pac - 12\n",
      "Actual Answer:  ['Division I', 'Division I', 'Division I']\n",
      "\n",
      "Model Response:  ucla bruins\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ucla bruins\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pac - 12\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  rugby\n",
      "Actual Answer:  ['Rugby', 'Rugby', 'Rugby']\n",
      "\n",
      "Model Response:  high school\n",
      "Actual Answer:  ['high school', 'high school', 'high school']\n",
      "\n",
      "Model Response:  an official school sport\n",
      "Actual Answer:  ['an official school sport', 'an official school', 'official school sport']\n",
      "\n",
      "Model Response:  rugby\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  ['BSkyB', 'BSkyB', 'BSkyB']\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  ['BSkyB', 'BSkyB', 'BSkyB']\n",
      "\n",
      "Model Response:  2014\n",
      "Actual Answer:  ['2014', '2014', '2014']\n",
      "\n",
      "Model Response:  british sky broadcasting group plc\n",
      "Actual Answer:  ['Sky plc', 'British Sky Broadcasting Group plc', 'British Sky Broadcasting Group plc']\n",
      "\n",
      "Model Response:  british sky broadcasting limited\n",
      "Actual Answer:  ['Sky UK Limited', 'Sky UK Limited', 'Sky UK Limited']\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2014\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  november 1990\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky uk limited\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2006\n",
      "Actual Answer:  ['2006', '2006', '2006']\n",
      "\n",
      "Model Response:  two\n",
      "Actual Answer:  ['two', 'two', 'two']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['Sky', 'Sky', 'Sky']\n",
      "\n",
      "Model Response:  £1. 3bn\n",
      "Actual Answer:  ['£1.3bn', '£1.3bn', '£4.2bn']\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  two\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  four\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  £1bn\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  3d\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ondigital consortium\n",
      "Actual Answer:  ['ONdigital', 'ONdigital', 'ONdigital']\n",
      "\n",
      "Model Response:  itv digital\n",
      "Actual Answer:  ['Freeview', 'ITV Digital', 'ITV Digital']\n",
      "\n",
      "Model Response:  three\n",
      "Actual Answer:  ['three', 'three', 'three']\n",
      "\n",
      "Model Response:  sky three\n",
      "Actual Answer:  ['Sky Three', 'Sky Three', 'Sky Three']\n",
      "\n",
      "Model Response:  pick tv\n",
      "Actual Answer:  ['Pick TV', 'Pick TV', 'Pick TV']\n",
      "\n",
      "Model Response:  ondigital consortium\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky three\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky news, sky three, and sky sports news. initially bskyb provided sky travel to the service. however, this was replaced by sky three\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  itv digital\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pick tv\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky + pvr\n",
      "Actual Answer:  ['Sky+ PVR', 'Sky+ PVR', 'Sky+ PVR']\n",
      "\n",
      "Model Response:  september 2007\n",
      "Actual Answer:  ['September 2007', 'September 2007', 'March 2008']\n",
      "\n",
      "Model Response:  can still pay a monthly fee\n",
      "Actual Answer:  ['monthly fee', 'a monthly fee', 'SkyHD box']\n",
      "\n",
      "Model Response:  january 2010\n",
      "Actual Answer:  ['January 2010', 'In January 2010', 'February 2011']\n",
      "\n",
      "Model Response:  sky + hd box\n",
      "Actual Answer:  ['Sky+HD Box', 'Sky+HD Box', 'Sky+HD Box']\n",
      "\n",
      "Model Response:  sky + pvr with their service ; waiving the charge for subscribers whose package included two or more premium channels. this changed as from 1 july 2007, and now customers that have sky + and subscribe to any bskyb subscription package get sky +\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  september 2007\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a monthly fee\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  multiroom box\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  videoguard\n",
      "Actual Answer:  ['VideoGuard', 'VideoGuard pay-TV', 'VideoGuard']\n",
      "\n",
      "Model Response:  nds\n",
      "Actual Answer:  ['NDS', 'NDS', 'NDS']\n",
      "\n",
      "Model Response:  cisco systems company\n",
      "Actual Answer:  ['Cisco Systems', 'Cisco Systems', 'Cisco Systems company']\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  ['BSkyB', 'BSkyB', 'BSkyB']\n",
      "\n",
      "Model Response:  sky +\n",
      "Actual Answer:  ['Sky+', 'Sky+', 'PVR']\n",
      "\n",
      "Model Response:  videoguard\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  conditional - access modules\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cisco systems\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky +\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2007\n",
      "Actual Answer:  ['2007', '2007', '2007']\n",
      "\n",
      "Model Response:  basic channels\n",
      "Actual Answer:  ['basic channels', 'the basic channels', 'the basic channels']\n",
      "\n",
      "Model Response:  substantially increased the asking price for the channels\n",
      "Actual Answer:  ['substantially increased the asking price', 'that BSkyB had substantially increased the asking price for the channels', 'increased the asking price']\n",
      "\n",
      "Model Response:  video on demand content\n",
      "Actual Answer:  ['Video On Demand', 'Video On Demand content', 'HD channels and Video On Demand']\n",
      "\n",
      "Model Response:  hd channels and video on demand content\n",
      "Actual Answer:  ['HD channels', 'HD channels', 'HD channels']\n",
      "\n",
      "Model Response:  2007\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hd\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  video on demand\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  their new deal offered \" substantially more value \"\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1 march 2007\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  july 2013\n",
      "Actual Answer:  ['July 2013', 'In July 2013', 'July 2013']\n",
      "\n",
      "Model Response:  2013\n",
      "Actual Answer:  ['2013', '2013', '31 July 2013']\n",
      "\n",
      "Model Response:  skydrive cloud storage service\n",
      "Actual Answer:  ['OneDrive', 'OneDrive', 'OneDrive']\n",
      "\n",
      "Model Response:  onedrive for business\n",
      "Actual Answer:  ['OneDrive for Business', 'OneDrive for Business', 'OneDrive for Business']\n",
      "\n",
      "Model Response:  cloud storage\n",
      "Actual Answer:  ['cloud storage', 'cloud storage', 'cloud storage service']\n",
      "\n",
      "Model Response:  july 2013\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  31 july 2013\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  onedrive for business\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  skydrive pro\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  27 january 2014\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sam chisholm and rupert murdoch\n",
      "Actual Answer:  ['Sam Chisholm', 'Sam Chisholm', 'Sam Chisholm and Rupert Murdoch']\n",
      "\n",
      "Model Response:  astra\n",
      "Actual Answer:  ['Astra', \"Astra's\", \"Astra's satellites\"]\n",
      "\n",
      "Model Response:  27 september 2001\n",
      "Actual Answer:  ['27 September 2001', '27 September 2001', 'September 2001']\n",
      "\n",
      "Model Response:  sky digital\n",
      "Actual Answer:  ['Sky Digital', 'Sky Digital', 'Sky Digital platform']\n",
      "\n",
      "Model Response:  3. 5 million\n",
      "Actual Answer:  ['3.5 million', '3.5 million', '3.5 million']\n",
      "\n",
      "Model Response:  sky digital\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  astra\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  400, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  michael grade\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  british sky broadcasting or bskyb\n",
      "Actual Answer:  ['BSkyB', 'British Sky Broadcasting', 'British Sky Broadcasting']\n",
      "\n",
      "Model Response:  telecommunications\n",
      "Actual Answer:  ['telecommunications', 'telecommunications', 'British telecommunications company']\n",
      "\n",
      "Model Response:  11 million\n",
      "Actual Answer:  ['11 million', '11 million', '11 million customers']\n",
      "\n",
      "Model Response:  freeview\n",
      "Actual Answer:  ['Freeview', 'Freeview', 'Freeview']\n",
      "\n",
      "Model Response:  british sky broadcasting or bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  freeview\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  11 million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  freeview\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  isleworth\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky q hub\n",
      "Actual Answer:  ['Sky Q Hub', 'Sky Q Hub', 'Sky Q Hub']\n",
      "\n",
      "Model Response:  sky q silver set top boxes\n",
      "Actual Answer:  ['Sky Q Silver set top boxes', 'the Sky Q Silver set top boxes', 'Sky Q Silver']\n",
      "\n",
      "Model Response:  share recordings and other media\n",
      "Actual Answer:  ['share recordings', 'to share recordings and other media', 'share recordings']\n",
      "\n",
      "Model Response:  later in 2016\n",
      "Actual Answer:  ['2016', 'later in 2016', '2016']\n",
      "\n",
      "Model Response:  2016\n",
      "Actual Answer:  ['2016', 'in 2016', '2016']\n",
      "\n",
      "Model Response:  sky q hub\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky q silver set top boxes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  share recordings and other media\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky q silver\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mpeg - 2\n",
      "Actual Answer:  ['DVB-compliant MPEG-2', 'DVB-compliant MPEG-2', 'MPEG-2']\n",
      "\n",
      "Model Response:  dolby digital\n",
      "Actual Answer:  ['Dolby Digital', 'Dolby Digital', 'Dolby Digital']\n",
      "\n",
      "Model Response:  mpeg - 4\n",
      "Actual Answer:  ['MPEG-4', 'MPEG-4', 'MPEG-4']\n",
      "\n",
      "Model Response:  opentv\n",
      "Actual Answer:  ['OpenTV', 'OpenTV', 'OpenTV']\n",
      "\n",
      "Model Response:  dvb - s2\n",
      "Actual Answer:  ['DVB-S2', 'DVB-S2', 'DVB-compliant MPEG-2']\n",
      "\n",
      "Model Response:  sky +\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  opentv\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky news\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dolby digital\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1998\n",
      "Actual Answer:  ['1998', '1998', '1998']\n",
      "\n",
      "Model Response:  astra 2a\n",
      "Actual Answer:  ['Astra 2A', 'the Astra 2A', 'Astra 2A']\n",
      "\n",
      "Model Response:  eurobird 1\n",
      "Actual Answer:  [\"Eutelsat's Eurobird 1\", \"Eutelsat's Eurobird 1\", \"Eutelsat's Eurobird 1\"]\n",
      "\n",
      "Model Response:  hundreds\n",
      "Actual Answer:  ['hundreds', 'hundreds', 'hundreds']\n",
      "\n",
      "Model Response:  28. 5°e\n",
      "Actual Answer:  ['28.5°E', '28.5°E', '28.5°E']\n",
      "\n",
      "Model Response:  sky digital\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  eurobird 1\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hundreds\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1998\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  22 may 2006\n",
      "Actual Answer:  ['22 May 2006', 'on 22 May 2006', '22 May 2006']\n",
      "\n",
      "Model Response:  40, 000\n",
      "Actual Answer:  ['40,000', '40,000', '40,000']\n",
      "\n",
      "Model Response:  thomson\n",
      "Actual Answer:  ['Thomson', 'Thomson', 'STB']\n",
      "\n",
      "Model Response:  17, 000\n",
      "Actual Answer:  ['17,000', '17,000', '17,000']\n",
      "\n",
      "Model Response:  4, 222, 000\n",
      "Actual Answer:  ['4,222,000', '4,222,000', '4,222,000']\n",
      "\n",
      "Model Response:  22 may 2006\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  thomson\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  40, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the bbc\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  31 march 2012\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  8 february 2007\n",
      "Actual Answer:  ['8 February 2007', 'On 8 February 2007', '8 February 2007']\n",
      "\n",
      "Model Response:  march\n",
      "Actual Answer:  ['March', 'in March', 'March']\n",
      "\n",
      "Model Response:  digital terrestrial\n",
      "Actual Answer:  ['digital terrestrial', 'digital terrestrial', 'digital terrestrial']\n",
      "\n",
      "Model Response:  virgin media\n",
      "Actual Answer:  ['Virgin Media', 'Virgin Media', 'Virgin Media']\n",
      "\n",
      "Model Response:  english premier league football ), films, entertainment and news\n",
      "Actual Answer:  ['English Premier League Football', 'English Premier League Football', 'sport (including English Premier League Football), films, entertainment and news']\n",
      "\n",
      "Model Response:  8 february 2007\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  march\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  digital terrestrial\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ntl\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  free - to - view\n",
      "Actual Answer:  ['free-to-view', 'free-to-view', 'free-to-air']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['monthly subscription', 'a monthly subscription', 'monthly subscription']\n",
      "\n",
      "Model Response:  videoguard uk\n",
      "Actual Answer:  ['VideoGuard UK', 'VideoGuard UK', 'VideoGuard UK']\n",
      "\n",
      "Model Response:  ku band\n",
      "Actual Answer:  ['Ku band', '9.75/10.600 GHz', 'universal Ku band']\n",
      "\n",
      "Model Response:  sky service\n",
      "Actual Answer:  ['Sky', 'Sky', 'Sky service']\n",
      "\n",
      "Model Response:  monthly subscription\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  videoguard uk\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  free\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky service\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  universal ku band lnb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  autumn of 1991\n",
      "Actual Answer:  ['1991', 'autumn of 1991', '1991']\n",
      "\n",
      "Model Response:  itv\n",
      "Actual Answer:  ['ITV', 'ITV', 'ITV']\n",
      "\n",
      "Model Response:  £34m per year\n",
      "Actual Answer:  ['£34m', '£34m', '£34m per year']\n",
      "\n",
      "Model Response:  the bbc\n",
      "Actual Answer:  ['BBC', 'The BBC', 'BBC']\n",
      "\n",
      "Model Response:  £304m\n",
      "Actual Answer:  ['£304m', '£304m', '£304m']\n",
      "\n",
      "Model Response:  itv\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  £304m\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the bbc\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  itv\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ofcom\n",
      "Actual Answer:  ['Ofcom', 'Ofcom', 'Ofcom']\n",
      "\n",
      "Model Response:  £15 – 100, 000\n",
      "Actual Answer:  ['£15–100,000', '£15–100,000', '£15–100,000']\n",
      "\n",
      "Model Response:  bskyb has no veto\n",
      "Actual Answer:  ['no', 'no', 'Third-party channels']\n",
      "\n",
      "Model Response:  bskyb does not\n",
      "Actual Answer:  ['not', 'not', 'BSkyB does not carry any control']\n",
      "\n",
      "Model Response:  bskyb does not\n",
      "Actual Answer:  ['not', 'not', 'BSkyB does not carry any control']\n",
      "\n",
      "Model Response:  ofcom\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  their epg\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb's epg\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1 october 1998\n",
      "Actual Answer:  ['1 October 1998', '1 October 1998', '1 October 1998']\n",
      "\n",
      "Model Response:  sky digital\n",
      "Actual Answer:  ['Sky Digital', 'Sky Digital', 'Sky Digital']\n",
      "\n",
      "Model Response:  open\n",
      "Actual Answer:  ['Sky Active', 'Open', 'Sky Active']\n",
      "\n",
      "Model Response:  ondigital\n",
      "Actual Answer:  ['ONdigital', 'ONdigital', 'ONdigital']\n",
      "\n",
      "Model Response:  over 100, 000\n",
      "Actual Answer:  ['100,000', 'over 100,000', '100,000']\n",
      "\n",
      "Model Response:  1 october 1998\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sky digital\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  over 100, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  may 1999\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2007\n",
      "Actual Answer:  ['2007', '2007', '2007']\n",
      "\n",
      "Model Response:  virgin media\n",
      "Actual Answer:  ['Virgin Media', 'Virgin Media', 'Virgin Media']\n",
      "\n",
      "Model Response:  video on demand\n",
      "Actual Answer:  ['Video On Demand', 'Video On Demand service', '(HDTV)']\n",
      "\n",
      "Model Response:  bbc hd\n",
      "Actual Answer:  ['BBC HD', 'BBC HD', 'BBC HD']\n",
      "\n",
      "Model Response:  channel 4 hd\n",
      "Actual Answer:  ['Channel 4 HD', 'Channel 4 HD', 'Channel 4 HD']\n",
      "\n",
      "Model Response:  2007\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  video on demand service to carry a modest selection of hd content\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bbc hd\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bbc hd\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  10 million\n",
      "Actual Answer:  ['10 million', '10 million', '10 million']\n",
      "\n",
      "Model Response:  25m people\n",
      "Actual Answer:  ['25m', '25m people', '36% of households']\n",
      "\n",
      "Model Response:  august 2004\n",
      "Actual Answer:  ['August 2004', 'August 2004', 'August 2004']\n",
      "\n",
      "Model Response:  36 %\n",
      "Actual Answer:  ['36%', '36% of households', '2.4m customers']\n",
      "\n",
      "Model Response:  flattened\n",
      "Actual Answer:  ['flattened', 'flattened', 'flattened']\n",
      "\n",
      "Model Response:  10 million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  25m people\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  36 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  welfare cash card\n",
      "Actual Answer:  ['Welfare Cash Card', 'Welfare Cash Card', 'Welfare Cash Card']\n",
      "\n",
      "Model Response:  essentials\n",
      "Actual Answer:  ['essentials', 'only \"essentials\"', 'essentials']\n",
      "\n",
      "Model Response:  often damaging\n",
      "Actual Answer:  ['often damaging', 'often damaging', 'often damaging']\n",
      "\n",
      "Model Response:  sky tv bills\n",
      "Actual Answer:  ['Sky TV bills', 'claimants\\' \"Sky TV bills', 'claimants']\n",
      "\n",
      "Model Response:  betray a man's presence in the household\n",
      "Actual Answer:  [\"a man's presence\", 'mother is wrongly claiming to be living alone', \"betray a man's presence in the household\"]\n",
      "\n",
      "Model Response:  welfare cash card\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  essentials\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  often damaging\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a man's presence in the household\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  £30m\n",
      "Actual Answer:  ['£30m', '£30m', '£30m']\n",
      "\n",
      "Model Response:  currently there is no indication\n",
      "Actual Answer:  ['no', 'no indication', 'no indication']\n",
      "\n",
      "Model Response:  virgin media\n",
      "Actual Answer:  ['Virgin Media', 'Virgin Media', 'Virgin Media']\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  ['BSkyB', 'BSkyB', 'BSkyB']\n",
      "\n",
      "Model Response:  carriage of their respective basic channels\n",
      "Actual Answer:  ['basic channels', 'the carriage of their respective basic channels', 'carriage of their respective basic channels']\n",
      "\n",
      "Model Response:  £30m\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  virgin media\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  carriage of their respective basic channels\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb and virgin media\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bskyb\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  highly diversified\n",
      "Actual Answer:  ['diversified', 'highly diversified', 'highly diversified']\n",
      "\n",
      "Model Response:  second\n",
      "Actual Answer:  ['second', 'second', 'second']\n",
      "\n",
      "Model Response:  fourth\n",
      "Actual Answer:  ['fourth', 'fourth', 'fourth']\n",
      "\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  ['Melbourne', 'Melbourne', 'Melbourne']\n",
      "\n",
      "Model Response:  melbourne cricket ground\n",
      "Actual Answer:  ['Melbourne Cricket Ground', 'The Melbourne Cricket Ground', 'Melbourne Cricket Ground']\n",
      "\n",
      "Model Response:  education\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  second\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  fourth\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  eight\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  bendigo\n",
      "Actual Answer:  ['Bendigo', 'Bendigo', 'Bendigo']\n",
      "\n",
      "Model Response:  new south wales\n",
      "Actual Answer:  ['New South Wales', 'New South Wales', 'New South Wales']\n",
      "\n",
      "Model Response:  buckland valley\n",
      "Actual Answer:  ['Buckland Valley', 'Buckland Valley near Bright', 'Buckland Valley']\n",
      "\n",
      "Model Response:  over 1, 000\n",
      "Actual Answer:  ['over 1,000', '1,000', '1,000']\n",
      "\n",
      "Model Response:  cramped and unsanitary\n",
      "Actual Answer:  ['cramped and unsanitary', 'cramped and unsanitary', 'cramped and unsanitary']\n",
      "\n",
      "Model Response:  bendigo\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  buckland valley\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cramped and unsanitary\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  multi - member proportional representation system\n",
      "Actual Answer:  ['multi-member proportional', 'multi-member proportional', 'multi-member proportional representation system']\n",
      "\n",
      "Model Response:  eight\n",
      "Actual Answer:  ['eight', 'eight', 'eight']\n",
      "\n",
      "Model Response:  five\n",
      "Actual Answer:  ['five', 'five', 'five']\n",
      "\n",
      "Model Response:  four years\n",
      "Actual Answer:  ['four years', 'four years', 'four years']\n",
      "\n",
      "Model Response:  every four years\n",
      "Actual Answer:  ['every four years', 'every four years', 'four years']\n",
      "\n",
      "Model Response:  22\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  five\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  four years\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  november\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  labor\n",
      "Actual Answer:  ['Australian Labor Party', 'Australian Labor Party', 'Labor']\n",
      "\n",
      "Model Response:  the liberals\n",
      "Actual Answer:  ['Liberal Party', 'Liberal Party of Australia', 'Liberals']\n",
      "\n",
      "Model Response:  the nationals\n",
      "Actual Answer:  ['National Party', 'National Party of Australia', 'Nationals']\n",
      "\n",
      "Model Response:  the greens\n",
      "Actual Answer:  ['The Greens', 'Australian Greens', 'Greens']\n",
      "\n",
      "Model Response:  australian greens\n",
      "Actual Answer:  ['Labor', 'Australian Labor Party', 'Labor']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  labor\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the greens\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  61. 1 %\n",
      "Actual Answer:  ['61.1%', '61.1%', '61.1%']\n",
      "\n",
      "Model Response:  61. 1 %\n",
      "Actual Answer:  ['26.7%', '26.7%', '26.7%']\n",
      "\n",
      "Model Response:  buddhism\n",
      "Actual Answer:  ['Buddhism', 'Buddhism', 'Buddhism']\n",
      "\n",
      "Model Response:  168, 637\n",
      "Actual Answer:  ['168,637', '168,637', '168,637']\n",
      "\n",
      "Model Response:  168, 637\n",
      "Actual Answer:  ['20%', '20%', '20%']\n",
      "\n",
      "Model Response:  61. 1 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  61. 1 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hinduism\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  61. 1 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  152, 775\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  south - east\n",
      "Actual Answer:  ['south-east', 'south-east', 'the south-east of Australia']\n",
      "\n",
      "Model Response:  second - most populous\n",
      "Actual Answer:  ['most densely populated', 'most', 'most densely populated state']\n",
      "\n",
      "Model Response:  second\n",
      "Actual Answer:  ['second', 'second-most', 'second-most populous']\n",
      "\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  ['Melbourne', 'Melbourne', 'Melbourne']\n",
      "\n",
      "Model Response:  second - largest\n",
      "Actual Answer:  ['second-largest', 'second-largest', 'second-largest city']\n",
      "\n",
      "Model Response:  bass strait\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  second - largest\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  second - most\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  second - largest\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  koori\n",
      "Actual Answer:  ['Koori', 'Koori', 'Koori']\n",
      "\n",
      "Model Response:  1788\n",
      "Actual Answer:  ['1788', '1788', '1788']\n",
      "\n",
      "Model Response:  sullivan bay\n",
      "Actual Answer:  ['New South Wales', 'New South Wales', 'New South Wales']\n",
      "\n",
      "Model Response:  sullivan bay\n",
      "Actual Answer:  ['Sullivan Bay', 'Sullivan Bay', 'Sullivan Bay']\n",
      "\n",
      "Model Response:  1803\n",
      "Actual Answer:  ['1803', '1803', '1803']\n",
      "\n",
      "Model Response:  koori\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1788\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sullivan bay\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sullivan bay\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1803\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  more than 26, 000 square kilometres\n",
      "Actual Answer:  ['26,000 square kilometres', '26,000 square kilometres', '26,000 square kilometres']\n",
      "\n",
      "Model Response:  50 %\n",
      "Actual Answer:  ['50%', '50%', '50%']\n",
      "\n",
      "Model Response:  6, 000 square kilometres\n",
      "Actual Answer:  ['6,000 square kilometres', '6,000 square kilometres', '6,000 square kilometres']\n",
      "\n",
      "Model Response:  90 %\n",
      "Actual Answer:  ['90%', '90%', '90%']\n",
      "\n",
      "Model Response:  270, 000\n",
      "Actual Answer:  ['270,000', '270,000', '121,200']\n",
      "\n",
      "Model Response:  more than 26, 000 square kilometres\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  more than 50 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  more than 26, 000 square kilometres ( 10, 000 sq mi )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  90 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  121, 200\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1975\n",
      "Actual Answer:  ['1975', '1975', '1975']\n",
      "\n",
      "Model Response:  1855 colonial constitution\n",
      "Actual Answer:  ['1855 colonial constitution', 'the 1855 colonial constitution', '1855 colonial constitution']\n",
      "\n",
      "Model Response:  parliament of victoria\n",
      "Actual Answer:  ['Parliament of Victoria', 'the Parliament of Victoria', 'Parliament of Victoria']\n",
      "\n",
      "Model Response:  \" entrenched \" provisions that require either an absolute majority in both houses, a three - fifths majority in both houses, or the approval of the victorian people in a referendum\n",
      "Actual Answer:  ['\"entrenched\" provisions', 'certain \"entrenched\" provisions', '\"entrenched\" provisions']\n",
      "\n",
      "Model Response:  victoria constitution act 1855\n",
      "Actual Answer:  ['Victoria Constitution Act 1855', 'the Victoria Constitution Act 1855', 'Victoria Constitution Act 185']\n",
      "\n",
      "Model Response:  1855 colonial constitution, passed by the united kingdom parliament as the victoria constitution act 1855\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1855 colonial constitution\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  parliament of victoria\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \" entrenched \" provisions that require either an absolute majority in both houses, a three - fifths majority in both houses, or the approval of the victorian people in a referendum\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  victoria constitution act 1855\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  hot winds\n",
      "Actual Answer:  ['warmest regions', 'semi-deserts', 'semi-deserts']\n",
      "\n",
      "Model Response:  32 °c ( 90 °f )\n",
      "Actual Answer:  ['32 °C', '32 °C', '32 °C (90 °F)']\n",
      "\n",
      "Model Response:  2 – 7 °c ( 4 – 13 °f )\n",
      "Actual Answer:  ['15 °C', '15 °C', '15 °C (59 °F)']\n",
      "\n",
      "Model Response:  48. 8 °c\n",
      "Actual Answer:  ['48.8 °C', '48.8 °C', '48.8 °C (119.8 °F)']\n",
      "\n",
      "Model Response:  7 february 2009\n",
      "Actual Answer:  ['2009', 'the 2009 southeastern Australia heat wave', '7 February 2009']\n",
      "\n",
      "Model Response:  48. 8 °c ( 119. 8 °f ) was recorded in hopetoun on 7 february 2009, during the 2009 southeastern australia heat wave\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  15 °c ( 59 °f )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  32 °c ( 90 °f )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  48. 8\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  state or government schools\n",
      "Actual Answer:  ['state or government', 'state or government schools', 'state or government schools']\n",
      "\n",
      "Model Response:  victoria department of education\n",
      "Actual Answer:  ['Victoria Department of Education', 'the Victoria Department of Education', 'Victoria Department of Education']\n",
      "\n",
      "Model Response:  extra costs are levied\n",
      "Actual Answer:  ['some extra costs', 'some extra costs are levied', 'extra costs']\n",
      "\n",
      "Model Response:  roman catholic church\n",
      "Actual Answer:  ['Roman Catholic Church', 'the Roman Catholic Church', 'Roman Catholic']\n",
      "\n",
      "Model Response:  government - set curriculum standards\n",
      "Actual Answer:  ['curriculum', 'curriculum standards', 'curriculum']\n",
      "\n",
      "Model Response:  victoria department of education\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  victoria department of education\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  four government selective schools\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  roman catholic church\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  government - set curriculum standards\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  car\n",
      "Actual Answer:  ['major car brands', 'major car brands', 'car']\n",
      "\n",
      "Model Response:  october 2016\n",
      "Actual Answer:  ['2017', '2017', '2017']\n",
      "\n",
      "Model Response:  october 2016\n",
      "Actual Answer:  ['May 2013', 'in May 2013', '2013']\n",
      "\n",
      "Model Response:  october 2016\n",
      "Actual Answer:  ['October 2016', 'in October 2016', '2013']\n",
      "\n",
      "Model Response:  ford, toyota\n",
      "Actual Answer:  ['Ford', 'Ford']\n",
      "\n",
      "Model Response:  car\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  february 2014\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  may 2013\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  october 2016\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  ford, toyota and holden\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2, 000 m\n",
      "Actual Answer:  ['2,000 m', 'almost 2,000 m', '2,000 m']\n",
      "\n",
      "Model Response:  mount bogong\n",
      "Actual Answer:  ['Mount Bogong', 'Mount Bogong', 'Mount Bogong']\n",
      "\n",
      "Model Response:  1, 986 m\n",
      "Actual Answer:  ['1,986 m', '1,986 m', '1,986 m']\n",
      "\n",
      "Model Response:  river systems\n",
      "Actual Answer:  ['river systems', 'river systems', 'river systems']\n",
      "\n",
      "Model Response:  helmeted honeyeater\n",
      "Actual Answer:  ['helmeted honeyeater', 'the helmeted honeyeater', 'helmeted honeyeater']\n",
      "\n",
      "Model Response:  2, 000 m ( 6, 600 ft )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mount bogong\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1, 986 m ( 6, 516 ft )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  helmeted honeyeater\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pink heath\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  victorian alps in the northeast\n",
      "Actual Answer:  ['Victorian Alps', 'The Victorian Alps', 'Victorian Alps']\n",
      "\n",
      "Model Response:  great dividing range mountain system\n",
      "Actual Answer:  ['Great Dividing Range', 'the Great Dividing Range', 'Great Dividing Range']\n",
      "\n",
      "Model Response:  east - west\n",
      "Actual Answer:  ['east-west', 'east-west', 'east-west']\n",
      "\n",
      "Model Response:  9 °c ( 48 °f )\n",
      "Actual Answer:  ['below 0 °C', 'below 0 °C', 'below 0 °C (32 °F)']\n",
      "\n",
      "Model Response:  −11. 7 °c\n",
      "Actual Answer:  ['−11.7 °C', '−11.7 °C', '−11.7 °C (10.9 °F)']\n",
      "\n",
      "Model Response:  victorian alps in the northeast\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  great dividing range mountain system\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  east - west\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  less than 9 °c ( 48 °f )\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the victorian government\n",
      "Actual Answer:  ['government-owned', 'government', 'several private and public railway operators']\n",
      "\n",
      "Model Response:  v / line\n",
      "Actual Answer:  ['Metro Trains Melbourne', 'Metro Trains Melbourne', 'Metro Trains Melbourne']\n",
      "\n",
      "Model Response:  the victorian government\n",
      "Actual Answer:  ['Victorian Government', 'the Victorian Government', 'Victorian Government']\n",
      "\n",
      "Model Response:  freight services\n",
      "Actual Answer:  ['freight services', 'freight', 'freight']\n",
      "\n",
      "Model Response:  electrified, passenger system\n",
      "Actual Answer:  ['passenger', 'extensive, electrified, passenger system', 'passenger']\n",
      "\n",
      "Model Response:  private and public railway operators\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  v / line\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  victorian government\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  pacific national, cfcl australia\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  metro trains melbourne\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  37\n",
      "Actual Answer:  ['37', '37', '37']\n",
      "\n",
      "Model Response:  12\n",
      "Actual Answer:  ['12', '12', '12']\n",
      "\n",
      "Model Response:  legislative council\n",
      "Actual Answer:  ['Legislative Assembly', 'the Legislative Assembly', 'Legislative Assembly']\n",
      "\n",
      "Model Response:  legislative council\n",
      "Actual Answer:  ['Legislative Council', 'the Legislative Council', 'Legislative Council']\n",
      "\n",
      "Model Response:  linda dessau\n",
      "Actual Answer:  ['Linda Dessau', 'Linda Dessau', 'Linda Dessau']\n",
      "\n",
      "Model Response:  37\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  12\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  legislative assembly\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  legislative council\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  daniel andrews\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1 july 1851\n",
      "Actual Answer:  ['1 July 1851', '1 July 1851', '1 July 1851']\n",
      "\n",
      "Model Response:  1851\n",
      "Actual Answer:  ['1851', 'in 1851', '1851']\n",
      "\n",
      "Model Response:  one of the largest gold rushes\n",
      "Actual Answer:  ['gold rush', 'gold rush', 'gold rushes']\n",
      "\n",
      "Model Response:  sevenfold\n",
      "Actual Answer:  ['sevenfold', 'sevenfold', '76,000 to 540,000']\n",
      "\n",
      "Model Response:  20 million ounces\n",
      "Actual Answer:  ['20 million ounces', '20 million ounces', '20 million ounces']\n",
      "\n",
      "Model Response:  1 july 1851\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1851\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  one of the largest gold rushes\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sevenfold\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  20 million ounces\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1, 548\n",
      "Actual Answer:  ['1,548', '1,548', '1,548']\n",
      "\n",
      "Model Response:  489\n",
      "Actual Answer:  ['489', '489', '489']\n",
      "\n",
      "Model Response:  540, 800\n",
      "Actual Answer:  ['540,800', '540,800', '540,800']\n",
      "\n",
      "Model Response:  63, 519\n",
      "Actual Answer:  ['63,519', '63,519', '63,519']\n",
      "\n",
      "Model Response:  over 61 per cent\n",
      "Actual Answer:  ['61', '61', '61']\n",
      "\n",
      "Model Response:  1, 548\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  489\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  540, 800\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  63, 519\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  61\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  victoria\n",
      "Actual Answer:  ['Victoria', 'Victoria', 'Victoria']\n",
      "\n",
      "Model Response:  3 million\n",
      "Actual Answer:  ['3 million', '3 million', '3 million']\n",
      "\n",
      "Model Response:  60 %\n",
      "Actual Answer:  ['60%', '60%', '60%']\n",
      "\n",
      "Model Response:  two - thirds\n",
      "Actual Answer:  ['two-thirds', 'nearly two-thirds', 'two-thirds']\n",
      "\n",
      "Model Response:  asia\n",
      "Actual Answer:  ['Asia', 'Asia', 'Asia']\n",
      "\n",
      "Model Response:  victoria\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  3 million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  60 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  60 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  asia\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1, 600 mm ( 5 ft 3 in ) broad gauge\n",
      "Actual Answer:  ['1,600 mm', '1,600 mm (5 ft 3 in) broad gauge', '1,600 mm (5 ft 3 in) broad gauge']\n",
      "\n",
      "Model Response:  1, 435 mm ( 4 ft 8 1⁄2 in ) standard gauge\n",
      "Actual Answer:  ['1,435 mm', '1,435 mm (4 ft 8 1⁄2 in) standard gauge', '1,435 mm (4 ft 8 1⁄2 in) standard gauge']\n",
      "\n",
      "Model Response:  760 mm\n",
      "Actual Answer:  ['760 mm', '760 mm (2 ft 6 in) narrow gauge lines', '760 mm (2 ft 6 in) narrow gauge lines']\n",
      "\n",
      "Model Response:  mountainous areas\n",
      "Actual Answer:  ['mountainous areas', 'mountainous areas', 'mountainous areas']\n",
      "\n",
      "Model Response:  five\n",
      "Actual Answer:  ['five', 'five', 'five']\n",
      "\n",
      "Model Response:  1, 600 mm ( 5 ft 3 in ) broad gauge\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1, 435 mm ( 4 ft 8 1⁄2 in ) standard gauge\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1, 600 mm ( 5 ft 3 in ) broad gauge\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mountainous areas\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  five\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1788\n",
      "Actual Answer:  ['1788', '1788', '1788']\n",
      "\n",
      "Model Response:  new south wales\n",
      "Actual Answer:  ['New South Wales', 'New South Wales', 'New South Wales']\n",
      "\n",
      "Model Response:  new holland\n",
      "Actual Answer:  ['New Holland', 'New Holland', 'New Holland']\n",
      "\n",
      "Model Response:  sydney\n",
      "Actual Answer:  ['Sydney', 'Sydney', 'Sydney']\n",
      "\n",
      "Model Response:  hms calcutta\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  new holland\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sydney\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the french\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1854\n",
      "Actual Answer:  ['1854', '1854', '1854']\n",
      "\n",
      "Model Response:  eureka stockade\n",
      "Actual Answer:  ['Eureka Stockade', 'Eureka Stockade', 'Eureka Stockade']\n",
      "\n",
      "Model Response:  miners\n",
      "Actual Answer:  ['British troops', 'British troops', 'British troops']\n",
      "\n",
      "Model Response:  mining licence fees\n",
      "Actual Answer:  ['mining licence fees', 'mining licence fees', 'mining licence fees']\n",
      "\n",
      "Model Response:  colony of victoria act 1855\n",
      "Actual Answer:  ['Colony of Victoria Act', 'the Colony of Victoria Act', 'Colony of Victoria Act 1855']\n",
      "\n",
      "Model Response:  1854\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  british troops\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  mining licence fees\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  members of the victorian parliament\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  miners\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  political party or coalition\n",
      "Actual Answer:  ['most seats', 'the most seats in the Legislative Assembly', 'most seats in the Legislative Assembly']\n",
      "\n",
      "Model Response:  cabinet\n",
      "Actual Answer:  ['Premier', 'The Premier is the public face of government and, with cabinet', 'Premier of Victoria']\n",
      "\n",
      "Model Response:  representatives elected to either house of parliament\n",
      "Actual Answer:  ['representatives', 'representatives elected to either house of parliament', 'representatives elected to either house of parliament']\n",
      "\n",
      "Model Response:  daniel andrews\n",
      "Actual Answer:  ['Daniel Andrews', 'Daniel Andrews', 'Daniel Andrews']\n",
      "\n",
      "Model Response:  either house of parliament\n",
      "Actual Answer:  ['elected', 'elected', 'elected']\n",
      "\n",
      "Model Response:  political party or coalition\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cabinet\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cabinet\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  daniel andrews\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cabinet consists of representatives elected to either house of parliament\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  17 % to $ 8. 7 billion\n",
      "Actual Answer:  ['$8.7 billion', '24%', '$8.7 billion']\n",
      "\n",
      "Model Response:  17 %\n",
      "Actual Answer:  ['17%', '17%', '17%']\n",
      "\n",
      "Model Response:  32, 463\n",
      "Actual Answer:  ['32,463', '32,463', '32,463']\n",
      "\n",
      "Model Response:  136, 000 square kilometres ( 52, 500 sq mi )\n",
      "Actual Answer:  ['136,000 square kilometres', '136,000 square kilometres', '136,000 square kilometres']\n",
      "\n",
      "Model Response:  60 %\n",
      "Actual Answer:  ['60%', '60%', '60%']\n",
      "\n",
      "Model Response:  17 % to $ 8. 7 billion\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  17 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  32, 463\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a quarter\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a quarter\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  tourism\n",
      "Actual Answer:  ['tourism', 'tourism', 'big']\n",
      "\n",
      "Model Response:  sports tourism\n",
      "Actual Answer:  ['sports', 'sports tourism', 'sports']\n",
      "\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  ['Melbourne', 'Melbourne', 'Melbourne']\n",
      "\n",
      "Model Response:  regional cities\n",
      "Actual Answer:  ['regional cities', 'in regional cities', 'Phillip Island']\n",
      "\n",
      "Model Response:  surfclassic\n",
      "Actual Answer:  ['SurfClassic', 'SurfClassic', 'SurfClassic']\n",
      "\n",
      "Model Response:  tourism\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sports tourism\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  melbourne\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  regional cities\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  port fairy folk festival\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern and central parts of france\n",
      "Actual Answer:  ['the southern and central parts of France', 'southern and central parts of France,', 'about one-eighth']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['about one-eighth the number', 'about one-eighth', 'about one-eighth']\n",
      "\n",
      "Model Response:  1562 to 1598\n",
      "Actual Answer:  ['from 1562 to 1598', '1562 to 1598', '562 to 1598']\n",
      "\n",
      "Model Response:  edict of nantes\n",
      "Actual Answer:  ['the Edict of Nantes', 'Edict of Nantes', 'the Edict of Nantes']\n",
      "\n",
      "Model Response:  gained influence and more openly displayed their faith\n",
      "Actual Answer:  ['granted the Huguenots substantial religious, political and military autonomy', 'granted the Huguenots substantial religious, political and military autonomy', 'granted the Huguenots substantial religious, political and military autonomy']\n",
      "\n",
      "Model Response:  1562\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  southern and central parts of france\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  huguenots\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  two million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  one - eighth\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  derision\n",
      "Actual Answer:  ['derision', 'derision', 'derision']\n",
      "\n",
      "Model Response:  besancon hugues\n",
      "Actual Answer:  ['Besançon Hugues', 'Besançon Hugues', 'Besançon Hugues']\n",
      "\n",
      "Model Response:  geneva\n",
      "Actual Answer:  ['Geneva', 'Geneva', 'Geneva']\n",
      "\n",
      "Model Response:  amboise plot\n",
      "Actual Answer:  ['Amboise plot', 'Amboise', 'the Amboise plot']\n",
      "\n",
      "Model Response:  [CLS]\n",
      "Actual Answer:  ['1560', '1560', '1560']\n",
      "\n",
      "Model Response:  1532\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  housemates\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  geneva\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  calvinist\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the availability of the bible\n",
      "Actual Answer:  ['availability of the Bible in vernacular languages', 'the Bible in vernacular languages', 'The availability of the Bible in vernacular languages']\n",
      "\n",
      "Model Response:  1294\n",
      "Actual Answer:  ['Around 1294', '1294', 'Around 1294']\n",
      "\n",
      "Model Response:  guyard de moulin\n",
      "Actual Answer:  ['Guyard de Moulin', 'Guyard de Moulin', 'Guyard de Moulin']\n",
      "\n",
      "Model Response:  1487\n",
      "Actual Answer:  ['1487', '1487', '1487']\n",
      "\n",
      "Model Response:  paris\n",
      "Actual Answer:  ['Paris', 'Paris', 'Paris']\n",
      "\n",
      "Model Response:  1294\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  france\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1294\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  french\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  paris\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  villes de surete\n",
      "Actual Answer:  ['villes de sûreté', '\"villes de sûreté\"', 'villes de sûreté']\n",
      "\n",
      "Model Response:  montpellier\n",
      "Actual Answer:  ['Montpellier', 'Montpellier', 'Montpellier']\n",
      "\n",
      "Model Response:  1622\n",
      "Actual Answer:  ['1622', '1622', '1622']\n",
      "\n",
      "Model Response:  edict of 1598\n",
      "Actual Answer:  ['Edict of Alès', 'Edict of Alès', 'Edict of Alès']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['1629', '1629', '1629']\n",
      "\n",
      "Model Response:  protestant rule was dead\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  montpellier was among the most important of the 66\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  66\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1629\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1622\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cape of good hope\n",
      "Actual Answer:  ['at the Cape of Good Hope', 'Cape of Good Hope', 'the Cape of Good Hope']\n",
      "\n",
      "Model Response:  cape town\n",
      "Actual Answer:  ['Cape Town', 'Cape Town', 'Cape Town']\n",
      "\n",
      "Model Response:  maria de la queillerie\n",
      "Actual Answer:  ['Maria de la Queillerie', 'Maria de la Queillerie', 'Maria de la Queillerie']\n",
      "\n",
      "Model Response:  dutch east india company\n",
      "Actual Answer:  ['Dutch East India Company', 'Dutch East India Company', 'Dutch East India Company']\n",
      "\n",
      "Model Response:  1700\n",
      "Actual Answer:  ['1700', '1700', '1700']\n",
      "\n",
      "Model Response:  1671\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  jan van riebeeck\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  seven\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  cape town\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1624\n",
      "Actual Answer:  ['1624', '1624', '1624']\n",
      "\n",
      "Model Response:  jesse de forest\n",
      "Actual Answer:  ['Jessé de Forest', 'Jessé de Forest', 'Jessé de Forest']\n",
      "\n",
      "Model Response:  l'eglise francaise a la nouvelle - amsterdam ( the french church in new amsterdam ). this parish continues today as l'eglise du saint - esprit\n",
      "Actual Answer:  [\"L'Église française à la Nouvelle-Amsterdam\", \"L'Église française à la Nouvelle-Amsterdam\", \"L'Église française à la Nouvelle-Amsterdam (the French church in New Amsterdam)\"]\n",
      "\n",
      "Model Response:  l'eglise du saint - esprit\n",
      "Actual Answer:  [\"L'Eglise du Saint-Esprit\", \"L'Eglise du Saint-Esprit\", \"L'Eglise du Saint-Esprit\"]\n",
      "\n",
      "Model Response:  brooklyn\n",
      "Actual Answer:  ['Brooklyn', 'Brooklyn', 'Brooklyn']\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1624\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  new netherland\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  new netherland\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1624\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  charleston\n",
      "Actual Answer:  ['Charleston, South Carolina', 'Charleston', 'Charleston, South Carolina']\n",
      "\n",
      "Model Response:  charleston\n",
      "Actual Answer:  ['the Charleston Orange district', 'Charleston Orange district', 'Charleston Orange district']\n",
      "\n",
      "Model Response:  1697\n",
      "Actual Answer:  ['1697', '1697', '1697']\n",
      "\n",
      "Model Response:  edmund bellinger\n",
      "Actual Answer:  ['the British Landgrave Edmund Bellinger', 'Edmund Bellinger', 'Edmund Bellinger']\n",
      "\n",
      "Model Response:  pons\n",
      "Actual Answer:  ['Pons', 'Pons in France', 'Pons']\n",
      "\n",
      "Model Response:  pons\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  suffolk\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1685\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1685\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1685\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  william iii of orange\n",
      "Actual Answer:  ['William III of Orange', 'Stadtholder William III of Orange', 'Stadtholder William III of Orange']\n",
      "\n",
      "Model Response:  king of england\n",
      "Actual Answer:  ['King of England', 'King of England', 'King of England']\n",
      "\n",
      "Model Response:  league of augsburg\n",
      "Actual Answer:  ['League of Augsburg', 'League of Augsburg', 'League of Augsburg']\n",
      "\n",
      "Model Response:  dutch republic\n",
      "Actual Answer:  ['Dutch Republic', 'Dutch Republic', 'Dutch Republic']\n",
      "\n",
      "Model Response:  1672\n",
      "Actual Answer:  ['1672', '1672', '1672']\n",
      "\n",
      "Model Response:  1672\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  french\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  french\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1672\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  edict of fontainebleau\n",
      "Actual Answer:  ['Edict of Fontainebleau', 'Edict of Fontainebleau', 'the Edict of Fontainebleau']\n",
      "\n",
      "Model Response:  1685\n",
      "Actual Answer:  ['1685', '1685', '1685']\n",
      "\n",
      "Model Response:  edict of fontainebleau\n",
      "Actual Answer:  ['Louis XIV', 'Louis XIV', 'Louis XIV']\n",
      "\n",
      "Model Response:  500, 000\n",
      "Actual Answer:  ['500,000', '500,000', 'roughly 500,000']\n",
      "\n",
      "Model Response:  1685\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  500, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  louis xiv\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  500, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  the catholic church in france\n",
      "Actual Answer:  ['Catholic Church in France', 'Catholic Church in France', 'The Catholic Church in France']\n",
      "\n",
      "Model Response:  st. bartholomew's day massacre\n",
      "Actual Answer:  [\"St. Bartholomew's Day massacre\", \"St. Bartholomew's Day massacre\", \"St. Bartholomew's Day massacre\"]\n",
      "\n",
      "Model Response:  5, 000 to 30, 000\n",
      "Actual Answer:  ['5,000 to 30,000', '5,000 to 30,000', '5,000 to 30,000']\n",
      "\n",
      "Model Response:  as they attempted to meet for worship\n",
      "Actual Answer:  ['their own militia', 'the Huguenots had their own militia']\n",
      "\n",
      "Model Response:  political reasons for this as well, as some of the huguenots were nobles trying to establish separate centers of power in southern france\n",
      "Actual Answer:  ['some of the Huguenots were nobles trying to establish separate centers of power in southern France', 'political reasons', 'some of the Huguenots were nobles trying to establish separate centers of power in southern France']\n",
      "\n",
      "Model Response:  5, 000 to 30, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  5, 000 to 30, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  5, 000 to 30, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  5, 000 to 30, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  huguenot rebellions\n",
      "Actual Answer:  ['Huguenot rebellions', 'Huguenot rebellions', 'the Huguenot rebellions']\n",
      "\n",
      "Model Response:  southwestern france\n",
      "Actual Answer:  ['southwestern France', 'southwestern France', 'mainly in southwestern France']\n",
      "\n",
      "Model Response:  between 1621 and 1629\n",
      "Actual Answer:  ['between 1621 and 1629', 'between 1621 and 1629', 'between 1621 and 1629']\n",
      "\n",
      "Model Response:  henry iv\n",
      "Actual Answer:  ['Henry IV', 'Henry IV', 'Henry IV']\n",
      "\n",
      "Model Response:  louis xiii\n",
      "Actual Answer:  ['Louis XIII', 'Louis XIII', 'Louis XIII']\n",
      "\n",
      "Model Response:  between 1621 and 1629\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1620\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  italian\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  foreign powers\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  one million\n",
      "Actual Answer:  ['one million', 'Approximately one million', 'Approximately one million']\n",
      "\n",
      "Model Response:  2 %\n",
      "Actual Answer:  ['2%', '2%', '2%']\n",
      "\n",
      "Model Response:  alsace\n",
      "Actual Answer:  ['Alsace', 'Alsace', 'Alsace']\n",
      "\n",
      "Model Response:  cevennes mountain region\n",
      "Actual Answer:  ['Cévennes', 'Cévennes', 'Cévennes mountain region']\n",
      "\n",
      "Model Response:  french australians\n",
      "Actual Answer:  ['Australia', 'Australia', 'Australia']\n",
      "\n",
      "Model Response:  one million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  approximately one million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  alsace\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  2 %\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  one million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  new rochelle\n",
      "Actual Answer:  ['New Rochelle', 'New Rochelle', 'New Rochelle']\n",
      "\n",
      "Model Response:  new rochelle\n",
      "Actual Answer:  ['New Paltz', 'New Paltz', 'New Paltz']\n",
      "\n",
      "Model Response:  huguenot street historic district \" in new paltz\n",
      "Actual Answer:  ['\"Huguenot Street Historic District\" in New Paltz', 'Huguenot Street Historic District', 'The \"Huguenot Street Historic District\" in New Paltz']\n",
      "\n",
      "Model Response:  huguenot street historic district\n",
      "Actual Answer:  ['the oldest street in the United States of America', 'the oldest street in the United States of America', 'the oldest street in the United States of America']\n",
      "\n",
      "Model Response:  new paltz. the \" huguenot street historic district \" in new paltz has been designated a national historic landmark site and contains the oldest street in the united states of america. a small group of huguenots also settled on the south shore of staten island\n",
      "Actual Answer:  ['Staten Island', 'Staten Island', 'Staten Island']\n",
      "\n",
      "Model Response:  21 miles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  21 miles north of new york in a town which they named new rochelle, and a third\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  21 miles\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  south shore of staten island\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  south shore of staten island\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dutch republic\n",
      "Actual Answer:  ['the Dutch Republic', 'Dutch Republic', 'Dutch Republic']\n",
      "\n",
      "Model Response:  75, 000 to 100, 000\n",
      "Actual Answer:  ['an estimated total of 75,000 to 100,000 people', '75,000 to 100,000', '75,000 to 100,000']\n",
      "\n",
      "Model Response:  ca. 2 million\n",
      "Actual Answer:  ['ca. 2 million', '2 million', '2 million']\n",
      "\n",
      "Model Response:  amsterdam and the area of west frisia\n",
      "Actual Answer:  ['Amsterdam and the area of West Frisia', 'Amsterdam and the area of West Frisia', 'Amsterdam and the area of West Frisia']\n",
      "\n",
      "Model Response:  edict of nantes\n",
      "Actual Answer:  ['the revocation of the Edict of Nantes', 'Edict of Nantes', 'the revocation of the Edict of Nantes']\n",
      "\n",
      "Model Response:  75, 000 to 100, 000 people. amongst them were 200 clergy. many came from the region of the cevennes, for instance, the village of fraissinet - de - lozere. this was a huge influx as the entire population of the dutch republic amounted to ca. 2 million\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1715\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  200\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dutch\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  huguon\n",
      "Actual Answer:  ['Tours', 'Tours', 'Tours']\n",
      "\n",
      "Model Response:  huguon, the gate of king hugo\n",
      "Actual Answer:  ['Huguon', 'Huguon', 'Huguon']\n",
      "\n",
      "Model Response:  le roi huguet\n",
      "Actual Answer:  ['the ghost of le roi Huguet', 'ghost of le roi Huguet', 'the ghost of le roi Huguet']\n",
      "\n",
      "Model Response:  pretendus reformes\n",
      "Actual Answer:  ['prétendus réformés', 'prétendus réformés', 'prétendus réformés']\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  canterbury\n",
      "Actual Answer:  ['Canterbury', 'Canterbury', 'Canterbury']\n",
      "\n",
      "Model Response:  the weavers\n",
      "Actual Answer:  ['The Weavers', 'The Weavers', 'The Weavers']\n",
      "\n",
      "Model Response:  the variety of occupations necessary to sustain the community as distinct from the indigenous population\n",
      "Actual Answer:  ['economic separation', 'economic separation', 'worked as weavers']\n",
      "\n",
      "Model Response:  sandwich, faversham and maidstone\n",
      "Actual Answer:  ['Kent, particularly Sandwich, Faversham and Maidstone', 'Sandwich, Faversham and Maidstone', 'Sandwich, Faversham and Maidstone']\n",
      "\n",
      "Model Response:  a weaving school\n",
      "Actual Answer:  ['a restaurant', 'restaurant', 'a restaurant']\n",
      "\n",
      "Model Response:  late 16th century to about 1830\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  canterbury\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  sandwich, faversham and maidstone\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  maidstone\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dublin, cork, youghal and waterford\n",
      "Actual Answer:  ['Dublin, Cork, Youghal and Waterford', 'Dublin, Cork, Youghal and Waterford', 'Dublin, Cork, Youghal and Waterford']\n",
      "\n",
      "Model Response:  cork city ; and d'olier street in dublin, named after a high sheriff and one of the founders of the bank of ireland. a french church in portarlington\n",
      "Actual Answer:  ['Cork City', 'Cork City', 'Cork City']\n",
      "\n",
      "Model Response:  dublin\n",
      "Actual Answer:  ['Dublin', 'Dublin', 'Dublin']\n",
      "\n",
      "Model Response:  a high sheriff and one of the founders of the bank of ireland\n",
      "Actual Answer:  ['a High Sheriff and one of the founders of the Bank of Ireland', 'High Sheriff', 'a High Sheriff and one of the founders of the Bank of Ireland']\n",
      "\n",
      "Model Response:  1696\n",
      "Actual Answer:  ['1696', '1696', '1696']\n",
      "\n",
      "Model Response:  dublin\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1696\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1696\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  17th and 18th centuries. numerous signs of huguenot presence can still be seen with names still in use, and with areas of the main towns and cities named after the people who settled there. examples include the huguenot district and french church street in cork city ; and d'olier street in dublin, named after a high sheriff and one of the founders of the bank of ireland. a french church in portarlington dates back to 1696\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  a high sheriff and one of the founders of the bank of ireland\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  brain drain\n",
      "Actual Answer:  ['brain drain', 'brain drain', 'brain drain']\n",
      "\n",
      "Model Response:  british colonies, which opened settlement to religious dissenters. by the time of the french and indian war ( the north american front of the seven years'war ), a sizeable population of huguenot descent lived in the british colonies, and many participated in the british defeat of new france\n",
      "Actual Answer:  ['New France', 'New France', 'New France']\n",
      "\n",
      "Model Response:  non - catholics\n",
      "Actual Answer:  ['non-Catholics', 'non-Catholics', 'non-Catholics']\n",
      "\n",
      "Model Response:  the seven years'war\n",
      "Actual Answer:  [\"Seven Years' War\", \"Seven Years' War\", \"Seven Years' War\"]\n",
      "\n",
      "Model Response:  1759 - 60\n",
      "Actual Answer:  ['1759-60', '1759-60', '1759-60']\n",
      "\n",
      "Model Response:  1759\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  non - catholics\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1759\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  french and indian war\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  henry of navarre, having succeeded to the french throne\n",
      "Actual Answer:  ['Henry of Navarre', 'Henry of Navarre', 'Henry of Navarre']\n",
      "\n",
      "Model Response:  1598\n",
      "Actual Answer:  ['1598', '1598', '1598']\n",
      "\n",
      "Model Response:  protected catholic interests\n",
      "Actual Answer:  ['granted the Protestants equality with Catholics', 'granted the Protestants equality', 'granted the Protestants equality with Catholics under the throne and a degree of religious and political freedom within their domains']\n",
      "\n",
      "Model Response:  the founding of new protestant churches in catholic - controlled regions\n",
      "Actual Answer:  ['the founding of new Protestant churches', 'founding of new Protestant churches in Catholic-controlled regions', 'the founding of new Protestant churches in Catholic-controlled regions']\n",
      "\n",
      "Model Response:  roman catholicism\n",
      "Actual Answer:  ['Protestantism', 'Protestantism', 'Protestantism']\n",
      "\n",
      "Model Response:  1598\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1598\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1598\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  new protestant churches\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  education\n",
      "Actual Answer:  ['education of children as Catholics', 'education of children as Catholics', 'required education of children as Catholics']\n",
      "\n",
      "Model Response:  forbade protestant services, required education of children as catholics, and prohibited emigration\n",
      "Actual Answer:  ['prohibited emigration', 'prohibited emigration', 'prohibited emigration']\n",
      "\n",
      "Model Response:  four thousand\n",
      "Actual Answer:  ['Four thousand', 'Four thousand', 'Four thousand']\n",
      "\n",
      "Model Response:  new converts\n",
      "Actual Answer:  ['\"new converts\"', '\"new converts\"', 'new converts']\n",
      "\n",
      "Model Response:  new york and virginia\n",
      "Actual Answer:  ['Holland, Prussia, and South Africa', 'Holland, Prussia, and South Africa', 'Britain as well as Holland, Prussia, and South Africa']\n",
      "\n",
      "Model Response:  four thousand\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  france. it precipitated civil bloodshed, ruined commerce, and resulted in the illegal flight from the country of hundreds of thousands of protestants, many of whom became intellectuals, doctors and business leaders in britain\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  four thousand\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  four thousand\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  switzerland and the netherlands\n",
      "Actual Answer:  ['Switzerland and the Netherlands', 'Switzerland and the Netherlands.', 'Switzerland and the Netherlands']\n",
      "\n",
      "Model Response:  1555\n",
      "Actual Answer:  ['1555', '1555', '1555']\n",
      "\n",
      "Model Response:  france antarctique\n",
      "Actual Answer:  ['France Antarctique', 'France Antarctique', 'France Antarctique']\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  ['1560', '1560', '1560']\n",
      "\n",
      "Model Response:  guanabara confession of faith\n",
      "Actual Answer:  ['the Guanabara Confession of Faith', 'Guanabara Confession of Faith', 'the Guanabara Confession of Faith']\n",
      "\n",
      "Model Response:  500\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1560\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  500\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  500\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  afrikaans\n",
      "Actual Answer:  ['Afrikaans', 'Afrikaans', 'Afrikaans']\n",
      "\n",
      "Model Response:  wine\n",
      "Actual Answer:  ['wine industry', 'wine', 'The wine industry']\n",
      "\n",
      "Model Response:  western cape province\n",
      "Actual Answer:  ['Western Cape province', 'Western Cape province']\n",
      "\n",
      "Model Response:  surnames\n",
      "Actual Answer:  ['surnames', 'names', 'surnames']\n",
      "\n",
      "Model Response:  huguenots\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  huguenots\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  [CLS]\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  [CLS]\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  paul revere\n",
      "Actual Answer:  ['Paul Revere', 'Paul Revere', 'Paul Revere']\n",
      "\n",
      "Model Response:  henry laurens\n",
      "Actual Answer:  ['Henry Laurens', 'Henry Laurens', 'Henry Laurens']\n",
      "\n",
      "Model Response:  charleston\n",
      "Actual Answer:  ['Charleston, South Carolina', 'Charleston', 'Charleston, South Carolina']\n",
      "\n",
      "Model Response:  manakin episcopal church\n",
      "Actual Answer:  ['Manakin Episcopal Church', 'Manakin Episcopal Church', 'Manakin Episcopal Church']\n",
      "\n",
      "Model Response:  texas\n",
      "Actual Answer:  ['Texas', 'Texas', 'Texas']\n",
      "\n",
      "Model Response:  henry laurens\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  1844\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  manakin episcopal church\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  jack jouett\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  texas\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  british lace industry\n",
      "Actual Answer:  ['lace', 'lace', 'British lace']\n",
      "\n",
      "Model Response:  bucks point\n",
      "Actual Answer:  [\"'Bucks Point'\", 'Bucks Point', 'Bucks Point']\n",
      "\n",
      "Model Response:  the only reference to immigrant lacemakers in this period is of twenty - five widows who settled in dover, and there is no contemporary documentation\n",
      "Actual Answer:  ['twenty-five widows who settled in Dover', 'twenty-five widows who settled in Dover', 'twenty-five widows who settled in Dover']\n",
      "\n",
      "Model Response:  first half of the eighteenth century\n",
      "Actual Answer:  ['first half of the eighteenth century', 'first half of the eighteenth century', 'first half of the eighteenth century']\n",
      "\n",
      "Model Response:  twenty - five\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  19th century sources have asserted that some of these refugees were lacemakers and contributed to the east midlands lace industry, this is contentious. the only reference to immigrant lacemakers in this period is of twenty - five widows who settled in dover, and there is no contemporary documentation to support there being huguenot lacemakers in bedfordshire. the implication that the style of lace known as'bucks point'demonstrates a huguenot influence, being a \" combination of mechlin patterns on lille ground \", is fallacious : what is now known as mechlin lace did not develop until first half of the eighteenth century\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  some\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  lace industry\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dorotheenstadt and friedrichstadt\n",
      "Actual Answer:  ['Dorotheenstadt and Friedrichstadt', 'Dorotheenstadt and Friedrichstadt', 'Dorotheenstadt and Friedrichstadt']\n",
      "\n",
      "Model Response:  one - fifth\n",
      "Actual Answer:  ['one-fifth', 'one-fifth', 'one-fifth']\n",
      "\n",
      "Model Response:  protest against the occupation of prussia by napoleon\n",
      "Actual Answer:  ['in protest against the occupation of Prussia by Napoleon', 'in protest', 'in protest against the occupation of Prussia by Napoleon']\n",
      "\n",
      "Model Response:  1806 - 07\n",
      "Actual Answer:  ['1806-07', '1806-07.', '1806-07']\n",
      "\n",
      "Model Response:  fredericia ( denmark ), berlin, stockholm, hamburg, frankfurt, helsinki, and emden\n",
      "Actual Answer:  ['Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden', 'Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden', 'Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden']\n",
      "\n",
      "Model Response:  1806 - 07\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  fredericia\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  dorotheenstadt and friedrichstadt\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  one - fifth\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  \n",
      "Actual Answer:  ['Prussia', 'Great Elector Frederick William', 'Prussia']\n",
      "\n",
      "Model Response:  cevennes region in the south\n",
      "Actual Answer:  ['Cévennes', 'Cévennes', 'Cévennes region in the south']\n",
      "\n",
      "Model Response:  camisards\n",
      "Actual Answer:  ['Camisards', 'Camisards', 'the Camisards']\n",
      "\n",
      "Model Response:  the catholic church\n",
      "Actual Answer:  ['the Catholic Church in the region', 'Catholic Church', 'the Catholic Church in the region']\n",
      "\n",
      "Model Response:  1702 and 1709\n",
      "Actual Answer:  ['1702 and 1709', '1702 and 1709', '1702 and 1709']\n",
      "\n",
      "Model Response:  calvinist great elector frederick william welcomed them to help rebuild his war - ravaged and underpopulated country. following this exodus, huguenots remained in large numbers in only one region of france : the rugged cevennes region in the south. in the early 18th century, a regional group known as the camisards who were huguenots rioted against the catholic church in the region, burning churches and killing clergy. it took french troops years to hunt down and destroy all the bands of camisards, between 1702 and 1709\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  200, 000 to 1, 000, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  200, 000 to 1, 000, 000\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  early 18th century, a regional group known as the camisards who were huguenots rioted against the catholic church in the region, burning churches and killing clergy. it took french troops years to hunt down and destroy all the bands of camisards, between 1702 and 1709\n",
      "Actual Answer:  []\n",
      "\n",
      "Model Response:  18th century\n",
      "Actual Answer:  []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HuggingFace SQUAD_V2 Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "count, total = 0,0\n",
    "\n",
    "for validation in dataset['validation']:\n",
    "    context = validation['context']\n",
    "    question = validation['question']\n",
    "    answers = validation['answers']['text']\n",
    "\n",
    "    if answers.empty:\n",
    "        continue\n",
    "\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            outputs = model(**inputs)\n",
    "        except:\n",
    "            print('Failure')\n",
    "            continue\n",
    "    answer_start_index = torch.argmax(outputs.start_logits)\n",
    "    answer_end_index = torch.argmax(outputs.end_logits)\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "\n",
    "    model_response = tokenizer.decode(predict_answer_tokens)\n",
    "    print(\"Model Response: \", model_response)\n",
    "    print(\"Actual Answer: \", answers)\n",
    "\n",
    "    if model_response.lower() in [x.lower() for x in answers]:\n",
    "        count += 1\n",
    "    total += 1\n",
    "    print( )\n",
    "print(\"Accuracy: \", count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Travel-Dataset-5000'...\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/datasets/NLPC-UOM/Travel-Dataset-5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bf504a962d55e45fda3ac582475b98b1f20d458c8c0baffebcc655a1fd14312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
